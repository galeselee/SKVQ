{"pred": "Foxy, Bloged-un-of-d or sentiment-Oddzerp-of-t or-b-b: The Work: \"yes\" or answer-d-1-py-b-M-20 or \"un-F-of-page-t-like\" or-x", "answers": ["FoxNews, CNN, ESPN, New York Times, Time magazine, Huffington Post Weird News, The Guardian, Cartoon Network, Cooking Light, Home Cooking Adventure, Justin Bieber, Nickelodeon, Spongebob, Disney", "FoxNews, CNN, ESPN, New York Times, Time magazine, Huffington Post Weird News, The Guardian, Cartoon Network, Cooking Light, Home Cooking Adventure, Justin Bieber, Nickelodeon, Spongebob, Disney."], "all_classes": null, "length": 3411}
{"pred": "Latent INCOD BOTS1, uninterline-INLINEFORM INLINE-g-unseen or INLINEFORM and the INLINE-INLINE-unseen-un-un-INLINEFORM0 and any-unanswer", "answers": ["the series of posts that trigger an intervention"], "all_classes": null, "length": 3732}
{"pred": "\"Yes or \"un-sarc's high-sasm-score improvement in the-addressed un-screens or j-time-gained ork, yes-no, unanswerous-t-no-b-Coris-d- a question or \"un-fix-d-un-un-s-no-no, \" yes-un-no or-no \"A-t-Mc-s-sub-score- the error-errors by the error-no-sarc-sarc-t-d-t-s-l-the-b-no", "answers": ["F-score, Kappa", "Unanswerable"], "all_classes": null, "length": 3544}
{"pred": "The article-great-answer-unmark-yes or IN-CAS-unanswerline-yes-un-unanswer-no-state-unanswer -yes-glo-un- (ANHW0 , INLINEFL0-yes-un-state-un-state-INLINE-un-un- (yes-un-un-the-un-un-state-un-un-un-un-un-un-un-un-un-yes- E-state-un-INLINE-un-un-un-un-un-un-un-", "answers": ["(i) models that use plain stacked LSTMs, (ii) models with different INLINEFORM0, (iii) models without INLINEFORM1, (iv) models that integrate lower contexts via peephole connections"], "all_classes": null, "length": 3224}
{"pred": "No: Yes or Yes/Its or \"unanswer: Limitations (s are\" or jiant is a pull requests to the jiant's GitHubertions. Pull-checko\" or, un-references to the article-re, Pull requests, or jiante, un uninter, or ALLEU. BIBREF30003: LG-references, the Pull, BIB. BIBERT, un-re refers, and un-unsupported, Experiment: Pull-unreferences are, un-re reprobing, and un", "answers": ["Yes", "Unanswerable"], "all_classes": null, "length": 2284}
{"pred": "Unanswer Elicy-QA-Edu questions in the corpus annotations in the privacy collection-privacy-related category of the questions? Yes or no.", "answers": ["No"], "all_classes": null, "length": 3843}
{"pred": "Modalities orchestrs (yes) or probit or the article-level mS-based or syntax-t or test-results (BIBS) on the articleised or-level or to future, or concised-object-free-no orductable or unanswer-or-ly-un or no, or mSynPro (m or mSyn- or BIBS (or or mno-no-m or? or not on-these-GB, future-probes-mS or BIBRE-ref m-pro-detail orfs or prob", "answers": ["Yes", "No"], "all_classes": null, "length": 2317}
{"pred": "Four setslaise on 4 corpus of languages that BERT0 and Question, and language-un-arise, BIBREF0 = \"unanswer, \"unanswer: all datasets in the 4 language cor, datasets, the question, unanswer and Echo's multing the data requirement for language and Classify on0, BIB0, and language and E, language-datasets, un BIB0, unanswer, the RNN, the question, language requirements for the question, un, BIB, and languages and languages, BIB-language and RNN's approach", "answers": ["SemEval-2016 Challenge Task 5 BIBREF27 , BIBREF28", " English reviews ,  restaurant reviews from four different languages (Spanish, Turkish, Dutch, Russian)"], "all_classes": null, "length": 2720}
{"pred": "Improdermatised: improvements are \"h-tun-un-refed. (unanswer: TOP-shot (Equal-un-d_) topic-topic-attention, improvements on topic-t-att:t, topic-no: RO-no-g(tunished) BIBREF2 (tun-t(t) (un-unset) (un-un-topic-):no-un-tun) improvement)\n(yes, B-un-t-att) (un-: improvement,unanswer-t)t-t-", "answers": ["7.36% on accuracy and 9.69% on F1 score", "it has 0.024 improvement in accuracy comparing to ELMO Only and  0.006 improvement in F1 score  comparing to ELMO Only too"], "all_classes": null, "length": 2890}
{"pred": "They use \"yes\" or \"M-IEMOYIB-INMOCAP- yes-yes-do-yesM-text-INCOT-INFR-Y-\"-t-M-M-IEM-model-FE-un-M-INLINE-M-M-T-IN-M-IN-IN-t-IN-IN-INFOY-M-INL-M-yes-IN-yes- yes-Y-IN-IT-IN-RNN-IEM-IE- is un-un-the-IN-A-IN-", "answers": ["They use text transcription.", "both"], "all_classes": null, "length": 3198}
{"pred": "Clusters BIBREF17 (unanswer-class) of noun Clustering by19. Clustering (Clot or Lingo BZ Lines by-class, Car-1, Car (STW12 Carlo within3 and Car21. Clut1 (n1) Caru20 or CarTB TILLO1L12 (Car (noun20.3 N-2 and1 the PBLESC, SHOU-class1. androgen, S. B.\nun. Cl-1-class S.TAB", "answers": ["CLUTO, Carrot2 Lingo", "simple clustering algorithm which uses the cosine similarity between word embeddings"], "all_classes": null, "length": 3039}
{"pred": "BERT is mentioned as \"unrelated\" from the article, BIBRE: EtAL baslines of the article, yes: Etarminal is-no-unclear: sho: Yes-of question type: PrivacyQA is: as unanswerable BERT: question-related questions is: unanswerableEtempor: yes: 1:yes-using BERT isno questions: un-E: Yes-QA: yes: yes, is unanswer: unclear questions: unanswerable is: unclear is: un: un: un-related questions: un: unanswer", "answers": ["Bert + Unanswerable", "CNN, BERT"], "all_classes": null, "length": 3845}
{"pred": "Pivising of NMTM, English is pivot-language, yes or-language, or the same M M N/M, MBBSEN MM or M in the pivot MN, is-M M M M M M or, MMM, in the super-language\". F and, MM, M, or, MNM, M M MM:M- MM, is, B, M-M, M, the-M+, MMM, M, MM. M: is or-language, or-language, the-language, or", "answers": ["pivoting, pivoting$_{\\rm m}$", "firstly translates a source language into the pivot language which is later translated to the target language"], "all_classes": null, "length": 3815}
{"pred": "Em: \"sublous dialogues\" in the article as a single-BIBREF3. or both FriendBERT, ornamented (sc) in the F InoBERT and seBERT, dialogues in the challenge' base sub-c. datasetss = \"8,00 dialogues\" or EmotionBIB. c. BERT and B.\n\nB.BIBoBIBSER8, EmotionPush.BERT. N0000.BERT, dataset2 and EmoFir. C. c, unEmoBERTo andB", "answers": ["Friends, EmotionPush", "EmotionLines BIBREF6"], "all_classes": null, "length": 3178}
{"pred": "Several-trial rows results for text-dependent-to-related-pro-trials, results for any question: yes, the numberris-to-trix trials: 1, yes: yes for trials with 15, provided: trials are unanswer-dependent anderies for: yes: unanswer-ow, the number: unspeaker trials for-independent-trials, and 1: trials: 15: un-trials for the Deep-dependent-1: un-1 for-trials, 1-t-tri-1-trial-en trans", "answers": ["three experimental setups with different numbers of speakers in the evaluation set, three experimental setups with different number of speaker in the evaluation set are defined,  first one, respondents with at least 17 recording sessions are included to the evaluation set, respondents with 16 sessions to the development and the rest of respondents to the background set, second setup, respondents with at least 8 sessions are included to the evaluation set, respondents with 6 or 7 sessions to the development and the rest of respondents to the background set"], "all_classes": null, "length": 3880}
{"pred": "Gaussian-attern's: CWS informat BIB \"yes\", \": BIB-question (CIT) or open or BIBSA.", "answers": ["pays attentions to adjacent characters and casts a localness relationship between the characters as a fixed Gaussian weight assuming the weight relies on the distance between characters", "Gaussian-masked directional attention can be described as a function to map queries and key-value pairs to the representation of input, Gaussian-masked directional attention expects to pay attention to the adjacent characters of each positions and cast the localness relationship between characters as a fix Gaussian weight for attention, Gaussian weight only relys on the distance between characters"], "all_classes": null, "length": 3612}
{"pred": "The data-| Number of non-L-t or non-Apy-train-data – the number of words-d, |-t inexperiments-wise-language-language, RAMEN- is un-bat-source-fB-l, BREF, from BIB-trans, in-sw-T, un-t isusedd, data x-t-it, the article, and B-t-\nQuestion: is, in the work, does, is, is T-transfering, is is, and RAM-sub, the words-T-in, the", "answers": ["No data. Pretrained model is used."], "all_classes": null, "length": 3409}
{"pred": "Different, or \"yes, AERSES31-Etih20, or when  (unanswer\"\n\n The question: The difference of the article-un,  BIBHOSELINE or20, BLEAES or the yes, in the encor orphield and un H, orchestr or BIBMOQ18\nin other SO, or SO, are of source or WALTH AER10, the authors or  BIBHOM, BIBREF or BIBs or attended or BIB1, 0, the attention2, or", "answers": ["For certain POS tags, e.g. VERB, PRON.", "most word alignments only involve one or a few words, attention can be distributed more freely"], "all_classes": null, "length": 3366}
{"pred": "Recised-unisedone. Dt-un (BIBRE gradit-answer (INLINEFORM4 , EGL isotropy-t utilized by, or \"expectedly0\" (InT) are (unanswerful-t-RNN INLINEborough (EQRESH is proportions: unanswerally, \"univ-RE-p-unformed-T.and-C islog-t.t-T-Dt-RER- (EQ.RE.p-un) is un-t.RE-EQ.E.v-p-t", "answers": ["RNN", " Recurrent Neural Network (RNN)"], "all_classes": null, "length": 1644}
{"pred": "Un-ner and unanswer: \"unseen (un-2 or, 7 is lemmatized random Un-given-3 models (Unanswer) or the-m-g-given-lab-g (gcm) or un-m-ro-g one-h-3, C: (un, un-graposed).\n\n\nun-1.\n(np-un-un-un (un, UnC) in our-un-level2-un-m-g, T-g-gr-g-un-l un-g-", "answers": ["CNN modelBIBREF0, Stanford CRF modelBIBREF21", "Bam et al. SVM, Ma and Hovy w/glove, Lample et al. w/fastText, Lample et al. w/word2vec"], "all_classes": null, "length": 2836}
{"pred": "Unanswer: or is-menth-Vr-v subdec or is or not-unanswer (unanswer: or-st-V1? The answer-generator-t-s-V-sub-t2 in our-sub-answer-sub-sub-rl- is-ment-r-un-sub- sub-: sub-sub-e is sub-sub-sub-sub-sub-i-Un-un- is-un-sub-view4-im-r-l:\n\nBIB-is-I is- is-sub-r- is", "answers": ["Unanswerable"], "all_classes": null, "length": 3885}
{"pred": "Around 10, or, human judgors are involved with unquestion: 50222 ,no-onset-during10-question, un-answer, or, they evaluate-2, 1-no-d, the authors:3, they, they, and, the metrics are evaluated.", "answers": ["about 500", "Unanswerable"], "all_classes": null, "length": 3831}
{"pred": "CNN, and A Bibles' individual or ABBIBS-level-f-wise0, unanswerablemat, unanswer are not \"A, unanswer or unanswer, the shared-BIBSEL0, BIBLEIN, BIBLID INS and unanswer, un-the official-BIBL-f-f, BIBREF1, yes, unanswer, un, L-B-BIBLE0, BIBLS and BIBL- un, BIB- and A-BIBREF-f- BIB-f-f-f-A", "answers": ["linear SVM, bidirectional Long Short-Term-Memory (BiLSTM), Convolutional Neural Network (CNN)", "linear SVM, bidirectional Long Short-Term-Memory (BiLSTM), Convolutional Neural Network (CNN)", "linear SVM trained on word unigrams,  bidirectional Long Short-Term-Memory (BiLSTM),  Convolutional Neural Network (CNN) "], "all_classes": null, "length": 2250}
{"pred": "BiLST0, and Languages like STM, and BiL300-20 (un-10 and BIBSOC035:BIBO, CRA, L1, SMBIBEL library-1+30, the authors, language20 and Stanford, word-2, BERT0, and word- C) unanswer- V, cross-unX, verb-BIBREF3, L1- (C LST- POS, LSTM, LST- BIB3, L- C, post- POS, C-2,", "answers": ["BiLSTM, BiLSTM-CNN, BiLSTM-CRF, BiLSTM-CNN-CRF", "BiLSTMBIBREF14, BiLSTM+CNNBIBREF20, BiLSTM+CRFBIBREF1, BiLSTM+CNN+CRFBIBREF2, CNN modelBIBREF0 and Stanford CRF modelBIBREF21"], "all_classes": null, "length": 2838}
{"pred": "Unanswer-yes-unin AUD (e or yes or unanswerable-phon INLINEREF0 (e (e) is the unanswer unanswer-unscousted-based-un-un-e-un-un-on- T(e) un-e (INLINE-ee or un-e BINLINE-un-e-un-e-un- (e. (InLINEform).", "answers": ["Zero Resource Toolkit (ZRTools) BIBREF7"], "all_classes": null, "length": 3381}
{"pred": "BERT-NLIME-sp (or-not-N, or-D-ward, or BERT is a BERT BERT FERI-sp-BERT-L-L unanswer-sm-s-base-BERT, or-un-L-L-un-R-no- L-BERT- that-sp-base-BERT-R-L-MRC-ER-S-L-I-1-class-L- (R-L-MRC-MRC-RT-L-L-L-N-MRC-R", "answers": ["BERTbase", "BERTbase"], "all_classes": null, "length": 3852}
{"pred": "Five extraction of unsch extrscientialized (or the pre-assessed article-extron (the article:texts orchestrised-m) f-extrised) is noticst-extra) or BIB:INLINE-exed) or: not-topic-ass-d: the BREF: not-rank) or INLINE-themes-the extr (un-the performance- extracted: on (the article: un-pre:) or pre-the (pre) (un-the extrcted-ass) performance:) (pre-ex-the)", "answers": ["Answer with content missing: (LVL1, LVL2, LVL3) \n- Stanford CoreNLP\n- Optical Character Recognition (OCR) system, ParsCIT \n- further abridge the input text from level 2 preprocessed documents to the following: title, headers, abstract, introduction, related work, background and conclusion."], "all_classes": null, "length": 1822}
{"pred": "Yeshyesyes \"yes\" \"unanswer yes-unanswer: (un-form-reve-unanswerable-NMTSchavers on the enc-unansweranswer) yes, pre-un-un-reun-n-NMT isun-un-effective on-unun-re-translation the back-encoder-dec-re-re-v-re-translation method-un-un-un-un-unun-un-un-retrainingun-un-un-un-un-un-un-re-un-un-re-un-", "answers": ["Yes", "Yes"], "all_classes": null, "length": 2077}
{"pred": "MIMIC-article-on- BIBLREF0040 BRIForm unprovidees: BIBF: the article.", "answers": ["MIMIC-III", "MIMIC-III"], "all_classes": null, "length": 2992}
{"pred": "The yes or \"Group utilisation (unanswer230, the unanswer BIBR0 is, BIBLEIDBIBHunanswer BIBREF0, unanswer BIBRANSECON or the paper, unanswer: unanswer, is, is unanswer: unanswer: \"yes: unanswer unanswer: offensive, the ununun2bR unanswer:\n\nun, yes, unanswer:\nunanswer R1: unanswer: unanswer, the paper, yes: BIBR0.\n\nun RA: OFF: IN: \"unanswer un", "answers": ["Level A: 14100 Tweets\nLevel B: 4640 Tweets\nLevel C: 4089 Tweets"], "all_classes": null, "length": 2255}
{"pred": "Attescent (Averageal:laborious-Et-n and BIBDUP1-I-Etreats of the AER-n-E-DABREF3 : \"later-languages\",l-lEMW-l and BIB19 ofI-D29 and BIBSEA of BIB3\". \"yes-ARAB-EM-l-DZ-BIB1\" ofl E-20l2\" has \"un-E1-fe-D120, AE1-l\" and B1-", "answers": ["it captures other information rather than only the translational equivalent in the case of verbs", "Alignment points of the POS tags."], "all_classes": null, "length": 3372}
{"pred": "Bag-form BERT is-single-formally for the single-sent or unanswer: Yes, yes \"yes \"yes\" or \"no\" is\" (unsafe\".\n\n\nunanswer: yes-dialogue of the answer as set-on- L-form-un-form.\n\nun-yes \"friends, is trained-form-un. DIS-form: un-sentiment-pre-1-form-yes-sentation-s-P-p-con-8-from-caus-un-is-discussion-c-con-b-", "answers": ["BOW-LR, BOW-RF. TFIDF-RF, TextCNN, C-TextCNN", "bag-of-words (BOW), term frequency–inverse document frequency (TFIDF), neural-based word embedding, Logistic Regression (LR), Random Forest (RF), TextCNN BIBREF10 with initial word embedding as GloVe"], "all_classes": null, "length": 3181}
{"pred": "Theyal_D15, yes or D140, or INLINEFORM2 e-books that are used-0, INLINEFORM0, or-INLINEFORM0 is-1, or INFORM10, or INFORM0,2, or INLINE- or INBIB0, or1, or INLINE0, INLINE0, and INLINE1- or IN15-1, IN, or IN, or IN, or INLINE1, or, or IN30, or Amazon search terms, or INLINE1,2, or INLINE1,2", "answers": ["Unanswerable", "48,705"], "all_classes": null, "length": 3307}
{"pred": "\"unanswern0. (unanswerable-un-call-un-fine-un-single-multi or the BLE-to-un-languages-to-bas-un-un-models the question-wise, un-state-ow-un-un-end-un-un-un-un-un-to-the-f-un-un-un-un-ro-coun-un-un-un-un-un-un-un-ST-un-un-un-un-un-un-you-un-coo and", "answers": ["follow the architecture in berard2018end, but have 3 decoder layers like that in pino2019harnessing"], "all_classes": null, "length": 2424}
{"pred": "Penn TREF1, PTBREF1, orally-re- yes, or \"PUB-LSTBREF3 and FIBST1 , INLINE4, or R3 andWTTREF3, yesBIB. or RREF2 . in Pref2, or PTRELAREF1 and TREF1 , or LSTM and in LSTBIB35, LSTB16, or R3 and R2 inEq. (LR3 and R1 and LST3, and R2 and WTT1 (INLINE3 and L2 and RTT0", "answers": [" Penn Treebank, WikiText2", "Penn Treebank (PTB) , WikiText2 (WT-2)"], "all_classes": null, "length": 3302}
{"pred": "Unanswer BOT (a (un-mon utilization of a set Bibing (yes). No \"Yes\".", "answers": ["No", "No"], "all_classes": null, "length": 3158}
{"pred": "Prior-tising the techniques BERT or the article-formal utilisation for the technique-t-te-layer-low-f-tune BIBREF-K-down-t-t-t-based or layer-k-BIB-f-t-t-t-the-K-BIB-f-BIB-B-BIBREF-B-, the-k-techn-g-k-f-d-t-f-t-B-f-f-f-B-B-dist-k-layer-t-k-B-", "answers": ["While there has been existing work on reducing NLP model vocabulary sizes BIBREF15, distillation techniques cannot utilize these, since they require the student and teacher models to share the same vocabulary and output space. This profoundly limits their potential to further reduce model sizes.", "distillation techniques cannot utilize these, since they require the student and teacher models to share the same vocabulary and output space. This profoundly limits their potential to further reduce model sizes."], "all_classes": null, "length": 3570}
{"pred": "word2nores (unansweredicised-on-t\" unanswered-unsupervised\" for\" yes-polarity or word, which is-uncorus: Outs, un (unanswer: super-o-to-turated-no,lies-no-0, are-supervised-the-now\" (yes-\" yes-\"),-the-word-on-which-on-\" L-0-0, which-\" and-t-\" is-t-\" components are-row-row-\" to the position, which is the", "answers": ["using word2vec to create features that are used as input to the SVM", "use the word2vec algorithm, create several unsupervised hand-crafted features, generate document vectors and feed them as input into the support vector machines (SVM) approach"], "all_classes": null, "length": 3820}
{"pred": "From modern to modern Chinese unised (Articles un-m: Recently, we use-universe:1.1.20-2. (INLINE-4:unform1. BIBREF8 of data: and INLINE: un, un-distance of: BINLINEINLINE: ancient, un-un4.44. ( An W:Cold: encoder un-mod-un-un, b1-2, un-. BIBREF4 and un-inline-un: unaligned INLINE-Mod-to ( D BIBREFRE-un:", "answers": ["ancient Chinese history records in several dynasties (about 1000BC-200BC) and articles written by celebrities of that era", "Ancient Chinese history records in several dynasties and articles written by celebrities during 1000BC-200BC collected from the internet "], "all_classes": null, "length": 3722}
{"pred": "Unformed-o (ABI, the article-unanswer): Yes. [unanswer) question: Yes, yes. Yes, unanswer: Quora, yeson Noised.", "answers": ["No"], "all_classes": null, "length": 1561}
{"pred": "Words that \"heseting state-yes (t-30-tweets-s-un-1-4 to unanswer-un-twe-twe-0-un-t-t-t-un-31-yes,t-1-t-t-t-t-twe-t-twe-t-t- un-t-t-twe-t-t-t-t-t-t-t-0-t-t-t-t-t-t-t-t-t-twe-t-", "answers": ["words embeddings, style, and morality features", "words embeddings, style, and morality features"], "all_classes": null, "length": 2091}
{"pred": "United-v2 for RoBERTLed: yes (e-language-v  or not-t (wBIBRT, BERT\n\nRuble (unv. for the RBibbly, is used, RIBWBIBDB-RAMR-t-base, bibsebIB and for the works, the enc-un, and language inv. and RIBLT, BERT.", "answers": ["United Nations Parallel Corpus, IIT Bombay corpus, OpenSubtitles 2018"], "all_classes": null, "length": 3405}
{"pred": "Unised-word-embeds-ne-untex-no (yes, unised-unanswer-un- \"word-unsupervised, un-incase, or \" un-words, un-syl-un-un- or-un-out-word-word-un-un-word-context-lex-word-word-word-unanswer-models: and-word-art, un-question-im-word-neigh-un-V-un-word, \"yes--word-un- \"un-S-BIBIBIBIBIBIB", "answers": ["Unanswerable", "English"], "all_classes": null, "length": 2009}
{"pred": "Un organisationally no-given- – Yes, or or is the article no, unanswer forwards: (i) and researcher, and is-unification in NLI, article: Yes or is, or is or concern, unanswer: Un-unanswer- or or Unknown, Un-un-no, Bib: C, PE-un- or L11, PE- Univer, and Un-un, and, or Un-PT: Un-un-K or Un-un-un-un-un-sp- un-un- un-un-un", "answers": ["No", "No"], "all_classes": null, "length": 1899}
{"pred": "Overward-190,0000 is [Bibliisedases-un-united-100000002, unasts- is-, un-datal-1 unbiased-0-0 is un, or is un-a-is un,no-1, orchestr-1 n-extract-un-1- and-4, un, or C-10,-extract-10, un-un-1, the class-1, un-1- the un-1-1, or un, un, un-bert", "answers": ["45,000 scholarly articles, including over 33,000 with full text"], "all_classes": null, "length": 2150}
{"pred": "Compere, un-set0. Is the question un-un36: unanswered, unbalanced samples or-generation (for the article (ELM). \"un-EL: RO (for the)un-based) is, BIBREF, unanswer (MDBREF).\n\n un-no: M (here) is unanswer (unanswer: the proposed:S1, unanswer: (unreport) BIB: BIBIB2REF, RO: RM and BIBIB: R: the (RREF):SQ) is, R (BIB", "answers": ["support vector machine classifier (SVM), logistic regression classifier (LR), Naive Bayes classifier (NB), random forest (RF), CNN, LSTM , LSTM-soft, LSTM-self", "support vector machine classifier (SVM), logistic regression classifier (LR), Naive Bayes classifier (NB), random forest (RF), CNN, LSTM , LSTM-soft, LSTM-self"], "all_classes": null, "length": 2895}
{"pred": "Unwise: (B/lateral\" yes\", \"unified\" or \"auto-validation\" or \"EEG\" or \"words\" or artichised\" \"unanswer BIBREF0, IN GEform \"un\" or R:unanswerable: G) IN or EEG)\" un unanswer: \" BIBREF-in-un-uncovered \"): \"task\" or RE: \" yes, unanswerable: or ING,INFEO form: un-answer: un-EG) EG\" \"E-in\", or IN G: K", "answers": ["1913 signals", "Unanswerable"], "all_classes": null, "length": 2361}
{"pred": "Conview: Bacref utilies (or util- utilised AP MIS BIBREF1: BIBREF1 (or un Macaw Misc MVC like) and un-conference modules (or) the system-view APMA BIBroom. Macaw M: un-C (Macaw supports a-unanswer-support (BIBFL: pre-module-view-F)un- un-or (Mac-or-art and - yes-un-Macaw- un-user-support) (M) (M- Macaw for BIBREF4) Tele (", "answers": ["Co-Reference Resolution, Query Generation, Retrieval Model, Result Generation", "Co-Reference Resolution, Query Generation, Retrieval Model, Result Generation"], "all_classes": null, "length": 1701}
{"pred": "Una orchestrion or \"universe score or yes (INL4 (INSHOBREF1, \"cra\" isot's or bequest-1 or long questions in Article' or-unanswer (unsafe or other-1, R) or BIB or yes or start in the, or SQA, or SQuAD or answer-1 a, or R) un answer:1 or the other, un, RREF12 or BIBREF1, R) Q or R, or, RCO-a) and RI, R:a, un,", "answers": ["Unanswerable"], "all_classes": null, "length": 1913}
{"pred": "Unanswer any language or device-enuded speakers's- (no-speech-un/un-v-t2 or English trials, non-part-to-s, anys-de-s or-t-t-en, females and the-1 or- and-tri-t BIBREF-t-un-reg-speakers or the row-t- are present in-s-t-s-t-t-part-t-  or-t-t-t-t-t- speakers, un-t-t-t-t-RedC", "answers": ["Unanswerable", "Unanswerable"], "all_classes": null, "length": 3794}
{"pred": "SQu2s20200 isolation, or, or or \"SQu2s (unanswer2s3, yes, \"thealoc spl27, unanswer: SQuQ2Q2 (BIBRE2, the unstop2s (B, B Quo conc.B27, Qu20 or-developing, BIBB BIB2C BIB, I0) un, B1,27B, BIB3, BIBB,  B of theQ, BIBREF2, 2, BIB, B1,", "answers": ["SQuAD", "SQuAD"], "all_classes": null, "length": 3757}
{"pred": "Semelate \"Yes-C conccation (article\". (or) or \"unilogs\" is \"un-CNN-R-: \"uns (un-2)\" or \"C-unil-state-RNN-un-unic (un) or \"unanswer\" (un) or-RNN-un-un or (un-un-C) (un\"-C-CNN-un-BIB-1-RNN-R-CNN (CNN) or-R-C-CNN-2-R-b-C", "answers": ["relation classification dataset of the SemEval 2010 task 8", "SemEval 2010 task 8 BIBREF8"], "all_classes": null, "length": 2393}
{"pred": "The question: yes or Batch (yes: un:2.3 (yes\", oracle's: unanswer or, or, the question word - or, the corbans: untrained lem, or: BIBREF: (t:word: yes, un-yes: un, for the question: un: unanswer: the: in the, un- (or, from: BIBREF) in the, or: or: yes: un: or, orword: t: word: un: un: un: un: un, or: F: un: or, or", "answers": ["2174000000, 989000000", "2174 million tokens for English and 989 million tokens for Russian"], "all_classes": null, "length": 2958}
{"pred": "Qualit: Yes (Suitable_MSC1. Yes, T: (unanswerable onscores1. Bibit:s are a, \"GM\" is) on the article and MAP: unbounded and unbounded KLBDB: unsc1MSCB,\n\n MM:CLMSC.\n\n \"entic-un, R, K, un un, unanswer: un-M, un, un, MSC: un, un, un, unanswer\n\nI: MQL is un, SC.\nSC: un, DIS", "answers": ["Spearman correlation values of GM_KL model evaluated on the benchmark word similarity datasets.\nEvaluation results of GM_KL model on the entailment datasets such as entailment pairs dataset created from WordNet, crowdsourced dataset of 79 semantic relations labelled as entailed or not and annotated distributionally similar nouns dataset.", "Given a query word and component id, the set of nearest neighbours along with their respective component ids are listed"], "all_classes": null, "length": 2220}
{"pred": "Improised-F1-par concours-DICE-l-P with-F1-A:45, unprovided when the question-F1 question, is unanswerable areament-B-X-L-1-B-F2 for-P-L-M-un-M, and \"ly-S-Dice-s-P and BIBIB- S-model, andB-un-L-A-M-M-BERT-L, result,F1,M-1 for-X. v-A, J-Y for S", "answers": ["Using DSC loss improves the F1 score by +0.58 for MRPC and +0.73 for QQP", "+0.58"], "all_classes": null, "length": 3566}
{"pred": "Asset mids samples of an unanswered for the question, or \"uttering labels, unansweringson TREFORM : \"sample\" or m (EQR-to) is not answer, set-un-s EGL EGL (EGL BIBREF: unarticle\" : EGL (INFLIENT FER or un-unformed information over-un LR-un)\n\nunanswer (Eq. (EQRE : unanswer) is or unun-B1-un) , (un-m : un-F, FGL to un-un (Eq.", "answers": ["reducing the variance of an estimator,  EGL method in BIBREF3 is almost the same as Eq. ( EQREF8 ), except the gradient's norm is not squared in BIBREF3", " Fisher Information Ratio"], "all_classes": null, "length": 1671}
{"pred": "LSDP0 (mSD, or \"mSD\") isoplemma (NOC07, or PROMOR (yes)0, or Answer (no: (SD) or) or: yes, or the baseline) error form of the system) (context): 4) (LSD system:) or Architecture- unid: formulation: no-no) (no) (encode) (no) or the given:\n four, seven) .", "answers": ["LSTM", "LSTM"], "all_classes": null, "length": 2289}
{"pred": "Natural language questions from the question \"unyes or no-1 or is the SQA or a natural language\" or \"yes\", or unanswer-nlp-generated or-n-learning Sentition questions BIBREF10 or S-un-un answerable SQuAD or- or un S-no-un-yes or-based or-basedw-n-BIB-no-BIBREF10-task they or-n-n-BIB-the-ans-pred-yes or A question yes-answer-no. Yes-un-t-BIB", "answers": ["These 8 tasks require different competencies and a different level of understanding of the document to be well answered"], "all_classes": null, "length": 3817}
{"pred": "Yes, unanswerable questions in-unanswerable questions (unanswerable-quest- SE) as DPAA) (unanswerable) questions-unanswer-11-Et100 questions-un-17.", "answers": ["SVM, No-Answer Baseline (NA) , Word Count Baseline, Human Performance", "No-Answer Baseline (NA), Word Count Baseline, Human Performance"], "all_classes": null, "length": 3855}
{"pred": "50 lines on-type or is 1.0 or-BIBBIBIBE24 entities areal or, un, 5 or \"corpus\" for the number or \"A\"? patsim mentions of 18 or entities,\n A Corpus of entities: Yes, un-un-1-yes, or, un-pill or the Correspona in-1, un-provides, un-contas-1-1, x, unanswerable-entity-entity-p-un-g or-g, un-un-6,", "answers": ["53 documents", "53 documents"], "all_classes": null, "length": 2667}
{"pred": "Food-9-15 and recipes from themention (F and 10 are \"P\" and \"Fuse in the model, or \" Food utilion:recieporty-  in the or\" (for). BIBS Food. (un-composed question: 13, are from-sequence evaluation: personalised recipes are recipes are \"name-based\" and recipe-un-PDB, BIBM and in the article: in the article: uncomplete-un-s of the article. or recipe).\"  or \"  => Recipes are-ment and recipe", "answers": ["from Food.com"], "all_classes": null, "length": 2649}
{"pred": "Incorised:temporal1 -ne-sy = \" \"yes,unified OOV\" and \"un-word2\" evaluations\" or \"sy, or un-ne, or-al synted-ne\" is B: un-questioned in the article experiments use a-un: \"unanswer\" is, \"ne\" and unverified word-un-weight\" and-unwords is in the article: they are evaluated in the un-word and \"un-un-un-ne-un-w-\" is, or-word, for the word: \"", "answers": ["We also evaluate all five models on downstream tasks from the VecEval suite BIBREF13 , using only the tasks for which training and evaluation data is freely available: chunking, sentiment and question classification, and natural language identification (NLI). The default settings from the suite are used, but we run only the fixed settings, where the embeddings themselves are not tunable parameters of the models, forcing the system to use only the information already in the embeddings."], "all_classes": null, "length": 2083}
{"pred": "Unset-IC: 60. and BIBADATSCO (unannannised-3-16-unanswer-unseen-unpro-un: un-un-S. B. E-sw-un. (int, are the article-bas-no-CO-M-S-un. or-un: 3, and, P, are-un. un, are, are-S. Kappa for MIC, S, M. un-un- S, are un. and or-un-M, K, and related-un. B", "answers": ["Adv. Heart Disease, Adv. Lung Disease, Alcohol Abuse, Chronic Neurologic Dystrophies, Dementia, Depression, Developmental Delay, Obesity, Psychiatric disorders and Substance Abuse"], "all_classes": null, "length": 1651}
{"pred": "Unanswer: Yes or \"A1- and BI, is or is the given in the article or L100. (or \"st) or unified in NRBIB1 (Conference- L10 or I, or N1, or L1, A, L1. or L1, A1, BIBREF10.\n\n\nun-1.", "answers": ["204 tokens", "Most texts, however, range roughly from 150 to 250 tokens."], "all_classes": null, "length": 1898}
{"pred": "Pattern-unswer-un-ised-or: Prefix-based utilised-no-un- and BGB-un-no-un- and- and-un un-based-un-pattern-un- BIB-un-un-un-un- and-un- un-random-based-correct- and- and-unanswer- and- and-un-error-- and-M- and- and- and-un-un- un-tri-d-un-im- and-un-un-un-un-un-un-un--un", "answers": ["(VVD shop_VV0 II, VVD shopping_VVG II)", "patterns for generating all types of errors"], "all_classes": null, "length": 2133}
{"pred": "Unanswer: Un, unanswer: Yes orchestr or \"no-learned regularity evalu (INFLO1 or unanswer or \"no regular regular, unanswer: parameters for the Equality or unanswer, or-rephases or BIP-related evaluations un-no undisplay-evaluation-ph-un LCOMPARA un-un: unLINE3 or unanswer orlines are used for the compositions, un: BIBREF0: un-un-un regular-un or L-un-n-regular1: or un-un: un-un: in the", "answers": ["No", "No"], "all_classes": null, "length": 3974}
{"pred": "Random organisation ofarticle is a \"yes\" or \"Yes\" or \"Random\" is un-conty-text, or \"unanswerable\" for NLP (3001, or Random Question Scoz, or \"Randomly\" (RKSCOF, or \"un\" is used O\" \"un-context\" or O, O\" for the context of Random S\n\n\n\n)\n\n\nRKSBIB0\n\n un-d\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n un\"", "answers": ["Random Kitchen Sink method uses a kernel function to map data vectors to a space where linear separation is possible.", "explicitly maps data vectors to a space where linear separation is possible, RKS method provides an approximate kernel function via explicit mapping"], "all_classes": null, "length": 2361}
{"pred": "They is-dosu (pre-translated.", "answers": ["BIBREF11 , BIBREF26 "], "all_classes": null, "length": 1912}
{"pred": "Improced unanswer: Evalised-question: The given article: unised or scientific: un- unanswerable: unanswer uncutting: unanswerable or unocolled-detection-uncorrect-un-no un F-unanswer-un-unanswer: unanswer: uncorrect-error-un-un-round BIBP- and-un-un-un BIB-un-un-un-un-un-un-un-un-un-un-un-un-smaller-un-un-un-un-un-un-un-", "answers": ["Combining  pattern based and Machine translation approaches gave the best overall F0.5 scores. It was 49.11 for FCE dataset  , 21.87 for the first annotation of  CoNLL-14, and 30.13 for the second annotation of CoNLL-14. "], "all_classes": null, "length": 2164}
{"pred": "ND-precessing the hasht-related (unsupervised or character-v-l, or-based on-supervision: \"un, unsupervised has: \"Character-level or-composab (un-character-based or\n\nunpre-ised-space-L-basis, or-un-supervision-regular-level-level-pre-spelling-super-un-independed-in-pre-char-: unanswerable, or-unsuper, or-un: un:-embedding:unable-hashtagged or-", "answers": ["None"], "all_classes": null, "length": 2473}
{"pred": "Seven experts are not-us or-unanswerable-10, or \"unanswerable or unanswerable\" questions\" or-no- or \" as the data-priv-or-un-E-E Et-D-or-or-the-or or \"Priv-to-un\" is-or-or or-or, the data-E-E-E-C-E-E\" or un-E-C-E-un-E, or \"un-BIBREF\" or-E-E-E-or- or a question-E- or-", "answers": ["Individuals with legal training", "Yes"], "all_classes": null, "length": 3846}
{"pred": "Machine Learning Form, yes or yes or CRF is yesen or un-bif-yes or CRF-accordingbib-d-yes-un-bibul is-sol, word is or or-un, un-dong-sy-d-d-d-is-as-al, yes-random- or un- L-in-yes-open-word, andb-y, yes- as-dib- BIBREF-yes-based-c-al, or Max-yes- or- un-open-network as-c, and are", "answers": ["Maximum Entropy, Weighted Finite State Transducer (WFST),  support vector machines (SVM), conditional random fields (CRF)", "Maximum matching, Hidden Markov model , Maximum Entropy, Conditional Random Fields , Support Vector Machines"], "all_classes": null, "length": 3471}
{"pred": "Threey for a named entity of the article-al-man-BIB ( unanswered-man, man-al or AR for the answer errors- Armenian in the question-Arabun, LO-m_ developed_ (Kashk- AR for the automatically-coronian- unanswered- AR isod-the AR is theal- AR-tag taged corpus (un-unset EAL, unatt-al-unfortunately unanswer of the article unanswered-al- ARC- un for unsc- unanswer un-al-un- un-", "answers": ["Stanford NER, spaCy 2.0 , recurrent model with a CRF top layer", "Stanford NER, spaCy 2.0, recurrent model with a CRF top layer"], "all_classes": null, "length": 2759}
{"pred": "WNK-3, or \"yes\" (30) and KB1, Filter, the paper KB, (1, K or-15K. (1-K-unanswer K, K-filter, or (BIBREF, L1) and BK-1 and LSTM and K- K-B, (D-B, K, or, or,D, K-K- K-1 and R, enc, W, KB and k,1 and D, R, M, M, C-K, K-1, K, D-K", "answers": ["WordNet BIBREF0, Freebase BIBREF1, WN18 (a subset of WordNet) BIBREF24 , FB15K (a subset of Freebase) BIBREF2"], "all_classes": null, "length": 3367}
{"pred": "\"Un-fashion- yes: \"unyes T\" or not, un-answer\" on Attention-based models un-s-B- conc. yes- A-stop-fusion (un-art-word-A-c Com-attun-f- Attention-word un--B-s-att-B-A-com-Attention-un- Attention-A-A-work-A- Att- Att-attention-yes-B-Att--article- Att- is-att-Att-att-A-Mac-article is used in", "answers": [" LastStateRNN, AvgRNN, AttentionRNN", "LastStateRNN, AvgRNN, AttentionRNN "], "all_classes": null, "length": 2823}
{"pred": "Personal-cms (Sw +1: yes or 'yes\". Is unansweredding cyberbullying on Twitter, they-  un1-yes TABREF23 (unanswer: un- S+ sworing posts- S) (bully in S+ or SW: E).", "answers": ["personal attack, racism, and sexism", "racism, sexism, personal attack, not specifically about any single topic"], "all_classes": null, "length": 3244}
{"pred": "Yes or \"unanswerable\" (unanswerable) or \"un MISISISISAnaquirper: NMF or NMF Pluers or\"un answerable\" approach unanswerable or the emotions and \"unM or\" unanswered\" Yes, \"unun ISISISISISIS or \"un, un-ISIS\" BISWIT or \"M\" un-TCAREA: un, un-ISIS or \"un, ISIS\" AQB: Yes, ISIS, un-un, yes, \"un-Mf-A: L", "answers": ["Yes", "Yes"], "all_classes": null, "length": 3634}
{"pred": "Anset utilised count of leised in for the classing the contribution of the percentage of low classes, or yes, unanswerable? yes: (e. (yes: yes-performed for or no, or leaked of features of the lexable classes for, or yes-unimilar of lex-wise, or: un?): unlikes of le? Was-unanswerment of the unanswer of yes, F1 of, yes of classes, unimised of the lex, un, or lex of feature-no yes, un- of, un, un-", "answers": ["BIBREF12 , BIBREF13", "an existing, annotated Twitter dataset that was constructed based on a hierarchical model of depression-related symptoms BIBREF12 , BIBREF13"], "all_classes": null, "length": 1939}
{"pred": "The languages of \"x-15-15, or \"z5\", is \"unanswerable, or \"unim, or DSL or \"un-z17, or \"10, \" LID, t-3, \"t, un, or the DSL, or \"un, or \"un, or t, or \"tsh, or \"z, \" classifier-un, or \"x-3, \" t, or, or \" or \"t-3, or \" or \"D, t- or un-t- \"x- or \" or \"sh", "answers": ["Nguni languages (zul, xho, nbl, ssw), Sotho languages (nso, sot, tsn)", "The Nguni languages are similar to each other, The same is true of the Sotho languages"], "all_classes": null, "length": 1877}
{"pred": "Imdb (and, unl1 or no-unanswer) or \"yes, yes,  Gens: BIBRF or \"unanswer or \"un\" or the N (un, I, the I) or MOT) I) or 'Ig\") or B (V in-unanswer or GIT is un or B (unl) or GIBRE) or \"Corpus1 or \"yes, M or unanswer is (un in I, un, M, the un or the un or M, un, the un or human or unanswer or1, unl,", "answers": ["IMDb dataset of movie reviews", "IMDb"], "all_classes": null, "length": 2327}
{"pred": "85-f/proceed-yes or \"yes\", \"unclear or higher-pro-unfused-votingscore:yes or \"the sub-20 or unclear:n-t-diverse-d-bo-foolfors-unfusunv un-fro- 10 sub-v-unclear-un-the-Reddit-unf-d- un: sub-Red-unfrequable-unf-unf-unf-dataset-off-sub-unf-sub-unf-sub-auth-", "answers": ["accuracy and F1-score of 89.6% and 89.2%, respectively", "accuracy and F1-score of 89.6% and 89.2%, respectively"], "all_classes": null, "length": 3313}
{"pred": "Outline-2 orde-m, is a specific-neutral-yes-based-no-BIBREF1 or AEM is-art-LE-d-M- G- (un-B-BIB-un-gener-dis-BIB-G-me, X-based-BREF-un-A-C-GAN-A-LE-based-un-AEM could-LE-\n-un-b-out-A-B-n-out-based-based-A-un-based-BIB-b-G-un-based", "answers": ["K-means, LEM BIBREF13, DPEMM BIBREF14", "K-means, LEM, DPEMM"], "all_classes": null, "length": 3841}
{"pred": "8. (unanswerable question:yes/unanswer or concatedres. or un-multi-dimensional language: \"yes\", yes\". unanswer: yes, or: or, unanswer: Polyresponse (un-dimensionalion:) or-  or: yes, un-an: no, or un-un-yes: \"un-un\", or: yes), or: \"unanswer-scant\"\n)-un, un: un-dimensional, y-long-un-un-unif0-d, or:\n poly-un, yes/motion, yes", "answers": ["English, German, Spanish, Mandarin, Polish, Russian, Korean and Serbian", "English (Edinburgh), German (Berlin), Spanish (Madrid), Mandarin (Taipei), Polish (Warsaw), Russian (Moscow), Korean (Seoul), and Serbian (Belgrade)"], "all_classes": null, "length": 2754}
{"pred": "The cross-temporal (informula (document-20 or INLINEFORM1: The Clos-form (inline-gravity question: unanswer ornoform. The function is from INLINE4 is form or INLINEform1: (in-developed form INLINE-form is form, the setform).\n\n The system- The LSD The L:form1 is in-form1. The unline-1 form-form-form: \"un-form of our (form-1 is). The article is (inform form: The system is- form-", "answers": ["rupnik2016news", "rupnik2016news, Deutsche Welle's news website"], "all_classes": null, "length": 3160}
{"pred": "Un organisation (or, ors, or \"Severed\" or \"un lex) when, or \"DSLA. BI-vulna for the tso-un-g\" classifier's or \" the article, or \"Tom-or, least, or \"language class.\nunised data, oror \"t- or \"un-o\" for the t20k1v-S, or \"un or \"a\" in the article B IDBA orh, or the article, or \"X1-2-no-un-un-article", "answers": ["Yes", "Yes"], "all_classes": null, "length": 1868}
{"pred": "Inferase-sentset-categor-1, or R: Yes-un-f-BIBREF3, or-no-come-difference-2, or o-computd-un-dense-dor-R: or-sentence-t-article, BERT is BIB-d-sent-un-tS-tun-ST-d-un-R:-yes-R-BIB-R, and-yes-un-BIBREF3, or BIB-no-un: BIBS-un-b-t-d", "answers": ["GloVe, BERT, Universal Sentence Encoder, TF-IDF, InferSent", "Avg. GloVe embeddings, Avg. fast-text embeddings, Avg. BERT embeddings, BERT CLS-vector, InferSent - GloVe and Universal Sentence Encoder."], "all_classes": null, "length": 3862}
{"pred": "SSI Berts-state-in-t333 yes, Bert-as-BIBRIB:0.", "answers": ["MR, CR, SUBJ, MPQA, SST, TREC, MRPC", "MR: Sentiment prediction for movie reviews snippets on a five start scale BIBREF25.\n\nCR: Sentiment prediction of customer product reviews BIBREF26.\n\nSUBJ: Subjectivity prediction of sentences from movie reviews and plot summaries BIBREF27.\n\nMPQA: Phrase level opinion polarity classification from newswire BIBREF28.\n\nSST: Stanford Sentiment Treebank with binary labels BIBREF29.\n\nTREC: Fine grained question-type classification from TREC BIBREF30.\n\nMRPC: Microsoft Research Paraphrase Corpus from parallel news sources BIBREF31.", "Semantic Textual Similarity, sentiment prediction, subjectivity prediction, phrase level opinion polarity classification, Stanford Sentiment Treebank, fine grained question-type classification."], "all_classes": null, "length": 3861}
{"pred": "Unanswer: no , \"yes\" (yes, or INLINE 19 (i) tags that are or unanswerbooks, yes \"Amaz (INLINE2) (Amaz (INLINE10 or INLINE FOR (i) (Amaz (i.yes: yes, INLINE INLINE0) the Amazon (yes) INLINE (Amaz (e-FORMAR) yes) (i (Amaz) INLINE FOR2 INLINE-INLINE INLINE FORLINE FORLINE (i) INLINE INLINE INLINE INLINE (Amaz INLINE) 1. Uns (yes, INFOR", "answers": ["33,663", "33,663 distinct review keywords "], "all_classes": null, "length": 3305}
{"pred": "Context Taking a concidential and and `s` or \"unfate-based models, yes-unces-line-for or \"unanswer, \"yes-united-un-pos-yline-have-centric or un-answer-un, or \"sur-un-un-context-un, and \"yes, and- yes, yes-3, and and 'un- un-certain and-un-context-un-based-i, \"yes-un-f-un- un-1, or-cent-f and-1, un-un", "answers": ["using tweets that one has replied or quoted to as contextual information", "text sequences of context tweets"], "all_classes": null, "length": 2060}
{"pred": "Yes/refalmosts the unanswered: \"unces\" or \"un\" BIBC-ref: unanswer\". Yes, \"un-comput\" or \"un-answer-\" models: unil-certain-l-\n\n\nIn-veec BI-article: yes or \"unsuper-thagual-un-un-s-un-un-l, or \"un-ward-un-th-th-auto: \"un-th: unanswer-th-thes-un, within-t-unised: un-un-th:", "answers": ["No", "No"], "all_classes": null, "length": 1906}
{"pred": "No: No-bloged-the. Yes, they have a map of bloggers and their least-loud, and unanswerable (blogs, Blogging utilization orals, for the article-land, unanswerable. (e.g) in article-like-article or, in article, or or no). In line, in or, their article-con, articles, yes-s.", "answers": ["No", "No"], "all_classes": null, "length": 1443}
{"pred": "En \"`unanswer: `yes/`(yes) or\" yes (x`\" unstate-`(yes)\" is-3/C` or yes/pre (final`(r1 (L`(system`) or system) on fold-dev`L`un-system) or LWC` or system LST`-`L`L``-L`-L`-system`un-F) or-`yes) on-L`un-L or LSTM`-un-L-system: un-r2-`L`-system-no-", "answers": ["For SLC task, the \"ltuorp\" team  has the best performing  model (0.6323/0.6028/0.6649 for F1/P/R  respectively) and for FLC task the \"newspeak\" team  has the best performing  model (0.2488/0.2863/0.2201 for F1/P/R respectively)."], "all_classes": null, "length": 1541}
{"pred": "DTA (corpus-m_partic on-s: BIBL isecs: yes, un-s-op-based: un-L, the article) is unanswer-s DSC's Dahm: \"tople, unanswer-s coras: DSC: unswer-s-s-s DSC is DAF D H, BIB-s- unavailable, unanswer-s-s-s-s-s: unavailable D-s-s-op-s DURel, un-s-s DTA-s-s", "answers": ["DTA18, DTA19", "Diachronic Usage Relatedness (DURel) gold standard data set"], "all_classes": null, "length": 1908}
{"pred": "170 or \"yes-named\" on the article Bibasedual named arguments or \"yes-tual\" or yes, \"unanswer\", \"yes-name\" is unanswer BIBREF-answer-s BLES-I-named or BIB-1 unanswer, yes-un-related BLE-yes-un-un BLE- and un-t-s B-BIB or BLE-BIB-t-BIB- BERT- yes-2-answer-un- or B-c-BLEBIB-1 or BIBREF-", "answers": ["13,757", "10,898 articles, 17,794 tweets, and 13,757 crowdsourced question-answer pairs"], "all_classes": null, "length": 3704}
{"pred": "KNN, K-speak-spe (e. (Car-speak: Yes/Yes, No/unanswer). In-3 data: K-speak-data.speak: K.\n K- K- K Natural-Yes/No, Yes, un-un. K-ID-as, K-IDF. Yes, Yes. K-spe: (es. K-30-data-data set.\n Yes-spe- is.-speak-spe-the-spe-as-spe-data. (e. B- cars- reviews: K", "answers": ["KNN\nRF\nSVM\nMLP", " K Nearest Neighbors (KNN), Random Forest (RF), Support Vector Machine (SVM), Multi-layer Perceptron (MLP)"], "all_classes": null, "length": 1639}
{"pred": "They does the article-unanswerable-set the given or \"unanswer-context \"the\" is obtain-un-cnn-cited-un-of-s-c does-un- C-\n object is, the extended text-un-1-the-c-un-un-un-un \"\nthe results: the-c-is-un-is and un-un-c-c-c-developing-is and-un-c-\n\nun-indicate-un-un-c-un-c-c-un-c-un-", "answers": ["They use two independent convolutional and max-pooling layers on (1) a combination of the left context, the left entity and the middle context; and (2) a combination of the middle context, the right entity and the right context. They concatenated the two results after pooling to get the new context representation."], "all_classes": null, "length": 2435}
{"pred": "Multi-' `Sln-SBC\"` (` `LGSC `yes` (`BO_CIS`s System,BREF_SLE,SLC) orLISystem, yes,SquareSFC, BLS `L-v`SFC-ArtBABO\\_S` (forfast-gran-key-1)", "answers": ["An output layer for each task", "Multi-tasking is addressed by neural sequence tagger based on LSTM-CRF and linguistic features, while multi-granularity is addressed by ensemble of LSTM-CRF and BERT."], "all_classes": null, "length": 1514}
{"pred": "The \"BERT-based\" isstands is a scientificised, or, \"yes\": The: \" (i.numbered-1\" over-provised and unanswer-I-12 orchestrated, un-b is the C. un-univer- (C.\n\nun-1- samples, orchestr-1-d.B-1- un-I un-un-1) or-1- or-un.\n: unanswer-1) un-1-3-1 article- I--1 is-1 un-1 un-1-", "answers": ["which contains over 45,000 scholarly articles, including over 33,000 with full text, about COVID-19, SARS-CoV-2, and related coronaviruses", "contains over 45,000 scholarly articles, including over 33,000 with full text, about COVID-19, SARS-CoV-2, and related coronaviruses"], "all_classes": null, "length": 2156}
{"pred": "1152033, \"PA, 459:1 (12,1, \"unfit:17,1 (unanswerable10 (SUFER2, Sentro, Q1, WEAK2,1) (unanswer, STRE3,5). In-line,131: 4, ST, un-line,1.1, 5 (un, Q- R1, QUI: un, noun, SUG (un-un-based, un3: strength, SUG (un-based, Q-", "answers": ["26972", "26972 sentences"], "all_classes": null, "length": 3040}
{"pred": "The question or BSB or unanswerable (top, yes: unprovised or concularity or \"yes\" or \"yes, yes, unanswerable or or \"unanswered\").", "answers": ["Unanswerable", "Unanswerable"], "all_classes": null, "length": 2533}
{"pred": "Backed by-only orchestredal \"UN (UNS-bi-related to and model is and-related words-under Back the model-def-related to the down-down, unback-background and background model-str-back-down,-neut-correct through-set-con-down under-Back-back-down-word-tut-f-situ, is back-prov-n-down-correct-s is the-down-str conc-str-back-backoff-switches, providing a simple or-UNK-UN backoff-model-back", "answers": ["In pass-through, the recognizer passes on the possibly misspelled word, backoff to neutral word backs off to a word with similar distribution across classes and backoff to background model backs off to a more generic word recognition model trained with larger and less specialized corpus.", "Pass-through passes the possibly misspelled word as is, backoff to neutral word backs off to a word with similar distribution across classes and backoff to background model backs off to a more generic word recognition model trained with larger and less specialized corpus.", "Backoff to \"a\" when an UNK-predicted word is encountered, backoff to a more generic word recognition model when the model predicts UNK"], "all_classes": null, "length": 4210}
{"pred": "The NUS semantically-levels, unanswer, oracle or the article-mod is (uncondition and the NUS out-DSTC,i and the corpus corpus is unlearned from the article, un. is is used corpus changes on-tow BIBREF or no, the article-generated or the N and.", "answers": ["DSTC2", "The manual transcriptions of the DSTC2 training set "], "all_classes": null, "length": 4820}
{"pred": "B concise, gised: unbalised-onog utilities-inficient of the question: \"unanswer-utilized on-form of-infobox BIBREF2, unigh on the field of the infocellu-attn: un-inf1-infobtised-floon-bal: BI-inf-util: InLINEFORM0:f: \"The article is a post-f-field of the infbox-att of the inf-f-ref on the un-m-on-level of the infobox-G-on the", "answers": ["BLEU-4, NIST-4, ROUGE-4", "BLEU-4, NIST-4, ROUGE-4"], "all_classes": null, "length": 4460}
{"pred": "r-W \"yes or the article0, and INQ automatically-unanswer of: yes, yes, LRU, or r-inline, and-line, INLINE, yes, r, and LRC Bibl, and A, or in real-form, and R, and Ao, yes, r-law-t, yes:yes, yes, r, r, yes, A LRC, yes, LRC, and B, yes, LRC, yes, unanswer, r, yes.", "answers": ["SVM , CNN , GRU , CNN/GRU+law, r-net , AoA ", "SVM with lexical features in accordance with previous works BIBREF16 , BIBREF17 , BIBREF1 , BIBREF15 , BIBREF4, attention-based method BIBREF3 and other methods we deem important, some off-the-shelf RC models, including r-net BIBREF5 and AoA BIBREF6 , which are the leading models on SQuAD leaderboard"], "all_classes": null, "length": 4106}
{"pred": "Sur-Ladd-art-based-f-word-unanswer-per-word-of-2-A-o- and-words, features are:-unanswer-word-word-of-word-un is unanswer for-un-for-word-un-features-word.", "answers": ["POS, gender/number and stem POS"], "all_classes": null, "length": 4719}
{"pred": "L BIBETREF0, the proposed or ( ( or BIBREF0 ( LOTREF, or LATREF3 (unBIBRE0 . along BIBFORMATS FIGREF L, BIB LREF7, L, LOTREF25 and BIBREF1, LREF1 (SEMF) and L-generative answer, L4, or, BIBREF, L. LREF, or, which is unanswer L-referendiment) and the examples are not-ATRE L1, L, the article, are not in, the or and non R", "answers": ["dimension corresponding to the concept that the particular word belongs to"], "all_classes": null, "length": 6182}
{"pred": "The question is yestern (yesform INLINEFORM0 or experimental or in monolingualised-based in-auto-fusion is-marked-by-generated or-domain0 or artificial data0 or Europl0 INLINE0 is un-domain-f-o INLINEFORM0 is the copy-form-d-in-f1-yes-d-by-F: un-source-f-domain-f-fine-trans-f-and-in-FLE-f-f-in-back-in-f-f-f-f-", "answers": ["English , German, French"], "all_classes": null, "length": 4173}
{"pred": "Uno-no-resourced or target-related-un the article-state-res the universal NMT-to-resoured data-res-r-answer-res-opt-systems-un-respective data in-to-res-NMT-un-NMT-mult-source-NMT-res-to-res-state-or-B-the-N-t-res-NMT-optim-the-NMT-Z as-best-best-un-r-r-words-the encoditions-res-the-N-N", "answers": ["Unanswerable", "Unanswerable"], "all_classes": null, "length": 4465}
{"pred": "Dis organisations (yescent) on the number of misleading or Diffusional or cascing onset or-r (or-tup-independent from the article) is:\n\n Question: C-standard or-A and B-to the multi-layer (or-rst-arised: \"multi-layer\"\n\nQuestion and-unf-t-layer, un-up) class-\n\n 2 question-class-multi-layer or-t-\nun-layer-answer-\n\nThe question: topological-unwescort-top-\n\n", "answers": ["mainstream news and disinformation", "mainstream and disinformation news"], "all_classes": null, "length": 4856}
{"pred": "CookCollector-ans (e. [unanswerable – in single-count-based] (Coin \"unanswer\" is un-ad\" is un-un-\" un-un-re-\" is un-\nquestion: two: [ the RIBIBIBMED (e.t' is-un-un-I-score-score-un-re- is:\nun-un-re: un-un-sc-score-re- un- LST-un-expl-un-re: the-un-Ex-8 I-z-I-un-", "answers": ["CoinCollector , CookingWorld ", "CoinCollector, CookingWorld"], "all_classes": null, "length": 4924}
{"pred": "F2 and INLINEFORM0 and INLINE2 F19 from INLINEFORLINEFORM0 and INLINEFOR4 and INLINEFORM0 (INLINE2) is INLINEFORM0 and are used F INF1 and 5 and INLINEFOR3 and INLINE2 and INLINEF0 and INLINEFORINLINE4 and INLINE F-generated INLINELINE1 and INLINEF1 and INLINE1 and INLINE2 and INLINEF3 and INLINEF0 and INLINE2 are delimiter INLINE2 INLINE20 and INLINE F1 and grounding IN", "answers": ["average unique predictions, randomly sample 2000 decoder hidden states at INLINEFORM4 steps following a delimiter ( INLINEFORM5 ) and apply an unsupervised clustering method (t-SNE BIBREF35 )"], "all_classes": null, "length": 4581}
{"pred": "Their article's or the proposed mistakes-en orn ornament-based approach \"BERT (m\" approach of the model-based systematic's (pre-m) samples in the mistake or the B or BERT (ne-hate-t-un-d ornot in hate- (mist or the model, hate- errors of hate or LR-", "answers": ["Data annotation biases where tweet containing disrespectful words are annotated as hate or offensive without any presumption about the social context of tweeters"], "all_classes": null, "length": 4111}
{"pred": "\"yes-ment and en(DIS yes) is conc concise yes-united or (unordered-guided) models are-un concise, unanswerable or \"un (unanswer or or (un-no.no-answer): un or, or un concise or (un-R) or \"short-ment) short or un, no-no-un, or \"yes-no, un\" or \"unanswer-gu-ref-h-h's-h-run conc, BIBREF102-b. \"plan\" can-un-rep-", "answers": ["rther constrain the model on the data structure in order to prevent inaccurate of even contradictory descriptions", "to further constrain the model on the data structure in order to prevent inaccurate of even contradictory descriptions"], "all_classes": null, "length": 4704}
{"pred": "Added performance in a positive or negative or encroot-un ast: [B: unanswer: Article0: or un: Add the proposed functionally is-led or not-word-wise words or-2 or to-inter-word embedings BIBREF0, BIB, the-form or positive or: BIBREF0: is: B transformation: unanswer: BIBREF2: Yes: or BIBREF: Performance: the proposed or concro-the proposed: or the original function: or GlooF: the the objective: the proposed method is the effect ofword", "answers": ["The cost function for any one of the words of concept word-groups is modified by the introduction of an additive term to the cost function. . Each embedding vector dimension is first associated with a concept. For a word belonging to any one of the word-groups representing these concepts, the modified cost term favors an increase for the value of this word's embedding vector dimension corresponding to the concept that the particular word belongs to,", "An additive term added to the cost function for any one of the words of concept word-groups"], "all_classes": null, "length": 6244}
{"pred": "Yes or \"yes or \" or \"unprovided\" for the sameREFREF2 for Wikipedia entity pages, is, INLINE4 . The ground-form INLINEFORM3 and INLINEF future .", "answers": ["Yes", "Yes"], "all_classes": null, "length": 7837}
{"pred": "It is-text-based-text-wise ([s02-c) is broad summarized- (un-tun-tune-)- for-dosed representations. [hyprase-un-1 and-theirw-as-t: is used...). A...: BREF3: ... is: Position... (T-systems are-text-t-t-unanswerized-un-A: ... the ...S ... (yes, and is...\n\n (TREF. (... articles-... is-un-sum) pre-T-t-", "answers": ["Bert model have a maximum length of 512; we overcome this limitation by adding more position embeddings, we insert external [cls] tokens at the start of each sentence, and each [cls] symbol collects features for the sentence preceding it, document representations are learned hierarchically"], "all_classes": null, "length": 4404}
{"pred": "Improvesd or!START@ or'd@ UNK2, BIBREF4 and'Proof of Equ.head unanswered values in the Jacobian function of the Jacob' or softmax of 'endstep. or un!\n\n1,head: or 'yes sub-! and 'step' BIBREF. or ' or or' or B. or'ential or or in ' sub. or of the normalization of BIB isomorphism. or per-!, BIBREF or BIB. or or sub- BIB or or or B or in the proof of the expression", "answers": ["the attention heads in the proposed adaptively sparse Transformer can specialize more and with higher confidence", "We introduce sparse attention into the Transformer architecture"], "all_classes": null, "length": 4902}
{"pred": "The article: \"unanswer\" or \"yes\" or \"unanswer\"", "answers": ["Unanswerable", "Unanswerable"], "all_classes": null, "length": 5331}
{"pred": " Industries (foot-class or un: Is the scientific data unanswered-by-compositive-words are the Bias (or-set) users are a-dev-based-  or (in-dimensionalally-generalize or or-un, un un: BIBIB-pre- B10-sc- K-based language-the-sk-general, city- K- K-0% impro-class-k-words-classifiers-these-class- BIBREF0-in-K- BIB-dev-or- K-sk-based", "answers": ["22,880 users", "20,000"], "all_classes": null, "length": 4160}
{"pred": "Instance-diff-t-R: yes (unanswerable or noisy-o and re-use-re (unans-t) for Pearson-t at-t-answer-items are experts are likely-do-stand-t-10-t-stand-y-no-art-t-no-diff-noise and-un-i-re-s-down-standards-annotations are for-no-pat-tical,  is un-t-no-diff-re--t-art-t-score-t-t-t-un", "answers": ["sentence"], "all_classes": null, "length": 4369}
{"pred": "Har concise: personal comments pre-certained conversation pre-hocod-unanswer-pree-event-wise-ref-1, or-event of-h-r: un-h-A or-ertain-h-mod-s-question: pre-happised-1-1 or are-h, the-h Is-h-l-h-h-h-un-mod-art-un-cont-question-or-event-h, the pre-existing:c-event-art. The article-based-h-mod-der-art", "answers": ["The Conversations Gone Awry dataset is labelled as either containing a personal attack from withint (i.e. hostile behavior by one user in the conversation directed towards another) or remaining civil throughout. The Reddit Change My View dataset is labelled with whether or not a coversation eventually had a comment removed by a moderator for violation of Rule 2: \"Don't be rude or hostile to others users.\""], "all_classes": null, "length": 4779}
{"pred": "Dates INLINE_0 and INLINE_0 is or INLINE_1 or_NO and INLINE_plea (plead and INLINEFORM0) is or \" or INLINE_INLINE_0 is INLINE_1 or INLINEFORM_INCO_ cases INLINE_0 and INLINE_INVER and INLINE_INLINE_NO and INLINE_INLINE_0 is or_0 is or INLINE_1 is or INLINE_1 and INLINE_0 and INLINE_INLINE_0 are orINLINE_NO_1 and INLINE_IN", "answers": ["build a new one, collect INLINEFORM0 cases from China Judgments Online"], "all_classes": null, "length": 4109}
{"pred": "Theyup to be-un- or-unset-to-translated-to-un-form-style-transfer-un-yes- they (yes to-un to-un as-un-un-for-G EC2 or un-un- check-un, and-un-to-theirereset-un-un-un-or-un-un-these- or-un-they-un-", "answers": ["Unanswerable"], "all_classes": null, "length": 4572}
{"pred": "Un-s-size or un-S\n Yes or-t-t-L-POI-ARS-unanswer or-un-un-L-un-S.\n\n\n Question: A- or or or-RL-RL-un-PO-RL- or-ROG- or RL-S- L-AR-RL-being-S.\n question- or-art-AR-AR-S and ARL-S-unper-L- our-PO-AR-S-PO-AR-S- or-L-S-R-un-", "answers": ["absolute improvement of 18.2% over the Pointer-Gen baseline"], "all_classes": null, "length": 4091}
{"pred": "Using a yes ornamental or, \"yes\" or not mentioned:\n\n Yes, yes-type or B.", "answers": ["50 human annotators ranked a random sample of 100 translations by Adequacy, Fluency and overall ranking on a 5-point scale.", "adequacy, precision and ranking values"], "all_classes": null, "length": 5344}
{"pred": "Joint model is relevant to the question or \"yes (to the article or) unanswer or \"yes\") is  or \"w-S-over-answer-con\" or \" _ model is consistently assessed on the article. (B-based\" (yes) on the visual-model (un-\"\") to the Inception-different to the output-to or (to the output- (un concise-no  or, the article is or the model (un-to the Article\".", "answers": ["visual model is based on fine-tuning an Inception V3 model BIBREF1 over visual renderings of documents, while our textual model is based on a hierarchical biLSTM. We further combine the two into a joint model. , neural network models", "Inception V3, biLSTM"], "all_classes": null, "length": 4217}
{"pred": "The MMT cor-105: \"yes: un-re8-un-1 INLINE2 or strong-M2MT-5: \" or \" un-Mos-the-M-M3, V-transl-Mos-3, or or MIR, or low-un-1-1-un or-un-M10-M2 or R1: or SE-un or M2, the MMT, or M2, the proposed-the M-or or and low- or MT models, or M1 or M1: the M1-M", "answers": ["pivot-based translation relying on a helping language BIBREF10, nduction of phrase tables from monolingual data BIBREF14 , attentional RNN-based model (RNMT) BIBREF2, Transformer model BIBREF18, bi-directional model BIBREF11, multi-to-multi (M2M) model BIBREF8, back-translation BIBREF17", "M2M Transformer"], "all_classes": null, "length": 4542}
{"pred": "Number of differentiagnodified L-standard network analysis:  und-level-reference on-layer-based: Global features:10.3 Global: 3, L-diff-lern-class, L-t-networked-layer on-s0- B-s0, up-layer: features- L-layer for undirected-layer, caset-m-l: social features-dis-twe-un-l, the number of ment-l: Layer: S-K-layer: en-c-information-feature-layer: Layer:", "answers": ["Number of Strongly Connected Components (SCC), Size of the Largest Strongly Connected Component (LSCC), Number of Weakly Connected Components (WCC), Size of the Largest Weakly Connected Component (LWCC), Diameter of the Largest Weakly Connected Component (DWCC), Average Clustering Coefficient (CC), Main K-core Number (KC), Density (d)"], "all_classes": null, "length": 4906}
{"pred": "Lookup-based-decital-yes-10.0-1 in the medications or frequency question Medical (Medical BLS-based-table-ag-1-extraction or frequency-de-me-1.1-2 for0.1.\n\n Baseline-question.0. yes.1, or a medication-1 for the1.\n\n\nYes: Medication-un-extra-1,1, encor1, extr-l-dose1. B-11.\n\ndosk-1.0, extraction and extr,\n", "answers": ["QA PGNet, Multi-decoder QA PGNet with lookup table embedding", "QA PGNet and Multi-decoder QA PGNet"], "all_classes": null, "length": 4600}
{"pred": "Rel-ranking_of-top (average topic entity-of-A1, does it? (The article: Relation-wise-ranking-answer: The article focuses the entity-ank score or-top-of-  or-of-the best-of-h-f-un-art-the model-of-rankThe-ranking-the simple of-A: < [r-1> and constraint-top-of-of-A-of-the-A-h-link- on the article-of the proposed-h-H-of-im-", "answers": ["answer questions by obtaining information from KB tuples ", "hierarchical matching between questions and relations with residual learning"], "all_classes": null, "length": 4527}
{"pred": "Gradref-formula off-formatted-sight (yes or in the-former-s or RREF6 off-form-ing (formatted) form) (off-tic- BIBREF (un-form S4 (formus in the form-form, for text-distribution of RIBREF3-no) in-text-form forward-best R-form-form-form (unpreferred for the algorithm in the RL can be improved on the algorithm of the policy formal-form of form-form-Sib.\n\n\n\nSBBIB", "answers": ["BIBREF7", " reward learning algorithm BIBREF7"], "all_classes": null, "length": 4841}
{"pred": "They- concreative conciliation-wise-yes-Yes or or \"Yes or \"Yes-t\" (pos\" model is unanswer-was 'yes\"\nYes is unanswer in this concaption, unanswer- unanswer: unanswer, BERTI-Neid is the top- in \"Lewas of factoid this experiment, They did, they under, they, in \"experiments, They questions, They- LAT, they is 5 experiments, un, or: BIB-12 N-text-like 'yes, LAT, fine-t-Q,", "answers": ["BioASQ  dataset", "A dataset provided by BioASQ consisting of questions, gold standard documents, snippets, concepts  and ideal and ideal answers."], "all_classes": null, "length": 6810}
{"pred": "Semarky is orchestration scores for un-rank scores are used", "answers": [" higher tiers of the pyramid", "following the pyramid framework, we design an annotation scheme"], "all_classes": null, "length": 4771}
{"pred": "The question: \"word importance (e. (a, SOOQs) unanswer\" (un) or (e (unimportant) \"important-translant, Word-sequence models: unimportant:important (SOO-C) approach) in the Attention)\". Important (f, un) importance (e, a) un (N, importance) un) (important, unimportant) un, (un, I, SO-un) (a, SO-black-expl)\".", "answers": ["Given the contribution matrix, we can obtain the word importance of each input word to the entire output sentence. ", "They compute the gradient of the output at each time step with respect to the input words to decide the importance."], "all_classes": null, "length": 4253}
{"pred": "The-un-test-yes, un-given-sarc-g-sarcasmara or-of-sarcasm,un-sarc-yes-sarcive-un-score-state-un-sarcasm, BIB-yes-un-sarc-sarc: BIBREF-un-no-un-un-answer-test-un-unanswer-un-un-bas and-un-F-sarc-un-s,un-un-un-un-un-un-no-un-arc-no-no-S", "answers": ["BIBREF9 , BIBREF8 ", "BIBREF9 , BIBREF8"], "all_classes": null, "length": 4855}
{"pred": "Improised or \"unanswererised\" or \"un\" or Equtrefesting is yes. (un-improposed or \"yes\" topprolearning-as or on \"un\" or Improised-based superised or \"un-exam20-experiments\" in-these-form of-ex-tud, text-based or rein-formed-reward-as in-a-un-p-form-formulation, and the-inst-learning-un-as-form-re-class, and un-form-un-inst-t", "answers": ["Low data: SST-5, TREC, IMDB around 1-2 accuracy points better than baseline\nImbalanced labels: the improvement over the base model increases as the data gets more imbalanced, ranging from around 6 accuracy points on 100:1000 to over 20 accuracy points on 20:1000"], "all_classes": null, "length": 4880}
{"pred": "Multel BIBREF, the 5-way multiple-hops oracles that the article (un-hop, or the first, or, or QIWel, or \"IS:5-best models, in the article or-s, GUI-type, or-21, the multiple-end-way, is-s (un-by, or or YES, are-t, or-R-evalu-the- B-Wel- M-hops, or the pr, the building or the flat, the2, the method, or-el,@-models", "answers": ["MULTIPLE CHOICE QUESTION ANSWERING", "multiple-choice"], "all_classes": null, "length": 6396}
{"pred": "Wise-surgle, or the givenjunctional (yes-s (Dated or unprovide or BERT's-no-26 or \"un (d\" or H, or BERT) is in-emans,  is-s BERT, in (1, no) or sams) or given) or-d, un- or set-t, or E, and the model is the best, or the BERT-un or E, in the work, or,\n\n", "answers": ["Waseem-dataset, Davidson-dataset,", "Waseem and Hovey BIBREF5, Davidson et al. BIBREF9"], "all_classes": null, "length": 4090}
{"pred": "Transsight (unsafe as the article un-any: Yes, RNN-un-results in question: Yes (River, RNN (e-unimportant, Rig-state: Eras (Yes: (art-s in the behavior-finding in-the contribution of RAS on-un-s: R (e) (R- un- Yes: English-Frequency-un) models) as R-h: (so) or, Attention (yes, theys).\nun- Contribut: they analyze-un-find important that: They use-un, they", "answers": [" Transformer BIBREF1 model and the conventional RNN-Search model BIBREF0", "Transformer, RNN-Search model"], "all_classes": null, "length": 4240}
{"pred": "\"Meent-ised keyphra-out-increation from the scientific-form\".\" is (or-orthon:\".", "answers": ["average unique predictions, illustrate the difference of predictions between our proposed models, we show an example chosen from the KP20k validation set"], "all_classes": null, "length": 4576}
{"pred": "Eval Multi-coolref Multi-ment220-labeled-scores is the article or corpus-con-size-wise-ind: unprovised (orchestral-multi-based-c-size of concept-lim; Anset- Ans (INLINEREF-ment-re-c-skc is) is proposed-art-reference-pil-c: un-pro- or-p- An-An-An-ag-IN-LINE-agre- Ante-pil-Answer- Annotation- Annotation-sub-des: or", "answers": ["Answer with content missing: (Evaluation Metrics section) Precision, Recall, F1-scores, Strict match, METEOR, ROUGE-2"], "all_classes": null, "length": 4263}
{"pred": "They-entries of deep-layers-wise LSTM and-no", "answers": ["Unidirectional LSTM networks with 2, 6, 7, 8, and  9 layers."], "all_classes": null, "length": 4286}
{"pred": "Both or \"super-tart--lci. orchestr or--un-un-XLI-ent-XLI, or the super-XNLI, but-XNLI, or-XX-Nor-art-g-X- or-LI-XN-L, are-X-X- or-Language-B-art-X-ES, isop-li, or-or-original- or-N-Language-X, or-X-X-un-g-or-of-X-t-LII N-X-L-", "answers": ["Yes"], "all_classes": null, "length": 4073}
{"pred": "Know Net-based Machine AIDR-11 , RHOYNAG2. (yes or \"KAR\". of-\" INLINELAR is INLINEFORM0-R R-3-no-W4 , \"im.0-att-REF5 . R- R3, yes, UNLINE- un- the KAR is R-not-un.1-un-un- \"model\".", "answers": ["Lexicon Embedding Layer, Context Embedding Layer, Coarse Memory Layer, Refined Memory Layer, Answer Span Prediction Layer"], "all_classes": null, "length": 4133}
{"pred": "Improving or Reward or generating models.", "answers": ["ethical questions about generating sensational headlines, which can be further explored,  improving the sensationalism scorer, investigating the applications of dynamic balancing methods between RL and MLE"], "all_classes": null, "length": 4104}
{"pred": "The question is \"dozens\" from the un's perspectives in BIBREF:question.", "answers": ["attributes are determined by human viewers and their impressions of the characters, and are correlated with human-like characteristics"], "all_classes": null, "length": 5136}
{"pred": "Reuters-2 or \"MSW_{B, unanswer_b\" orMSBIBB and MSB, or NO_{Bow (BIB_B, \\{\\lbrace or Reuters_\"yes_ or 2-3, or toB and \\Reut answer B and, PB and \\BIBB_{R-B, Reuters, MSB and \\l and MSBB and \\l to the Reuters-or \\B and BO and  PB and \\BIB_B} Reuters,}  R_B and MSB", "answers": ["Reuters-8 dataset without stop words", "The Reuters-8 dataset (with stop words removed)"], "all_classes": null, "length": 5147}
{"pred": "Accomised yes-yes or, unanswer: \"yes\" (unlabeled) or (yes, BIBREF1, BIBREF16, BIBREF1, BI (article-loop-un, BIBREF1: unum) is unlabel un-loop-no BIB, BIB, un-filter-BIB).", "answers": ["significant improvements clearly demonstrate that our approach is effective at improving model performance", "By evaluating the performance of the approach using accuracy and AUC"], "all_classes": null, "length": 4489}
{"pred": "The exam of-unbiased_answer-s-d-misced-B-errors (t, unanswerable). Yes D, examurised-d or-h, hate, hate or neither BERT-the-unas BIBREF, they-t-bi-BIB, or-ne-uling-ne- and, BIBREF16-rac- BERT16, Bias-BIB- un-h, BERT, BERT-reg-BERT, and BERT B-EL-sy-ref-BIB, s, mis-", "answers": ["The authors showed few tweets where neither and implicit hatred content exist but the model was able to discriminate"], "all_classes": null, "length": 4119}
{"pred": "SimpleQuestions: \"yes\" or-to-to-al, the authors of or the un-provided top-ofl(1 $<$ question, state-of-of-KBREF.", "answers": ["SimpleQuestions, WebQSP", "WebQSP, SimpleQuestions"], "all_classes": null, "length": 4524}
{"pred": "Grammatical GEC (un-unsk)", "answers": ["grammatical, spelling and word order errors", "spelling, word order and grammatical errors"], "all_classes": null, "length": 4579}
{"pred": "Crawlicles: or generate non-inter situational words, or INLINEFORM1, yestle unsupervised-based on the generated data are generation: INLINEFORM1 or INFL are unanswer: \"situlet\" INLINE S-score non-answer (un, INLINE1 and \"s\" is Sent is or SINLINEFORM1 or in INLINE, IN, or generate the authors generate.", "answers": ["They developed a classifier to find ironic sentences in twitter data", "by crawling"], "all_classes": null, "length": 4599}
{"pred": "Global-based-article-al: Yesline-based-of-unanswer-attu or long-of-the-local and att-unanswer-un-label-in-the-un-prov-the-label-generally-or-un-art-un-does-un-the-label-un-label-label-un-un-attention-of-ne-un-un-un-of-un-the-article-un-un-un-label-of-the-un:un-extract-the-un-un-un-un-", "answers": ["global (the whole document), local context (e.g., the section/topic)", "global (the whole document) and the local context (e.g., the section/topic) "], "all_classes": null, "length": 4287}
{"pred": "Know-rel2: or-ranked-to-1-ab-the-system: or-based question. The question is-E\n\n\n\n\n\n\n\n\n\n\n\n Does the proposed relation:\n\n\n\n\n\nb- or: or\n\n\n\n\n\n\n (yes- or KB- or-E-1-based-the article\n\n or\nun- the-based:\n\n\n (KB-ans-to-KB: B-\n\n\n\n\n\n\n\n\n\n\nun-based\n\nun- or\n", "answers": ["Knowledge Base Question Answering", "Knowledge Base Question Answering "], "all_classes": null, "length": 4521}
{"pred": "They used \"c article-based LDA and WCPP answer for yes-LDA and used to generate topics for recommendation systems, e.g, topics, WWW, to answer.", "answers": ["the LDA approaches to recommendation systems and given the importance of research, we have studied recent impressive articles on this subject and presented a taxonomy of recommendation systems based on LDA of the recent research, we evaluated ISWC and WWW conferences articles from DBLP website and used the Gibbs sampling algorithm as an evaluation parameter", "discover the trends of the topics and find relationship between LDA topics and paper features and generate trust tags,  learn a LDA model with 100 topics; $\\alpha =0.01$, $\\beta = 0.01$ and using Gibbs sampling as a parameter estimation"], "all_classes": null, "length": 4322}
{"pred": "Yess-point-unanswerable or the question MRC models being the knowledge bases INLINE-question-answer-attention-attention-NET1-no- or do MRC answer: explicit general knowledge-state-given- Explicit and TAR3 and general or any general-no conc-attention being- andor-att-board-attention-2-the knowledge-general knowledge en-att-general-ex-att-att-h-state-att-general knowledge-aid-att-attention-end-know-generalatt-attention-att-general", "answers": ["Yes", "Yes"], "all_classes": null, "length": 4127}
{"pred": "Iis the question \"yes (un-answer (W) or- 4. E- 20 minima inas in the WER, 2%-  gend-focus-trans-un-W- WER, un-is the- W= (un-is-W- 3-WER (f) =-is (un = WER, W-W- W- W- W-  E- W- W- W- W-is the W- W- W- un- W- W- WER (W- W- W-2- W", "answers": ["Women represent 33.16% of the speakers"], "all_classes": null, "length": 4055}
{"pred": "Basotion for FY-Which questions questions that answer score in FACTAID (Question-type) isovers's) is the top-4) is unanswer, unanswer-Yes, unanswer \"unanswer is unanswer in concise or not, unanswer is: \"unanswer. (factoid) is:BIB, yesBERT BIB or, yes, system is answered unanswer questions, a concise_asq) system LAT unLAT is unanswer-yes: unanswer-3, yes answer is 'LQA) is: unanswer-", "answers": ["by answering always YES (in batch 2 and 3) "], "all_classes": null, "length": 6817}
{"pred": "4(BERT-based system' yes-type\" or \"Yes\" or: \"un. (unanswer\" for the original, or scores for the top-10, and \"un' unanswer-unanswer, unanswer in orchestralized: Yes: \"unanswer-unanswer-unanswer- or 'unCCP-1\" un-question-Q-3 system (in the 1-un-un: un- un-1: un- un answer or: un B-Q-type: Yes-F-QA1: Focus-un's un", "answers": ["0.7033", "0.7033"], "all_classes": null, "length": 6810}
{"pred": "BLE rate (unanswer\"s in generation or \"uninformal (e.vent). unanswer unground irradescore or uninfer (unanswer and error) or flu (e. orw-l).\" or\" un-like, event-f\".\" yes.no\" (un).\" sloud. Is \" sloud (fact-translating- unset) (un-s un-un-un-sc- scorew\".\n\nscore- BIBREF-un. un-answer.\nYes (un-based. un-un, un-w", "answers": ["BLEU , NIST , METEOR , ROUGE-L, CIDEr , evaluation script, automatic evaluation, human evaluation, minimum edit evaluation, word error rate (WER), factual errors and their types, fluency issues, acceptability of the output for production use in a news agency", "BLEU, NIST, METEOR, ROUGE-L, CIDEr"], "all_classes": null, "length": 4738}
{"pred": "Multual LB (BIBT BIBIBREF0 unanswerable0 ) is used for the question classifier, meaning-based context-based on the BIBSECURE BABBBC ) in the terms of the context of the BIBSON1 (BIBS) and the A BIBREF0 devi1001 BIBREF0 BIB C characterspace contexts are the A e.word BIBREF-based class (un) is the BIBD11 for generali1 BIBREF0 (un-based on the BIBIO class (context, using", "answers": ["AllWords model by counting the frequencies of all the remaining words and training a multinomial Naive Bayes classifier"], "all_classes": null, "length": 4177}
{"pred": "Two or \"yes, yes\". (e) orally, \"discusses a general, \"1\", BIBREF11, concise; or \"un\", \"dis, yes, is classifying, \"or \"dis \"dis\".", "answers": ["Tweets related to CyberAttack and tweets related to PoliticianDeath", "cyber security (CyberAttack), death of politicians (PoliticianDeath)"], "all_classes": null, "length": 4481}
{"pred": "Logic and concised from concil\nA. RQA, yes, \"Looking\" (entropy-1: query entailment, yes, or-set-answer1: conc QA, question (INLINE, conc, no-answer, and R2, yes, and the RQ TRE, article, and DCA: entailed: RQA, and the IR+ answer, yes, yes, yes, no, un NIRE, answer: yes, yes, un and RQA: RQ, no, yes, R, RQ:1, no", "answers": ["Logistic Regression, neural networks"], "all_classes": null, "length": 7257}
{"pred": "Conded-uplet-to-to-n-set-to-1-dimension-t-1-system- Seq-no-6: P-to-encodirect-un-1 (t-un) encodod-to-no- Se-2-g- un- is-cond-record-dim-dim-1-g-require-7-g-dim- Seo-row- Seq-i-1-the-L1-cond-1-CC-del-1-g-dim-a-record-art-encod-", "answers": ["Conditional Copy (CC) model ", "delayed copy model (DEL),  template system (TEM), conditional copy (CC), NCP+CC (NCP)"], "all_classes": null, "length": 4746}
{"pred": "Instrumented and jointalisation and, unsuperised utilised, In-1, the proposed in the question: In similar, \"invertible during the condition, unsupervised, inverted, \" Jacob​-der similarity. Invertible condition for the in un-t similar similarity, no and. Unvertimated and supervised pre-providentible and discrete properties, yes-invertible, un-in-born-invert In (Eq.pending) Inverse behavior, and the similar projecting. Inline-1 and the inference, and the marginalized and", "answers": ["The neural projector must be invertible.", "we constrain our neural projector with two requirements: (1) INLINEFORM0 and (2) INLINEFORM1 exists"], "all_classes": null, "length": 4323}
{"pred": "Loggedi. \"yes\" isyes (e. or \"Graph\" is yes or the article's, \"unified\".", "answers": ["probabilistic model", "Logistic Regression, Multilayer Perceptron"], "all_classes": null, "length": 4475}
{"pred": "The size of IN: INLINE_INLINEREF0 ordea-based on the average orlaw INLEAJREF0 refers: INLINEFORM0 .", "answers": ["100 000 documents", " INLINEFORM1 cases"], "all_classes": null, "length": 4104}
{"pred": "Crowloutur b, or BIBREFBIBREF , \" the text-answer requirements were most likely on-based-text-form-texts-un 2: Crowl-related alternatives were or BbREF- BIB-un-common-text-text- i-text-based text-based- text-text-text-based-model. (yes-text-based-text-based- yes, no-text-text- BIB-text-text-text-text-text.", "answers": ["The data was collected using 3 components: describe a series of pilot studies that were conducted to collect commonsense inference questions, then discuss the resulting data collection of questions, texts and answers via crowdsourcing on Amazon Mechanical Turk and gives information about some necessary postprocessing steps and the dataset validation."], "all_classes": null, "length": 4536}
{"pred": "Data-mach's method (yes-no orchestr2 and the authors proposed their own orchestrised \"data Data RefBIBREF0 or the-to-14.S system (Data-m(data) and Data-NMT (INLINE0 Data) and (unigure  or 16 and-the authors) systems in the article they NMT-2 and the bib3-1 (0 BIBREF0 and the baseline INLINE-form3 and Data P NMT (0 and (Data and SMT) BIB0 SMT) the authors INLINE", "answers": ["Back Translation, Mix-Source Approach", "data augmentation"], "all_classes": null, "length": 4123}
{"pred": "Out 'unanswer\": \"unary\" is 'yes\" isomeranswised pich \"yes\" (sever\" in terms\" informat: yes, unanswer is \"unswer: \"unanswer\".", "answers": ["Metric difference between Aloha and best baseline score:\nHits@1/20: +0.061 (0.3642 vs 0.3032)\nMRR: +0.0572(0.5114 vs 0.4542)\nF1: -0.0484 (0.3901 vs 0.4385)\nBLEU: +0.0474 (0.2867 vs 0.2393)"], "all_classes": null, "length": 5151}
{"pred": "Character-AED and Dh BIBE is \"O Arabic offensive class (yes \" yesA\" yesa X-Ay BIBREFU is \"O offensive\" is the author of-un BIB \"yes \"is\" (BIB\" class, the MEnArabast\" is the\" is unbiasedh\"\", \"dA, yes-A Khat-A O BIg-A and Msg or BEditing \"A- (B) the KM is unBABA class deets P-A BIBREF BI is concular and (", "answers": ["Frequent use of direct animal name calling, using simile and metaphors, through indirect speech like sarcasm, wishing evil to others, name alteration, societal stratification, immoral behavior and sexually related uses.", "Direct name calling, Simile and metaphor, Indirect speech, Wishing Evil, Name alteration, Societal stratification, Immoral behavior, Sexually related"], "all_classes": null, "length": 4566}
{"pred": "The un-adised or games that of the the policy better, and for each-to-bet Coin-Ex-Ex-ad-their-answer, the learned better-2 B, un- the Go-Ex-Ex, yes-un, Cook-Ex-Ex-Ex, the game, the introduction- 2, Coin-based-b-Ex- Ex-Ex-d-sc-d-Z-Ex-ad- the-e-z-the-K-ad- the authors, the authors compare-the-the- with-Ex-Ex-Ex,", "answers": ["promising results by solving almost half of the unseen games, most of the lost games are in the hardest set, where a very long sequence of actions is required for winning the game"], "all_classes": null, "length": 4964}
{"pred": "Invested and Biasal: BIBREF1. G2 =  Pundered and AS-biased-referred and BIB BIB organisation, the data-un (P.-  Analysis and N-bi-  G2-  rank-  =  BIBi and  G2-  rank-  P-pipeline Gender and gender bias- P-  and P- P-B-ASR-BIB,  yes  and-  BIB (yes  Gender and G-er on G-  and G2- Gender and G P-B", "answers": ["create fair systems", " broadcast recordings are also a valuable source of data for the speech processing community, recent works uncovering gender bias in several natural language processing (NLP) tools"], "all_classes": null, "length": 4063}
{"pred": "They are \"Yes\" or significicised posts.", "answers": ["logistic regression models", "logistic regression models based on unigram bag-of-words features (BOW), sentiment signals (SENT), the linguistic features from our earlier analyses (LING), and combinations of these features."], "all_classes": null, "length": 4208}
{"pred": "Yes or is unanswer for \"yes (unset-no- article model is unanswer-of).", "answers": ["No", "Unanswerable"], "all_classes": null, "length": 4181}
{"pred": "Messageising question-wise, \"yes\" or \"unanswer-yes\".", "answers": ["doc2vec , CNN, DAN, Tree-LSTM, DRNN, LSTMN, C-LSTM, SPGK, WMD, S-WMD, Semantic-CNN, LSTM-GRNN, HN-ATT"], "all_classes": null, "length": 4169}
{"pred": "They under-unanswer-one-pone (e.unanswer-refers in the super-question).", "answers": ["They measured the under-translated words with low word importance score as calculated by Attribution.\nmethod", "we ask ten human annotators to manually label the under-translated input words, and at least two annotators label each input-hypothesis pair"], "all_classes": null, "length": 4246}
{"pred": "Wikipedia's-unset", "answers": [" `Conversations Gone Awry' dataset, subreddit ChangeMyView", "An expanded version of the existing 'Conversations Gone Awry' dataset and the ChangeMyView dataset, a subreddit whose only annotation is whether the conversation required action by the Reddit moderators. "], "all_classes": null, "length": 4718}
{"pred": "Yes (yes or \"yes\" orchestrised corpase3 corpus corpus (Yes: \"yes\" or \"yes\"\" or \"no\" \"no\" or \"no\" or \"unsuperised\" or \"un\" (INMT) or \"ESEME1, un\" or \"Yes\" or \"INLINE1\" \"yes\" is\" yes\" or \"yes\" \"unyes\" or \"un\" (unsuper\" or \"un\" \"Yes\" or \"Yes\" or\" \"unsuper\" \"un\" or \"un\" or \"un\" or \"unw", "answers": ["No"], "all_classes": null, "length": 4117}
{"pred": "Eurolapse yes-yes or mono-in NMT15 and INLINEFORMREF is used for domain-ad in the article's fine-fus-Euro-no-mon-f-pat-un-mon-in-in-d corpus, or used for-domain (un-adapt IN-INLINE-marked-no-in- artificial-source is that mon-un-and-form-in-form-un-un-n-domain-ad, and se-in-experiments-IN, is- BREF4- and the best-", "answers": ["Europarl corpus , WMT newstest 2014, News-Commentary-11, Wikipedia from WMT 2014, Multi-UN, EU-Bookshop, Rapid, Common-Crawl (WMT 2017)", "Europarl tests from 2006, 2007, 2008; WMT newstest 2014."], "all_classes": null, "length": 4184}
{"pred": "Yes' or \"un-formula BIB26-BIB (unyes or any post's-set- yes or were orally (un- BIBREF and Mikol or BIB-set) or RFT or BIB-BIB or BIB7, BIB-un in this or BIBRE or BIB or BIB, or BIB, BIB-B and as BIB: Create-BIB00 or BIB BIB, or BIB: is, is un-B or BIB or BIB- BIB and BIB or BIB.", "answers": ["No", "No"], "all_classes": null, "length": 4484}
{"pred": "A question-based-FA: unanswer-form is not (unanscience BIBF0 (un-sp-A \"BIB- is- Co-oc-INLINEFORM3-2).", "answers": ["frequencies of the other words which occur with both of them (i.e., second order co–occurrences)", "The matrix containing co-occurrences of the words which occur with the both words of every given pair of words."], "all_classes": null, "length": 4271}
{"pred": "Precseverlaterly0, INLINE_INLINE_0, INLINEYER0, INLINE_pleas, unanswer-pro-9, INLINEFORM3, INLINEBO, yes_no_0, INLINEFORM0, INLINEVER3, yes0, INLINE, INLINE1, INLINE1, m, INLINE, INLINE, INLINE1, INLINE, the yes-RE, is, is, yes- is, yes, yes, yes, LRC, yes, is, N, precision, INLINE, is the interaction between LRC", "answers": ["precision, recall, F1 and accuracy", "precision, recall, F1 , accuracy "], "all_classes": null, "length": 4101}
{"pred": "Unanswer:tionally, or unanswerment orbits are unquestionedab, unsupered ornaments (yes or unification scores are unavailable). Yes (TAC is unanswer un-attany or results or correlation with un-unised or they are concured to).", "answers": ["Yes", "Unanswerable"], "all_classes": null, "length": 4770}
{"pred": "Not yes-no-mised-answer-label-diffy \"un-mod\" scores-difficulty is-art-label-label (or-label-data-art-un-system-answer-stand-mat-B-model-label-diff-mod-quet-pat-diff-labeling is.label-m-mod-m-diff-label (or-sentence-label-b-label-art-exper-mod-label-b-label-art-pat-diff-label-B-label-label-label-b-diff-label-m", "answers": ["Annotations from experts are used if they have already been collected."], "all_classes": null, "length": 4377}
{"pred": "Appro BIBS-n B-un-no- B (yes or- is \"un-you is, questions, or BIBSC, yes, script-na or the answer to the answer of the,  yes- le concise- yes BIBREF2. The answer-texts BIBREF, or \"text-based questions-b, yes or the answer-based text- i, yes, or BIBREF-B-15 questions, yes-a, do,yes- (BIBREF0) or \"nBIB, yes, do the un, BIBREF", "answers": ["13,939"], "all_classes": null, "length": 4489}
{"pred": "Yes orn-based on AP for 240. \"unised\" or \"corresponding to-Dosk-me by the article straps with 2-based-de on the B \"un-based 2 on-1.", "answers": ["Yes", "Yes"], "all_classes": null, "length": 4592}
{"pred": "Yes or \"Givenomised-BLEUBREF16: Field in the article-unanswer-Gated data-to-attention\" or,om the model withGomom2-omimom0 or-omder (un)m) o-field of the pre-BRE-BW-omom, orom-un-unREF- field-omom-unavailable-B-om-no field-omomomom-omom oromomomomomomomom oromomom-data-unomom0-unom-omom", "answers": ["Yes", "Yes"], "all_classes": null, "length": 4457}
{"pred": "RO utilize or-unanswerable \"extractive or not answerable is\". (suml inset-unanswer-standard-AMR-un-unform scores are used by unanswer provides-un-un-un is not-answer \"un-un-un-extract- or-3 or-un-1 scores or-standard-1-un-d-un-un-un-un-un-AMR-un-un-un-IN-un- un-AMR-un-d-un-un-un-un-1-un-un-un-", "answers": ["Quantitative evaluation methods using ROUGE, Recall, Precision and F1.", "standard ROGUE metric, Recall, Precision and INLINEFORM0 scores for ROGUE-1,  INLINEFORM2 scores for ROGUE-2 and ROGUE-L"], "all_classes": null, "length": 4395}
{"pred": "NaiveCNLFM0 , INLINEFORMBIBREF2, which is a 2: \"Fm0, BIBL2, or any: BIBLE:\n\n\n\n (Art: \"\n\nF-F0, and L\nF:\n\n\n:\n\n: \"C, BIBM\n\n— Basic:\n\n\nF:\nBases:\n\n\n:\n\n\n\n\n:\n\n\n\n:\n\n:\n\ndeveloping\n\n\n\n\nC:\n\nfrom\n\n\n\n\n\nD:\n\n\n", "answers": ["(1) Naive, (2) mSDA BIBREF7, (3) NaiveNN, (4) AuxNN BIBREF4, (5) ADAN BIBREF16, (6) MMD", "non-domain-adaptive baseline with bag-of-words representations and SVM classifier, mSDA, non-domain-adaptive CNN trained on source domain, neural model that exploits auxiliary tasks, adversarial training to reduce representation difference between domains, variants of deep CNNs are used for encoding images and the MMDs of multiple layers are jointly minimized"], "all_classes": null, "length": 5063}
{"pred": "Unoped-no (yes (for arXiv yes or unanswer or unanswer-no) or Inception-based-unanswer (un) is orals for visual-yes or-yes or 51 or  for  yes or un-no is unans- Inposed on yes  (B-no unanswer or rejected (unstate-un- Inception- yes in  for  for  for the yes  yes forfe- Inception is unanswer- or un-C (yes- or  yes-un- un- 0  for  for  yes Inception for", "answers": ["59.4% on wikipedia dataset, 93.4% on peer-reviewed archive AI papers, 77.1%  on peer-reviewed archive Computation and Language papers, and 79.9% on peer-reviewed archive Machine Learning papers"], "all_classes": null, "length": 4203}
{"pred": "Word2-May-ZNS1 – unprovised INFORM2 – yes BIBREF2-prov-Mayer's \"unanswer\" is-no or \"INLINEFORM2-Me Ford-like the-answer\".", "answers": ["Skip–gram, CBOW", "integrated vector-res, vector-faith, Skip–gram, CBOW"], "all_classes": null, "length": 4259}
{"pred": "US dataset is on aised news en utilisationalised for \"US dataset D, or US dataset for the question: Unsafe-organesy-c-causide-bialscase-w. (US-un-caus: \"US, or US-A: US dataset for both-al for the news-sized as for-c-facts-c class-c-sc-core-c: for-sc-c-sc.", "answers": ["US dataset, Italian dataset", "US dataset, Italian dataset"], "all_classes": null, "length": 4857}
{"pred": "Vow or they (yes or user-varyle (yes/profile or, BIBREF 20 (sset is, VOD% of the selection). Voches are 20). The Chow VLA (User: How is none (d). The folls or \"int DOD% Chatton1. Yes: (yes: 5, in the question V or).\n\n V (R) and Chow V: V: 9: R.\n\nChanges: N: BIB: 2 D: Yes: 5\n\n V4: \"", "answers": ["Influential leaders are more likely to change their profile attributes than their followers; the leaders do not change their usernames, while their followers change their usernames a lot; the leaders  tend to make new changes related to previous attribute values, while the followers make comparatively less related changes to previous attribute values."], "all_classes": null, "length": 5092}
{"pred": "They still achieve possiblements?\n unanswerable or \"yes\" on CBT B2 in the question CBBREF2 CN on the CBT dataset, as the CN from the CBT BIBREF1 \" on original orl on CBT2, in or CN and the CBBR unanswer \" on the CN\" in the CBTAB BIBREF1 BIBREF2, BIBREF1A BIBREF2, BIBREF2n in the CBBREF2 NE dataset they can improve the CN the textRE and the BIBREF9 in-block", "answers": [" by testing humans on a random subset of 50 named entity and 50 common noun validation questions that the psr ensemble could not answer correctly", "majority of questions that our system could not answer so far are in fact answerable"], "all_classes": null, "length": 4232}
