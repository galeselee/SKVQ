{"pred": "Fox:", "answers": ["FoxNews, CNN, ESPN, New York Times, Time magazine, Huffington Post Weird News, The Guardian, Cartoon Network, Cooking Light, Home Cooking Adventure, Justin Bieber, Nickelodeon, Spongebob, Disney", "FoxNews, CNN, ESPN, New York Times, Time magazine, Huffington Post Weird News, The Guardian, Cartoon Network, Cooking Light, Home Cooking Adventure, Justin Bieber, Nickelodeon, Spongebob, Disney."], "all_classes": null, "length": 3411}
{"pred": "A series of posts (hLto a LITFORM0 (LAL)", "answers": ["the series of posts that trigger an intervention"], "all_classes": null, "length": 3732}
{"pred": "F-score (and... features, along with an F-mat-REF, (un-referated, and the Bigrams (galah, the at yes, for the \"c (untrack, and and the cognitive)", "answers": ["F-score, Kappa", "Unanswerable"], "all_classes": null, "length": 3544}
{"pred": "The best results on the information flow of the lower context.", "answers": ["(i) models that use plain stacked LSTMs, (ii) models with different INLINEFORM0, (iii) models without INLINEFORM1, (iv) models that integrate lower contexts via peephole connections"], "all_classes": null, "length": 3224}
{"pred": "Un yes, yes/unâese's answer is illustrated, unanswerable:", "answers": ["Yes", "Unanswerable"], "all_classes": null, "length": 2284}
{"pred": "Unconcresdiscin-answers-d.", "answers": ["No"], "all_classes": null, "length": 3843}
{"pred": "The question (labeled $F}L", "answers": ["Yes", "No"], "all_classes": null, "length": 2317}
{"pred": "The sentiment in multilingual sentiment, the general, a \"un-else (BIBREF6\".", "answers": ["SemEval-2016 Challenge Task 5 BIBREF27 , BIBREF28", " English reviews ,  restaurant reviews from four different languages (Spanish, Turkish, Dutch, Russian)"], "all_classes": null, "length": 2720}
{"pred": "The ELMMC. a self-14.89% and  14.2, and the improvement in a few-shot learning a rare-sensing can, of 14. The topic-7.7. Our model has 11. The 11 14.14, and  0.125/, 0.125.2 samples/ 0.0. The 12. 12. 12.0. 14,  14.7. 12.  14.  0.9. 14. 0. 0.0.  0", "answers": ["7.36% on accuracy and 9.69% on F1 score", "it has 0.024 improvement in accuracy comparing to ELMO Only and  0.006 improvement in F1 score  comparing to ELMO Only too"], "all_classes": null, "length": 2890}
{"pred": "They use the I.", "answers": ["They use text transcription.", "both"], "all_classes": null, "length": 3198}
{"pred": "CLF- \n\nAppiff, the sentence in each P, assigned (Table D1)", "answers": ["CLUTO, Carrot2 Lingo", "simple clustering algorithm which uses the cosine similarity between word embeddings"], "all_classes": null, "length": 3039}
{"pred": "BERT: B.BET-30. B.B.B: \"BIB-CIT, and part of 3, BIBIB:54, and to 35 questions in N. BIB-A, and the performance in, a, and B-REF-2-1, and 3 e Pot, B. B-9, an el is 50, and, privacy, a privacy. B-64, B. \"un answer, and 5, B 7 and 35,  n, and 35 2, and  BIB assistant, B as 9, and 8,", "answers": ["Bert + Unanswerable", "CNN, BERT"], "all_classes": null, "length": 3845}
{"pred": "P-ling$\\rightarrow $without an alignment-based, yes-60.", "answers": ["pivoting, pivoting$_{\\rm m}$", "firstly translates a source language into the pivot language which is later translated to the target language"], "all_classes": null, "length": 3815}
{"pred": "Emotion language the general attention's tweets in the same of the Emotion X BIBRE, the emotion label and the Emo, the article, and the original, and Emotion's, and Chat, the model, the, and the personality, and Future, the emotion, and the last, in EmN- T, the emotion X, and 1, and model, and BIBRA, and Chat, and 1, and, and, BERT, and the Emotion, and the scenario, Chat, and Em, and the challenge, and, and, and 1, BIC, and", "answers": ["Friends, EmotionPush", "EmotionLines BIBREF6"], "all_classes": null, "length": 3178}
{"pred": "The results in the main for large-spk for the first or all non- and a one number of the i-v for the phrase and 1-sr and LER (for the Deep Mine and DIB REF for background (GMainly, the Large- for the remaining (i) have i. training. i. The results in the i yes, the results have  i for all 4 and  for the one, the 3-s, and 3, and the 1, the all 25, the and  i-v, i. the a 1-s, 1-s and 3", "answers": ["three experimental setups with different numbers of speakers in the evaluation set, three experimental setups with different number of speaker in the evaluation set are defined,  first one, respondents with at least 17 recording sessions are included to the evaluation set, respondents with 16 sessions to the development and the rest of respondents to the background set, second setup, respondents with at least 8 sessions are included to the evaluation set, respondents with 6 or 7 sessions to the development and the rest of respondents to the background set"], "all_classes": null, "length": 3880}
{"pred": "G", "answers": ["pays attentions to adjacent characters and casts a localness relationship between the characters as a fixed Gaussian weight assuming the weight relies on the distance between characters", "Gaussian-masked directional attention can be described as a function to map queries and key-value pairs to the representation of input, Gaussian-masked directional attention expects to pay attention to the adjacent characters of each positions and cast the localness relationship between characters as a fix Gaussian weight for attention, Gaussian weight only relys on the distance between characters"], "all_classes": null, "length": 3612}
{"pred": "The V, the model can is conc to 1. For the given language, and the English words, we  BIBEQ28- 2, 2, we can 2G BIBlarge, we, and  The language, a, and 1. 3. BIC, and  N (BIB {| {BEM {|target. N.", "answers": ["No data. Pretrained model is used."], "all_classes": null, "length": 3409}
{"pred": "In attention models that the highly standard attention to the attention loss that is the attention model that training is unanswer:", "answers": ["For certain POS tags, e.g. VERB, PRON.", "most word alignments only involve one or a few words, attention can be distributed more freely"], "all_classes": null, "length": 3366}
{"pred": "RNN: answer the article BIBFORM (unaries are a  yes, BREF (yes, BIBREF2.", "answers": ["RNN", " Recurrent Neural Network (RNN)"], "all_classes": null, "length": 1644}
{"pred": "unanswerable yes.", "answers": ["CNN modelBIBREF0, Stanford CRF modelBIBREF21", "Bam et al. SVM, Ma and Hovy w/glove, Lample et al. w/fastText, Lample et al. w/word2vec"], "all_classes": null, "length": 2836}
{"pred": "Un", "answers": ["Unanswerable"], "all_classes": null, "length": 3885}
{"pred": "Around 500 different models specific, and INLINE form BIBing the total 16 BIBREF, P and  PIBRU, and an un- 500 B, unanswer study of  the 500, BIBREF27, 500.", "answers": ["about 500", "Unanswerable"], "all_classes": null, "length": 3831}
{"pred": "The baseline models used in the article: The research `Fast BIB system, and three models: The models: The performance of the shared 1-6: a: 2: 17, 17, and 0. (the  training. The -  yes, and 0: 0, and 0, 21, and 0. 0, 0, 1, and 21, 1, 0: 0. and 0. 0, 1, and 1, 0, 0, 0, and 0, 1,", "answers": ["linear SVM, bidirectional Long Short-Term-Memory (BiLSTM), Convolutional Neural Network (CNN)", "linear SVM, bidirectional Long Short-Term-Memory (BiLSTM), Convolutional Neural Network (CNN)", "linear SVM trained on word unigrams,  bidirectional Long Short-Term-Memory (BiLSTM),  Convolutional Neural Network (CNN) "], "all_classes": null, "length": 2250}
{"pred": "Bi-mat to ourN named REF and his future to be unstandard list of  un + to the standard BREF7.", "answers": ["BiLSTM, BiLSTM-CNN, BiLSTM-CRF, BiLSTM-CNN-CRF", "BiLSTMBIBREF14, BiLSTM+CNNBIBREF20, BiLSTM+CRFBIBREF1, BiLSTM+CNN+CRFBIBREF2, CNN modelBIBREF0 and Stanford CRF modelBIBREF21"], "all_classes": null, "length": 2838}
{"pred": "Un", "answers": ["Zero Resource Toolkit (ZRTools) BIBREF7"], "all_classes": null, "length": 3381}
{"pred": "BERT: $\\textBIB\\ and BIBref (unphase is the next, In our method. unanswer to the method, and B \"unanswer: un-1 109. (base gain) in the BIn N N, quick. Introduction.", "answers": ["BERTbase", "BERTbase"], "all_classes": null, "length": 3852}
{"pred": "Five models: the models used range of key/no, key, and: topic, were answer out, and, abridge REFREFREF", "answers": ["Answer with content missing: (LVL1, LVL2, LVL3) \n- Stanford CoreNLP\n- Optical Character Recognition (OCR) system, ParsCIT \n- further abridge the input text from level 2 preprocessed documents to the following: title, headers, abstract, introduction, related work, background and conclusion."], "all_classes": null, "length": 1822}
{"pred": "No/-", "answers": ["Yes", "Yes"], "all_classes": null, "length": 2077}
{"pred": "Mrosse standard, the upper bound on BIBREF3 )", "answers": ["MIMIC-III", "MIMIC-III"], "all_classes": null, "length": 2992}
{"pred": "Unovation: \"un", "answers": ["Level A: 14100 Tweets\nLevel B: 4640 Tweets\nLevel C: 4089 Tweets"], "all_classes": null, "length": 2255}
{"pred": "Attention patterns of attention model B BIB-Et-al attention's \"yes, other mixed information, for example 4.", "answers": ["it captures other information rather than only the translational equivalent in the case of verbs", "Alignment points of the POS tags."], "all_classes": null, "length": 3372}
{"pred": "The article \"yes, the question is denoted, the personality and the same as our label, the challenge and 0, the models are B 1, and  Table, and the, the, the, and, the weights,  unanswer, and, original, the, the emotion labels, BIB, and the weights, and Text CNN <display, the, by, and, BIB, yes, the weights, and, and, un- Car, and,, and, 1, and, and, 3, and, and, and D, and, and, and, and original", "answers": ["BOW-LR, BOW-RF. TFIDF-RF, TextCNN, C-TextCNN", "bag-of-words (BOW), term frequency–inverse document frequency (TFIDF), neural-based word embedding, Logistic Regression (LR), Random Forest (RF), TextCNN BIBREF10 with initial word embedding as GloVe"], "all_classes": null, "length": 3181}
{"pred": "The article.", "answers": ["Unanswerable", "48,705"], "all_classes": null, "length": 3307}
{"pred": "The un-to- have 11 B11 CoV Bilingual, Co B 3, Co, the 201, and, E- and 10, 2 for future, BBLEASH- evaluation, the 11 F-, have, and 3, to our, 3, 1, 2 Co, 11, many,, the 11,, and 2, 3, 1, 3, to, the, the 1, and 1, 3, 1,, 1, 2, 3, 1, 3,", "answers": ["follow the architecture in berard2018end, but have 3 decoder layers like that in pino2019harnessing"], "all_classes": null, "length": 2424}
{"pred": "The question in BIBREF: PTIBE", "answers": [" Penn Treebank, WikiText2", "Penn Treebank (PTB) , WikiText2 (WT-2)"], "all_classes": null, "length": 3302}
{"pred": "Unlaiform2 (a) for the bag ****** of the clustering - our algorithm, and inline and un (unanswer:", "answers": ["No", "No"], "all_classes": null, "length": 3158}
{"pred": "The question is effective in the previous ones distillation, the student BERT-teacher, which is not to a smaller for future future, the student and student language, can, an NLP, the student, and student, have un effective, and, in the student, the student model and student, the student, and and, and, and, the student, the student, and BIBREF, and, aligning, and student, and, and, and, and, and, and, a, and, and, and, and, and, and, and, the teacher, and, and, and,", "answers": ["While there has been existing work on reducing NLP model vocabulary sizes BIBREF15, distillation techniques cannot utilize these, since they require the student and teacher models to share the same vocabulary and output space. This profoundly limits their potential to further reduce model sizes.", "distillation techniques cannot utilize these, since they require the student and teacher models to share the same vocabulary and output space. This profoundly limits their potential to further reduce model sizes."], "all_classes": null, "length": 3570}
{"pred": "The article is \"unanswer\"", "answers": ["using word2vec to create features that are used as input to the SVM", "use the word2vec algorithm, create several unsupervised hand-crafted features, generate document vectors and feed them as input into the support vector machines (SVM) approach"], "all_classes": null, "length": 3820}
{"pred": "The large-based-based and the large-ages.", "answers": ["ancient Chinese history records in several dynasties (about 1000BC-200BC) and articles written by celebrities of that era", "Ancient Chinese history records in several dynasties and articles written by celebrities during 1000BC-200BC collected from the internet "], "all_classes": null, "length": 3722}
{"pred": "Un", "answers": ["No"], "all_classes": null, "length": 1561}
{"pred": "\": un answer: or B2, and in a set, our results suggest that the chunk'... Table, B, word, and yes/no FIB: words in Social works, and \"h,, scientific, B, B, and to, on, B, B,", "answers": ["words embeddings, style, and morality features", "words embeddings, style, and morality features"], "all_classes": null, "length": 2091}
{"pred": "The single- 6, we BIBREF32 and 6, and 12 models in all, and 12, and we- (top, 24 24, 32, and, 12 or 25, 3, 12 in 12, and 11, and 32, 7^, and 4, 0,  no) and 24 1, and  and 11, 50, RAMEN  and, the  27, the  no, and  and, can B,  and, and), and  no, and ", "answers": ["United Nations Parallel Corpus, IIT Bombay corpus, OpenSubtitles 2018"], "all_classes": null, "length": 3405}
{"pred": "un-", "answers": ["Unanswerable", "English"], "all_classes": null, "length": 2009}
{"pred": "No, the question: \"unanswer, and two-3, B, and, three texts- 15, L1, and, the question: B, yes, and future language,1.: \"un, S, and \"un, and N, the three, and, and, B, three, and, and, and, and, and, \"re, and, and, and, and, and, and, and, \"un, and, and, C, and, 1, and, and, 3, and, and, and, and, and, and, and,", "answers": ["No", "No"], "all_classes": null, "length": 1899}
{"pred": "The article, Table TABREF4, 45 REF: \"un-ref: 10, 408T: 6", "answers": ["45,000 scholarly articles, including over 33,000 with full text"], "all_classes": null, "length": 2150}
{"pred": "Traditional, NLMREF1 report a  \"unexplainable-tentune self is 0. The X as a 0 and the median 11, the topic-ELMIB� our L and BIBSO, 15, and 2, we \"yes. our 11 3: a 0, specifically, and 0, B 0, and 14.", "answers": ["support vector machine classifier (SVM), logistic regression classifier (LR), Naive Bayes classifier (NB), random forest (RF), CNN, LSTM , LSTM-soft, LSTM-self", "support vector machine classifier (SVM), logistic regression classifier (LR), Naive Bayes classifier (NB), random forest (RF), CNN, LSTM , LSTM-soft, LSTM-self"], "all_classes": null, "length": 2895}
{"pred": "Unanswer:", "answers": ["1913 signals", "Unanswerable"], "all_classes": null, "length": 2361}
{"pred": "Macaw can be-say the following actions: a list of modules BIBBanswer: B", "answers": ["Co-Reference Resolution, Query Generation, Retrieval Model, Result Generation", "Co-Reference Resolution, Query Generation, Retrieval Model, Result Generation"], "all_classes": null, "length": 1701}
{"pred": "unanswer:", "answers": ["Unanswerable"], "all_classes": null, "length": 1913}
{"pred": "unavailable (i-speech for all of the last or at the main limitation for the (background data for the unanswer mine (i-s) and the results in each of the DeepMine (i-IT (un) for the language, i- i the i) for all of the i-v and i- text-p, in one yes, text (i- and BIBMine) for the main, DeepSc (the large, and s for the rest (i-s) for the full case, and the normal (i- and large number of full- and BIB- for the i-s and 2", "answers": ["Unanswerable", "Unanswerable"], "all_classes": null, "length": 3794}
{"pred": "The proposed BIBREF24: we conduct, BIB, and the set 20, and, and our re the original SQu and the data. Our-Na, the experiments and the future,", "answers": ["SQuAD", "SQuAD"], "all_classes": null, "length": 3757}
{"pred": "The results of tables TABSERT16 and 2010, our ", "answers": ["relation classification dataset of the SemEval 2010 task 8", "SemEval 2010 task 8 BIBREF8"], "all_classes": null, "length": 2393}
