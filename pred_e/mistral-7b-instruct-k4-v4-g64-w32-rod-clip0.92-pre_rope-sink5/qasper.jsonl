{"pred": "FoxNews, CNN, ESPN, New York Times, Time magazine, Huffington Post Weird News, The Guardian, Cartoon Network, Cooking Light, Home Cooking Adventure, Justin Bieber, Nickelodeon, Spongebob, Disney.", "answers": ["FoxNews, CNN, ESPN, New York Times, Time magazine, Huffington Post Weird News, The Guardian, Cartoon Network, Cooking Light, Home Cooking Adventure, Justin Bieber, Nickelodeon, Spongebob, Disney", "FoxNews, CNN, ESPN, New York Times, Time magazine, Huffington Post Weird News, The Guardian, Cartoon Network, Cooking Light, Home Cooking Adventure, Justin Bieber, Nickelodeon, Spongebob, Disney."], "all_classes": null, "length": 3411}
{"pred": "Latent context inferred by attention models.", "answers": ["the series of posts that trigger an intervention"], "all_classes": null, "length": 3732}
{"pred": "\"F-scores and Kappa statistics\"", "answers": ["F-score, Kappa", "Unanswerable"], "all_classes": null, "length": 3544}
{"pred": "The baselines are plain stacked LSTMs.", "answers": ["(i) models that use plain stacked LSTMs, (ii) models with different INLINEFORM0, (iii) models without INLINEFORM1, (iv) models that integrate lower contexts via peephole connections"], "all_classes": null, "length": 3224}
{"pred": "No. jiant is compatible with models implemented by Huggingface's Transformers package, which are primarily in Python.", "answers": ["Yes", "Unanswerable"], "all_classes": null, "length": 2284}
{"pred": "Unanswerable (based on the information provided, it is not clear if the experts are comparable to real-world users)", "answers": ["No"], "all_classes": null, "length": 3843}
{"pred": "Modest gains on three of the four downstream tasks relative to ELMo-only baselines.", "answers": ["Yes", "No"], "all_classes": null, "length": 2317}
{"pred": "Four datasets were used in evaluation.", "answers": ["SemEval-2016 Challenge Task 5 BIBREF27 , BIBREF28", " English reviews ,  restaurant reviews from four different languages (Spanish, Turkish, Dutch, Russian)"], "all_classes": null, "length": 2720}
{"pred": "Improvements are observed with small-scale unbalanced datasets when sentence representation is enhanced with topic information.", "answers": ["7.36% on accuracy and 9.69% on F1 score", "it has 0.024 improvement in accuracy comparing to ELMO Only and  0.006 improvement in F1 score  comparing to ELMO Only too"], "all_classes": null, "length": 2890}
{"pred": "They determine text from the audio.", "answers": ["They use text transcription.", "both"], "all_classes": null, "length": 3198}
{"pred": "Clustering algorithms used are simple clustering algorithm using cosine similarity between word embeddings, CLUTO, and Carrot2 Lingo.", "answers": ["CLUTO, Carrot2 Lingo", "simple clustering algorithm which uses the cosine similarity between word embeddings"], "all_classes": null, "length": 3039}
{"pred": "BERT", "answers": ["Bert + Unanswerable", "CNN, BERT"], "all_classes": null, "length": 3845}
{"pred": "Pivot-based methods (BIBREF4, BIBREF5, BIBREF12, BIBREF13, BIBREF14)", "answers": ["pivoting, pivoting$_{\\rm m}$", "firstly translates a source language into the pivot language which is later translated to the target language"], "all_classes": null, "length": 3815}
{"pred": "EmotionLines dataset", "answers": ["Friends, EmotionPush", "EmotionLines BIBREF6"], "all_classes": null, "length": 3178}
{"pred": "Several evaluation protocols are provided for each part of the DeepMine database.", "answers": ["three experimental setups with different numbers of speakers in the evaluation set, three experimental setups with different number of speaker in the evaluation set are defined,  first one, respondents with at least 17 recording sessions are included to the evaluation set, respondents with 16 sessions to the development and the rest of respondents to the background set, second setup, respondents with at least 8 sessions are included to the evaluation set, respondents with 6 or 7 sessions to the development and the rest of respondents to the background set"], "all_classes": null, "length": 3880}
{"pred": "Gaussian-masked directional multi-head attention adjusts the weight between characters and their adjacent character to a larger value, which stands for the effect of adjacent characters.", "answers": ["pays attentions to adjacent characters and casts a localness relationship between the characters as a fixed Gaussian weight assuming the weight relies on the distance between characters", "Gaussian-masked directional attention can be described as a function to map queries and key-value pairs to the representation of input, Gaussian-masked directional attention expects to pay attention to the adjacent characters of each positions and cast the localness relationship between characters as a fix Gaussian weight for attention, Gaussian weight only relys on the distance between characters"], "all_classes": null, "length": 3612}
{"pred": "The system uses monolingual data from the non-English language for fine-tuning target embeddings and bilingual LMs.", "answers": ["No data. Pretrained model is used."], "all_classes": null, "length": 3409}
{"pred": "Different from alignment in cases of verbs.", "answers": ["For certain POS tags, e.g. VERB, PRON.", "most word alignments only involve one or a few words, attention can be distributed more freely"], "all_classes": null, "length": 3366}
{"pred": "Recurrent Neural Network (RNN)", "answers": ["RNN", " Recurrent Neural Network (RNN)"], "all_classes": null, "length": 1644}
{"pred": "The baseline is not explicitly mentioned in the article.", "answers": ["CNN modelBIBREF0, Stanford CRF modelBIBREF21", "Bam et al. SVM, Ma and Hovy w/glove, Lample et al. w/fastText, Lample et al. w/word2vec"], "all_classes": null, "length": 2836}
{"pred": "Unanswerable (The article is an introduction and does not provide a publication date)", "answers": ["Unanswerable"], "all_classes": null, "length": 3885}
{"pred": "Around 500 different workers were involved in the annotation.", "answers": ["about 500", "Unanswerable"], "all_classes": null, "length": 3831}
{"pred": "CNN, BiLSTM, and SVM", "answers": ["linear SVM, bidirectional Long Short-Term-Memory (BiLSTM), Convolutional Neural Network (CNN)", "linear SVM, bidirectional Long Short-Term-Memory (BiLSTM), Convolutional Neural Network (CNN)", "linear SVM trained on word unigrams,  bidirectional Long Short-Term-Memory (BiLSTM),  Convolutional Neural Network (CNN) "], "all_classes": null, "length": 2250}
{"pred": "BiLSTM, BiLSTM-CNN, BiLSTM-CRF, BiLSTM-CNN-CRF, Stanford CRF", "answers": ["BiLSTM, BiLSTM-CNN, BiLSTM-CRF, BiLSTM-CNN-CRF", "BiLSTMBIBREF14, BiLSTM+CNNBIBREF20, BiLSTM+CRFBIBREF1, BiLSTM+CNN+CRFBIBREF2, CNN modelBIBREF0 and Stanford CRF modelBIBREF21"], "all_classes": null, "length": 2838}
{"pred": "Unsupervised term discovery (UTD) and acoustic unit discovery (AUD) are methods for automatically discovering word-like or phoneme-like units.", "answers": ["Zero Resource Toolkit (ZRTools) BIBREF7"], "all_classes": null, "length": 3381}
{"pred": "BERTBase model", "answers": ["BERTbase", "BERTbase"], "all_classes": null, "length": 3852}
{"pred": "Five keyphrase extraction models were reassessed.", "answers": ["Answer with content missing: (LVL1, LVL2, LVL3) \n- Stanford CoreNLP\n- Optical Character Recognition (OCR) system, ParsCIT \n- further abridge the input text from level 2 preprocessed documents to the following: title, headers, abstract, introduction, related work, background and conclusion."], "all_classes": null, "length": 1822}
{"pred": "Yes", "answers": ["Yes", "Yes"], "all_classes": null, "length": 2077}
{"pred": "MIMIC-III database", "answers": ["MIMIC-III", "MIMIC-III"], "all_classes": null, "length": 2992}
{"pred": "The dataset sizes for each step of the hierarchy are not explicitly stated in the article.", "answers": ["Level A: 14100 Tweets\nLevel B: 4640 Tweets\nLevel C: 4089 Tweets"], "all_classes": null, "length": 2255}
{"pred": "Attention captures information beyond alignment.", "answers": ["it captures other information rather than only the translational equivalent in the case of verbs", "Alignment points of the POS tags."], "all_classes": null, "length": 3372}
{"pred": "Bag-of-words, term frequency–inverse document frequency, Logistic Regression, Random Forest, TextCNN, and proposed model.", "answers": ["BOW-LR, BOW-RF. TFIDF-RF, TextCNN, C-TextCNN", "bag-of-words (BOW), term frequency–inverse document frequency (TFIDF), neural-based word embedding, Logistic Regression (LR), Random Forest (RF), TextCNN BIBREF10 with initial word embedding as GloVe"], "all_classes": null, "length": 3181}
{"pred": "They look at multiple tags.", "answers": ["Unanswerable", "48,705"], "all_classes": null, "length": 3307}
{"pred": "\"Transformer base for MT, similar to berard2018end for ASR and ST, with 3 decoder layers.\"", "answers": ["follow the architecture in berard2018end, but have 3 decoder layers like that in pino2019harnessing"], "all_classes": null, "length": 2424}
{"pred": "Penn Treebank (PTB) and WikiText2 (WT-2) datasets", "answers": [" Penn Treebank, WikiText2", "Penn Treebank (PTB) , WikiText2 (WT-2)"], "all_classes": null, "length": 3302}
{"pred": "Unanswerable (The article does not mention the use of graphical models)", "answers": ["No", "No"], "all_classes": null, "length": 3158}
{"pred": "Prior knowledge distillation techniques are ineffective in producing student models with vocabularies different from the original teacher models because they require the student and teacher models to share the same vocabulary and output space.", "answers": ["While there has been existing work on reducing NLP model vocabulary sizes BIBREF15, distillation techniques cannot utilize these, since they require the student and teacher models to share the same vocabulary and output space. This profoundly limits their potential to further reduce model sizes.", "distillation techniques cannot utilize these, since they require the student and teacher models to share the same vocabulary and output space. This profoundly limits their potential to further reduce model sizes."], "all_classes": null, "length": 3570}
{"pred": "word2vec", "answers": ["using word2vec to create features that are used as input to the SVM", "use the word2vec algorithm, create several unsupervised hand-crafted features, generate document vectors and feed them as input into the support vector machines (SVM) approach"], "all_classes": null, "length": 3820}
{"pred": "From the internet.", "answers": ["ancient Chinese history records in several dynasties (about 1000BC-200BC) and articles written by celebrities of that era", "Ancient Chinese history records in several dynasties and articles written by celebrities during 1000BC-200BC collected from the internet "], "all_classes": null, "length": 3722}
{"pred": "Unanswerable (based on the provided article)", "answers": ["No"], "all_classes": null, "length": 1561}
{"pred": "Words embeddings, style, and morality features.", "answers": ["words embeddings, style, and morality features", "words embeddings, style, and morality features"], "all_classes": null, "length": 2091}
{"pred": "United Nations Parallel Corpus, IIT Bombay corpus, OpenSubtitles 2018, XNLI dataset, Universal Dependencies v2.4.", "answers": ["United Nations Parallel Corpus, IIT Bombay corpus, OpenSubtitles 2018"], "all_classes": null, "length": 3405}
{"pred": "Unspecified in the article.", "answers": ["Unanswerable", "English"], "all_classes": null, "length": 2009}
{"pred": "Unanswerable", "answers": ["No", "No"], "all_classes": null, "length": 1899}
{"pred": "Over 45,000 articles", "answers": ["45,000 scholarly articles, including over 33,000 with full text"], "all_classes": null, "length": 2150}
{"pred": "Compared baseline models", "answers": ["support vector machine classifier (SVM), logistic regression classifier (LR), Naive Bayes classifier (NB), random forest (RF), CNN, LSTM , LSTM-soft, LSTM-self", "support vector machine classifier (SVM), logistic regression classifier (LR), Naive Bayes classifier (NB), random forest (RF), CNN, LSTM , LSTM-soft, LSTM-self"], "all_classes": null, "length": 2895}
{"pred": "Unanswerable (The article does not provide the number of electrodes used in the EEG sessions.)", "answers": ["1913 signals", "Unanswerable"], "all_classes": null, "length": 2361}
{"pred": "Conversational search, conversational question answering, conversational recommendation, and conversational natural language interface to structured and semi-structured data.", "answers": ["Co-Reference Resolution, Query Generation, Retrieval Model, Result Generation", "Co-Reference Resolution, Query Generation, Retrieval Model, Result Generation"], "all_classes": null, "length": 1701}
{"pred": "Unanswerable (based on the information provided in the article)", "answers": ["Unanswerable"], "all_classes": null, "length": 1913}
{"pred": "Unanswerable (The article does not provide information about the accents present in the corpus.)", "answers": ["Unanswerable", "Unanswerable"], "all_classes": null, "length": 3794}
{"pred": "SQuAD dataset", "answers": ["SQuAD", "SQuAD"], "all_classes": null, "length": 3757}
{"pred": "SemEval 2010 task 8 dataset", "answers": ["relation classification dataset of the SemEval 2010 task 8", "SemEval 2010 task 8 BIBREF8"], "all_classes": null, "length": 2393}
{"pred": "The English corpus was twice the size of the Russian corpus.", "answers": ["2174000000, 989000000", "2174 million tokens for English and 989 million tokens for Russian"], "all_classes": null, "length": 2958}
{"pred": "Qualitative experiments are performed on the Text8 dataset.", "answers": ["Spearman correlation values of GM_KL model evaluated on the benchmark word similarity datasets.\nEvaluation results of GM_KL model on the entailment datasets such as entailment pairs dataset created from WordNet, crowdsourced dataset of 79 semantic relations labelled as entailed or not and annotated distributionally similar nouns dataset.", "Given a query word and component id, the set of nearest neighbours along with their respective component ids are listed"], "all_classes": null, "length": 2220}
{"pred": "Improves F1 by +0.58 for MRPC and +0.73 for QQP.", "answers": ["Using DSC loss improves the F1 score by +0.58 for MRPC and +0.73 for QQP", "+0.58"], "all_classes": null, "length": 3566}
{"pred": "Asymptotic variance is calculated using Fisher Information Matrix.", "answers": ["reducing the variance of an estimator,  EGL method in BIBREF3 is almost the same as Eq. ( EQREF8 ), except the gradient's norm is not squared in BIBREF3", " Fisher Information Ratio"], "all_classes": null, "length": 1671}
{"pred": "LSTM encoder", "answers": ["LSTM", "LSTM"], "all_classes": null, "length": 2289}
{"pred": "Natural language questions are present in the dataset.", "answers": ["These 8 tasks require different competencies and a different level of understanding of the document to be well answered"], "all_classes": null, "length": 3817}
{"pred": "Yes", "answers": ["SVM, No-Answer Baseline (NA) , Word Count Baseline, Human Performance", "No-Answer Baseline (NA), Word Count Baseline, Human Performance"], "all_classes": null, "length": 3855}
{"pred": "53", "answers": ["53 documents", "53 documents"], "all_classes": null, "length": 2667}
{"pred": "Food.com", "answers": ["from Food.com"], "all_classes": null, "length": 2649}
{"pred": "Intrinsic evaluations (word similarity and word analogy tasks) and downstream tasks (chunking, sentiment and question classification, and natural language identification) from the VecEval suite.", "answers": ["We also evaluate all five models on downstream tasks from the VecEval suite BIBREF13 , using only the tasks for which training and evaluation data is freely available: chunking, sentiment and question classification, and natural language identification (NLI). The default settings from the suite are used, but we run only the fixed settings, where the embeddings themselves are not tunable parameters of the models, forcing the system to use only the information already in the embeddings."], "all_classes": null, "length": 2083}
{"pred": "Unanswerable (The article only lists 15 annotated phenotypes)", "answers": ["Adv. Heart Disease, Adv. Lung Disease, Alcohol Abuse, Chronic Neurologic Dystrophies, Dementia, Depression, Developmental Delay, Obesity, Psychiatric disorders and Substance Abuse"], "all_classes": null, "length": 1651}
{"pred": "Unanswerable (average length is not provided in the article)", "answers": ["204 tokens", "Most texts, however, range roughly from 150 to 250 tokens."], "all_classes": null, "length": 1898}
{"pred": "Patterns over words and part-of-speech (POS) tags are extracted.", "answers": ["(VVD shop_VV0 II, VVD shopping_VVG II)", "patterns for generating all types of errors"], "all_classes": null, "length": 2133}
{"pred": "Unanswerable (The article does not mention the study of numerical properties such as orthogonality of their obtained vectors.)", "answers": ["No", "No"], "all_classes": null, "length": 3974}
{"pred": "Random Kitchen Sink approach", "answers": ["Random Kitchen Sink method uses a kernel function to map data vectors to a space where linear separation is possible.", "explicitly maps data vectors to a space where linear separation is possible, RKS method provides an approximate kernel function via explicit mapping"], "all_classes": null, "length": 2361}
{"pred": "They compare to a Big Transformer model and a variant where they share token embeddings between the encoder and decoder.", "answers": ["BIBREF11 , BIBREF26 "], "all_classes": null, "length": 1912}
{"pred": "Improvements for error detection on both datasets.", "answers": ["Combining  pattern based and Machine translation approaches gave the best overall F0.5 scores. It was 49.11 for FCE dataset  , 21.87 for the first annotation of  CoNLL-14, and 30.13 for the second annotation of CoNLL-14. "], "all_classes": null, "length": 2164}
{"pred": "Named Entity Recognition, POS tagging, text classification, and language modeling.", "answers": ["None"], "all_classes": null, "length": 2473}
{"pred": "Seven experts with legal training", "answers": ["Individuals with legal training", "Yes"], "all_classes": null, "length": 3846}
{"pred": "Machine learning-based methods have been applied to solve word segmentation in Vietnamese.", "answers": ["Maximum Entropy, Weighted Finite State Transducer (WFST),  support vector machines (SVM), conditional random fields (CRF)", "Maximum matching, Hidden Markov model , Maximum Entropy, Conditional Random Fields , Support Vector Machines"], "all_classes": null, "length": 3471}
{"pred": "Three named entity recognition models were evaluated: Stanford NER, spaCy 2.0, and a recurrent model with a CRF top layer.", "answers": ["Stanford NER, spaCy 2.0 , recurrent model with a CRF top layer", "Stanford NER, spaCy 2.0, recurrent model with a CRF top layer"], "all_classes": null, "length": 2759}
{"pred": "WN18 and FB15K", "answers": ["WordNet BIBREF0, Freebase BIBREF1, WN18 (a subset of WordNet) BIBREF24 , FB15K (a subset of Freebase) BIBREF2"], "all_classes": null, "length": 3367}
{"pred": "\"LastStateRNN\"", "answers": [" LastStateRNN, AvgRNN, AttentionRNN", "LastStateRNN, AvgRNN, AttentionRNN "], "all_classes": null, "length": 2823}
{"pred": "Personal attack, racism, and sexism", "answers": ["personal attack, racism, and sexism", "racism, sexism, personal attack, not specifically about any single topic"], "all_classes": null, "length": 3244}
{"pred": "Yes", "answers": ["Yes", "Yes"], "all_classes": null, "length": 3634}
{"pred": "Annotated Twitter dataset constructed based on a hierarchical model of depression-related symptoms", "answers": ["BIBREF12 , BIBREF13", "an existing, annotated Twitter dataset that was constructed based on a hierarchical model of depression-related symptoms BIBREF12 , BIBREF13"], "all_classes": null, "length": 1939}
{"pred": "The Nguni languages are similar to each other. The same is true of the Sotho languages.", "answers": ["Nguni languages (zul, xho, nbl, ssw), Sotho languages (nso, sot, tsn)", "The Nguni languages are similar to each other, The same is true of the Sotho languages"], "all_classes": null, "length": 1877}
{"pred": "IMDb dataset", "answers": ["IMDb dataset of movie reviews", "IMDb"], "all_classes": null, "length": 2327}
{"pred": "FoxNews, CNN, ESPN, New York Times, Time magazine, Huffington Post Weird News, The Guardian, Cartoon Network, Cooking Light, Home Cooking Adventure, Justin Bieber, Nickelodeon, Spongebob, Disney.", "answers": ["FoxNews, CNN, ESPN, New York Times, Time magazine, Huffington Post Weird News, The Guardian, Cartoon Network, Cooking Light, Home Cooking Adventure, Justin Bieber, Nickelodeon, Spongebob, Disney", "FoxNews, CNN, ESPN, New York Times, Time magazine, Huffington Post Weird News, The Guardian, Cartoon Network, Cooking Light, Home Cooking Adventure, Justin Bieber, Nickelodeon, Spongebob, Disney."], "all_classes": null, "length": 3411}
{"pred": "89.6% and 89.2% accuracy and F1-score, respectively.", "answers": ["accuracy and F1-score of 89.6% and 89.2%, respectively", "accuracy and F1-score of 89.6% and 89.2%, respectively"], "all_classes": null, "length": 3313}
{"pred": "Latent context inferred by attention models.", "answers": ["the series of posts that trigger an intervention"], "all_classes": null, "length": 3732}
{"pred": "\"F-scores and Kappa statistics\"", "answers": ["F-score, Kappa", "Unanswerable"], "all_classes": null, "length": 3544}
{"pred": "Out-performs K-means, LEM, and DPEMM.", "answers": ["K-means, LEM BIBREF13, DPEMM BIBREF14", "K-means, LEM, DPEMM"], "all_classes": null, "length": 3841}
{"pred": "The baselines are plain stacked LSTMs.", "answers": ["(i) models that use plain stacked LSTMs, (ii) models with different INLINEFORM0, (iii) models without INLINEFORM1, (iv) models that integrate lower contexts via peephole connections"], "all_classes": null, "length": 3224}
{"pred": "8 languages: English, German, Spanish, Mandarin, Polish, Russian, Korean, Serbian.", "answers": ["English, German, Spanish, Mandarin, Polish, Russian, Korean and Serbian", "English (Edinburgh), German (Berlin), Spanish (Madrid), Mandarin (Taipei), Polish (Warsaw), Russian (Moscow), Korean (Seoul), and Serbian (Belgrade)"], "all_classes": null, "length": 2754}
{"pred": "The datasets are not explicitly stated in the article.", "answers": ["rupnik2016news", "rupnik2016news, Deutsche Welle's news website"], "all_classes": null, "length": 3160}
{"pred": "No. jiant is compatible with models implemented by Huggingface's Transformers package, which are primarily in Python.", "answers": ["Yes", "Unanswerable"], "all_classes": null, "length": 2284}
{"pred": "Unanswerable (The article does not specify whether the lexicon is the same for all languages or not.)", "answers": ["Yes", "Yes"], "all_classes": null, "length": 1868}
{"pred": "Unanswerable (based on the information provided, it is not clear if the experts are comparable to real-world users)", "answers": ["No"], "all_classes": null, "length": 3843}
{"pred": "InferSent, Universal Sentence Encoder, and average GloVe embeddings are evaluated.", "answers": ["GloVe, BERT, Universal Sentence Encoder, TF-IDF, InferSent", "Avg. GloVe embeddings, Avg. fast-text embeddings, Avg. BERT embeddings, BERT CLS-vector, InferSent - GloVe and Universal Sentence Encoder."], "all_classes": null, "length": 3862}
{"pred": "Modest gains on three of the four downstream tasks relative to ELMo-only baselines.", "answers": ["Yes", "No"], "all_classes": null, "length": 2317}
{"pred": "SentEval transfer tasks are evaluated.", "answers": ["MR, CR, SUBJ, MPQA, SST, TREC, MRPC", "MR: Sentiment prediction for movie reviews snippets on a five start scale BIBREF25.\n\nCR: Sentiment prediction of customer product reviews BIBREF26.\n\nSUBJ: Subjectivity prediction of sentences from movie reviews and plot summaries BIBREF27.\n\nMPQA: Phrase level opinion polarity classification from newswire BIBREF28.\n\nSST: Stanford Sentiment Treebank with binary labels BIBREF29.\n\nTREC: Fine grained question-type classification from TREC BIBREF30.\n\nMRPC: Microsoft Research Paraphrase Corpus from parallel news sources BIBREF31.", "Semantic Textual Similarity, sentiment prediction, subjectivity prediction, phrase level opinion polarity classification, Stanford Sentiment Treebank, fine grained question-type classification."], "all_classes": null, "length": 3861}
{"pred": "Four datasets were used in evaluation.", "answers": ["SemEval-2016 Challenge Task 5 BIBREF27 , BIBREF28", " English reviews ,  restaurant reviews from four different languages (Spanish, Turkish, Dutch, Russian)"], "all_classes": null, "length": 2720}
{"pred": "Unanswerable (the article does not provide information about the size of the vocabulary)", "answers": ["33,663", "33,663 distinct review keywords "], "all_classes": null, "length": 3305}
{"pred": "Improvements are observed with small-scale unbalanced datasets when sentence representation is enhanced with topic information.", "answers": ["7.36% on accuracy and 9.69% on F1 score", "it has 0.024 improvement in accuracy comparing to ELMO Only and  0.006 improvement in F1 score  comparing to ELMO Only too"], "all_classes": null, "length": 2890}
{"pred": "Context tweets are proposed as additional features.", "answers": ["using tweets that one has replied or quoted to as contextual information", "text sequences of context tweets"], "all_classes": null, "length": 2060}
{"pred": "Yes", "answers": ["No", "No"], "all_classes": null, "length": 1906}
{"pred": "They determine text from the audio.", "answers": ["They use text transcription.", "both"], "all_classes": null, "length": 3198}
{"pred": "Clustering algorithms used are simple clustering algorithm using cosine similarity between word embeddings, CLUTO, and Carrot2 Lingo.", "answers": ["CLUTO, Carrot2 Lingo", "simple clustering algorithm which uses the cosine similarity between word embeddings"], "all_classes": null, "length": 3039}
{"pred": "BERT", "answers": ["Bert + Unanswerable", "CNN, BERT"], "all_classes": null, "length": 3845}
{"pred": "No. The article describes the creation of maps reflecting demographic, linguistic, and psycholinguistic properties of a dataset of bloggers, but does not mention building a model to automatically detect these dimensions.", "answers": ["No", "No"], "all_classes": null, "length": 1443}
{"pred": "Pivot-based methods (BIBREF4, BIBREF5, BIBREF12, BIBREF13, BIBREF14)", "answers": ["pivoting, pivoting$_{\\rm m}$", "firstly translates a source language into the pivot language which is later translated to the target language"], "all_classes": null, "length": 3815}
{"pred": "EmotionLines dataset", "answers": ["Friends, EmotionPush", "EmotionLines BIBREF6"], "all_classes": null, "length": 3178}
{"pred": "Ensemble+ of (r4, r7, r12) is ranked 4th in SLC task. Ensemble+ of (II and IV) is ranked 3rd in FLC task.", "answers": ["For SLC task, the \"ltuorp\" team  has the best performing  model (0.6323/0.6028/0.6649 for F1/P/R  respectively) and for FLC task the \"newspeak\" team  has the best performing  model (0.2488/0.2863/0.2201 for F1/P/R respectively)."], "all_classes": null, "length": 1541}
{"pred": "DTA18 and DTA19", "answers": ["DTA18, DTA19", "Diachronic Usage Relatedness (DURel) gold standard data set"], "all_classes": null, "length": 1908}
{"pred": "Several evaluation protocols are provided for each part of the DeepMine database.", "answers": ["three experimental setups with different numbers of speakers in the evaluation set, three experimental setups with different number of speaker in the evaluation set are defined,  first one, respondents with at least 17 recording sessions are included to the evaluation set, respondents with 16 sessions to the development and the rest of respondents to the background set, second setup, respondents with at least 8 sessions are included to the evaluation set, respondents with 6 or 7 sessions to the development and the rest of respondents to the background set"], "all_classes": null, "length": 3880}
{"pred": "13,757 question-answer pairs", "answers": ["13,757", "10,898 articles, 17,794 tweets, and 13,757 crowdsourced question-answer pairs"], "all_classes": null, "length": 3704}
{"pred": "KNN, Random Forest, Support Vector Machine, and Multi-layer Perceptron", "answers": ["KNN\nRF\nSVM\nMLP", " K Nearest Neighbors (KNN), Random Forest (RF), Support Vector Machine (SVM), Multi-layer Perceptron (MLP)"], "all_classes": null, "length": 1639}
{"pred": "Gaussian-masked directional multi-head attention adjusts the weight between characters and their adjacent character to a larger value, which stands for the effect of adjacent characters.", "answers": ["pays attentions to adjacent characters and casts a localness relationship between the characters as a fixed Gaussian weight assuming the weight relies on the distance between characters", "Gaussian-masked directional attention can be described as a function to map queries and key-value pairs to the representation of input, Gaussian-masked directional attention expects to pay attention to the adjacent characters of each positions and cast the localness relationship between characters as a fix Gaussian weight for attention, Gaussian weight only relys on the distance between characters"], "all_classes": null, "length": 3612}
{"pred": "The system uses monolingual data from the non-English language for fine-tuning target embeddings and bilingual LMs.", "answers": ["No data. Pretrained model is used."], "all_classes": null, "length": 3409}
{"pred": "They obtain the new context representation by splitting the contexts into three disjoint regions based on the two relation arguments: the left context, the middle context and the right context.", "answers": ["They use two independent convolutional and max-pooling layers on (1) a combination of the left context, the left entity and the middle context; and (2) a combination of the middle context, the right entity and the right context. They concatenated the two results after pooling to get the new context representation."], "all_classes": null, "length": 2435}
{"pred": "Different from alignment in cases of verbs.", "answers": ["For certain POS tags, e.g. VERB, PRON.", "most word alignments only involve one or a few words, attention can be distributed more freely"], "all_classes": null, "length": 3366}
{"pred": "Multi-granularity and multi-tasking in neural architecture design.", "answers": ["An output layer for each task", "Multi-tasking is addressed by neural sequence tagger based on LSTM-CRF and linguistic features, while multi-granularity is addressed by ensemble of LSTM-CRF and BERT."], "all_classes": null, "length": 1514}
{"pred": "Recurrent Neural Network (RNN)", "answers": ["RNN", " Recurrent Neural Network (RNN)"], "all_classes": null, "length": 1644}
{"pred": "The baseline is not explicitly mentioned in the article.", "answers": ["CNN modelBIBREF0, Stanford CRF modelBIBREF21", "Bam et al. SVM, Ma and Hovy w/glove, Lample et al. w/fastText, Lample et al. w/word2vec"], "all_classes": null, "length": 2836}
{"pred": "Unanswerable (The article is an introduction and does not provide a publication date)", "answers": ["Unanswerable"], "all_classes": null, "length": 3885}
{"pred": "The CORD-19 dataset is a collection of over 45,000 scholarly articles about COVID-19, SARS-CoV-2, and related coronaviruses.", "answers": ["which contains over 45,000 scholarly articles, including over 33,000 with full text, about COVID-19, SARS-CoV-2, and related coronaviruses", "contains over 45,000 scholarly articles, including over 33,000 with full text, about COVID-19, SARS-CoV-2, and related coronaviruses"], "all_classes": null, "length": 2156}
{"pred": "Around 500 different workers were involved in the annotation.", "answers": ["about 500", "Unanswerable"], "all_classes": null, "length": 3831}
{"pred": "4528 employees", "answers": ["26972", "26972 sentences"], "all_classes": null, "length": 3040}
{"pred": "CNN, BiLSTM, and SVM", "answers": ["linear SVM, bidirectional Long Short-Term-Memory (BiLSTM), Convolutional Neural Network (CNN)", "linear SVM, bidirectional Long Short-Term-Memory (BiLSTM), Convolutional Neural Network (CNN)", "linear SVM trained on word unigrams,  bidirectional Long Short-Term-Memory (BiLSTM),  Convolutional Neural Network (CNN) "], "all_classes": null, "length": 2250}
{"pred": "Performs favorably against recent neural network-based approaches to grammar induction.", "answers": ["Unanswerable", "Unanswerable"], "all_classes": null, "length": 2533}
{"pred": "BiLSTM, BiLSTM-CNN, BiLSTM-CRF, BiLSTM-CNN-CRF, Stanford CRF", "answers": ["BiLSTM, BiLSTM-CNN, BiLSTM-CRF, BiLSTM-CNN-CRF", "BiLSTMBIBREF14, BiLSTM+CNNBIBREF20, BiLSTM+CRFBIBREF1, BiLSTM+CNN+CRFBIBREF2, CNN modelBIBREF0 and Stanford CRF modelBIBREF21"], "all_classes": null, "length": 2838}
{"pred": "Backoff strategies pass the input as is, back off to a neutral word, or fall back upon a more generic word recognizer trained on a larger corpus when the foreground model predicts UNK.", "answers": ["In pass-through, the recognizer passes on the possibly misspelled word, backoff to neutral word backs off to a word with similar distribution across classes and backoff to background model backs off to a more generic word recognition model trained with larger and less specialized corpus.", "Pass-through passes the possibly misspelled word as is, backoff to neutral word backs off to a word with similar distribution across classes and backoff to background model backs off to a more generic word recognition model trained with larger and less specialized corpus.", "Backoff to \"a\" when an UNK-predicted word is encountered, backoff to a more generic word recognition model when the model predicts UNK"], "all_classes": null, "length": 4210}
{"pred": "Unsupervised term discovery (UTD) and acoustic unit discovery (AUD) are methods for automatically discovering word-like or phoneme-like units.", "answers": ["Zero Resource Toolkit (ZRTools) BIBREF7"], "all_classes": null, "length": 3381}
{"pred": "BERTBase model", "answers": ["BERTbase", "BERTbase"], "all_classes": null, "length": 3852}
{"pred": "The Neural User Simulator (NUS) is learned from a corpus of recorded dialogues.", "answers": ["DSTC2", "The manual transcriptions of the DSTC2 training set "], "all_classes": null, "length": 4820}
{"pred": "Five keyphrase extraction models were reassessed.", "answers": ["Answer with content missing: (LVL1, LVL2, LVL3) \n- Stanford CoreNLP\n- Optical Character Recognition (OCR) system, ParsCIT \n- further abridge the input text from level 2 preprocessed documents to the following: title, headers, abstract, introduction, related work, background and conclusion."], "all_classes": null, "length": 1822}
{"pred": "Yes", "answers": ["Yes", "Yes"], "all_classes": null, "length": 2077}
{"pred": "BLEU-4, NIST-4, and ROUGE-4", "answers": ["BLEU-4, NIST-4, ROUGE-4", "BLEU-4, NIST-4, ROUGE-4"], "all_classes": null, "length": 4460}
{"pred": "MIMIC-III database", "answers": ["MIMIC-III", "MIMIC-III"], "all_classes": null, "length": 2992}
{"pred": "r-net and AoA", "answers": ["SVM , CNN , GRU , CNN/GRU+law, r-net , AoA ", "SVM with lexical features in accordance with previous works BIBREF16 , BIBREF17 , BIBREF1 , BIBREF15 , BIBREF4, attention-based method BIBREF3 and other methods we deem important, some off-the-shelf RC models, including r-net BIBREF5 and AoA BIBREF6 , which are the leading models on SQuAD leaderboard"], "all_classes": null, "length": 4106}
{"pred": "The dataset sizes for each step of the hierarchy are not explicitly stated in the article.", "answers": ["Level A: 14100 Tweets\nLevel B: 4640 Tweets\nLevel C: 4089 Tweets"], "all_classes": null, "length": 2255}
{"pred": "Surface, morphological, and syntactic features", "answers": ["POS, gender/number and stem POS"], "all_classes": null, "length": 4719}
{"pred": "Attention captures information beyond alignment.", "answers": ["it captures other information rather than only the translational equivalent in the case of verbs", "Alignment points of the POS tags."], "all_classes": null, "length": 3372}
{"pred": "Larger values along the dimension associated with the semantic concept.", "answers": ["dimension corresponding to the concept that the particular word belongs to"], "all_classes": null, "length": 6182}
{"pred": "The article does not specify the language of the data.", "answers": ["English , German, French"], "all_classes": null, "length": 4173}
{"pred": "Bag-of-words, term frequency–inverse document frequency, Logistic Regression, Random Forest, TextCNN, and proposed model.", "answers": ["BOW-LR, BOW-RF. TFIDF-RF, TextCNN, C-TextCNN", "bag-of-words (BOW), term frequency–inverse document frequency (TFIDF), neural-based word embedding, Logistic Regression (LR), Random Forest (RF), TextCNN BIBREF10 with initial word embedding as GloVe"], "all_classes": null, "length": 3181}
{"pred": "They look at multiple tags.", "answers": ["Unanswerable", "48,705"], "all_classes": null, "length": 3307}
{"pred": "Unanswerable (The article does not provide information about whether the framework automatically optimizes for hyperparameters.)", "answers": ["Unanswerable", "Unanswerable"], "all_classes": null, "length": 4465}
{"pred": "Disinformation and mainstream news", "answers": ["mainstream news and disinformation", "mainstream and disinformation news"], "all_classes": null, "length": 4856}
{"pred": "\"Transformer base for MT, similar to berard2018end for ASR and ST, with 3 decoder layers.\"", "answers": ["follow the architecture in berard2018end, but have 3 decoder layers like that in pino2019harnessing"], "all_classes": null, "length": 2424}
{"pred": "CookingWorld and CoinCollector", "answers": ["CoinCollector , CookingWorld ", "CoinCollector, CookingWorld"], "all_classes": null, "length": 4924}
{"pred": "F @k and F @10", "answers": ["average unique predictions, randomly sample 2000 decoder hidden states at INLINEFORM4 steps following a delimiter ( INLINEFORM5 ) and apply an unsupervised clustering method (t-SNE BIBREF35 )"], "all_classes": null, "length": 4581}
{"pred": "Penn Treebank (PTB) and WikiText2 (WT-2) datasets", "answers": [" Penn Treebank, WikiText2", "Penn Treebank (PTB) , WikiText2 (WT-2)"], "all_classes": null, "length": 3302}
{"pred": "Their model captures biases in the process of collecting or annotating datasets.", "answers": ["Data annotation biases where tweet containing disrespectful words are annotated as hate or offensive without any presumption about the social context of tweeters"], "all_classes": null, "length": 4111}
{"pred": "Unanswerable (The article does not mention the use of graphical models)", "answers": ["No", "No"], "all_classes": null, "length": 3158}
{"pred": "\"Operation-guided networks and further constraining the model on the data structure\"", "answers": ["rther constrain the model on the data structure in order to prevent inaccurate of even contradictory descriptions", "to further constrain the model on the data structure in order to prevent inaccurate of even contradictory descriptions"], "all_classes": null, "length": 4704}
{"pred": "Prior knowledge distillation techniques are ineffective in producing student models with vocabularies different from the original teacher models because they require the student and teacher models to share the same vocabulary and output space.", "answers": ["While there has been existing work on reducing NLP model vocabulary sizes BIBREF15, distillation techniques cannot utilize these, since they require the student and teacher models to share the same vocabulary and output space. This profoundly limits their potential to further reduce model sizes.", "distillation techniques cannot utilize these, since they require the student and teacher models to share the same vocabulary and output space. This profoundly limits their potential to further reduce model sizes."], "all_classes": null, "length": 3570}
{"pred": "word2vec", "answers": ["using word2vec to create features that are used as input to the SVM", "use the word2vec algorithm, create several unsupervised hand-crafted features, generate document vectors and feed them as input into the support vector machines (SVM) approach"], "all_classes": null, "length": 3820}
{"pred": "From the internet.", "answers": ["ancient Chinese history records in several dynasties (about 1000BC-200BC) and articles written by celebrities of that era", "Ancient Chinese history records in several dynasties and articles written by celebrities during 1000BC-200BC collected from the internet "], "all_classes": null, "length": 3722}
{"pred": "Additive modification to the objective function is a term that encourages embedding vectors of a given concept word-group to achieve deliberately increased values along an associated dimension.", "answers": ["The cost function for any one of the words of concept word-groups is modified by the introduction of an additive term to the cost function. . Each embedding vector dimension is first associated with a concept. For a word belonging to any one of the word-groups representing these concepts, the modified cost term favors an increase for the value of this word's embedding vector dimension corresponding to the concept that the particular word belongs to,", "An additive term added to the cost function for any one of the words of concept word-groups"], "all_classes": null, "length": 6244}
{"pred": "Yes", "answers": ["Yes", "Yes"], "all_classes": null, "length": 7837}
{"pred": "Unanswerable (based on the provided article)", "answers": ["No"], "all_classes": null, "length": 1561}
{"pred": "It is based on Bert.", "answers": ["Bert model have a maximum length of 512; we overcome this limitation by adding more position embeddings, we insert external [cls] tokens at the start of each sentence, and each [cls] symbol collects features for the sentence preceding it, document representations are learned hierarchically"], "all_classes": null, "length": 4404}
{"pred": "Words embeddings, style, and morality features.", "answers": ["words embeddings, style, and morality features", "words embeddings, style, and morality features"], "all_classes": null, "length": 2091}
{"pred": "Improves through sparsity and adaptivity of attention heads.", "answers": ["the attention heads in the proposed adaptively sparse Transformer can specialize more and with higher confidence", "We introduce sparse attention into the Transformer architecture"], "all_classes": null, "length": 4902}
{"pred": "The article does not provide a quantitative comparison of the improvement in the attention mechanism.", "answers": ["Unanswerable", "Unanswerable"], "all_classes": null, "length": 5331}
{"pred": "United Nations Parallel Corpus, IIT Bombay corpus, OpenSubtitles 2018, XNLI dataset, Universal Dependencies v2.4.", "answers": ["United Nations Parallel Corpus, IIT Bombay corpus, OpenSubtitles 2018"], "all_classes": null, "length": 3405}
{"pred": "22,880 users", "answers": ["22,880 users", "20,000"], "all_classes": null, "length": 4160}
{"pred": "Unspecified in the article.", "answers": ["Unanswerable", "English"], "all_classes": null, "length": 2009}
{"pred": "Unanswerable", "answers": ["No", "No"], "all_classes": null, "length": 1899}
{"pred": "Instance is a sentence.", "answers": ["sentence"], "all_classes": null, "length": 4369}
{"pred": "Over 45,000 articles", "answers": ["45,000 scholarly articles, including over 33,000 with full text"], "all_classes": null, "length": 2150}
{"pred": "Compared baseline models", "answers": ["support vector machine classifier (SVM), logistic regression classifier (LR), Naive Bayes classifier (NB), random forest (RF), CNN, LSTM , LSTM-soft, LSTM-self", "support vector machine classifier (SVM), logistic regression classifier (LR), Naive Bayes classifier (NB), random forest (RF), CNN, LSTM , LSTM-soft, LSTM-self"], "all_classes": null, "length": 2895}
{"pred": "Harassment, personal attacks, general toxicity, and derailment of online conversations.", "answers": ["The Conversations Gone Awry dataset is labelled as either containing a personal attack from withint (i.e. hostile behavior by one user in the conversation directed towards another) or remaining civil throughout. The Reddit Change My View dataset is labelled with whether or not a coversation eventually had a comment removed by a moderator for violation of Rule 2: \"Don't be rude or hostile to others users.\""], "all_classes": null, "length": 4779}
{"pred": "Unanswerable (The article does not provide the number of electrodes used in the EEG sessions.)", "answers": ["1913 signals", "Unanswerable"], "all_classes": null, "length": 2361}
{"pred": "Datasets constructed from China Judgments Online are used in the experiment.", "answers": ["build a new one, collect INLINEFORM0 cases from China Judgments Online"], "all_classes": null, "length": 4109}
{"pred": "They measure style transfer success using human evaluation.", "answers": ["Unanswerable"], "all_classes": null, "length": 4572}
{"pred": "Conversational search, conversational question answering, conversational recommendation, and conversational natural language interface to structured and semi-structured data.", "answers": ["Co-Reference Resolution, Query Generation, Retrieval Model, Result Generation", "Co-Reference Resolution, Query Generation, Retrieval Model, Result Generation"], "all_classes": null, "length": 1701}
{"pred": "Unanswerable (The article does not provide a comparison with the best performing state-of-the-art.)", "answers": ["absolute improvement of 18.2% over the Pointer-Gen baseline"], "all_classes": null, "length": 4091}
{"pred": "Unanswerable (based on the information provided in the article)", "answers": ["Unanswerable"], "all_classes": null, "length": 1913}
{"pred": "Unanswerable (The article does not provide information about the accents present in the corpus.)", "answers": ["Unanswerable", "Unanswerable"], "all_classes": null, "length": 3794}
{"pred": "Using a group of 50 native people who were well-versed in both English and Tamil languages.", "answers": ["50 human annotators ranked a random sample of 100 translations by Adequacy, Fluency and overall ranking on a 5-point scale.", "adequacy, precision and ranking values"], "all_classes": null, "length": 5344}
{"pred": "SQuAD dataset", "answers": ["SQuAD", "SQuAD"], "all_classes": null, "length": 3757}
{"pred": "SemEval 2010 task 8 dataset", "answers": ["relation classification dataset of the SemEval 2010 task 8", "SemEval 2010 task 8 BIBREF8"], "all_classes": null, "length": 2393}
{"pred": "They use a joint model that combines visual features learned through Inception V3 with textual features learned through a biLSTM.", "answers": ["visual model is based on fine-tuning an Inception V3 model BIBREF1 over visual renderings of documents, while our textual model is based on a hierarchical biLSTM. We further combine the two into a joint model. , neural network models", "Inception V3, biLSTM"], "all_classes": null, "length": 4217}
{"pred": "The English corpus was twice the size of the Russian corpus.", "answers": ["2174000000, 989000000", "2174 million tokens for English and 989 million tokens for Russian"], "all_classes": null, "length": 2958}
{"pred": "Qualitative experiments are performed on the Text8 dataset.", "answers": ["Spearman correlation values of GM_KL model evaluated on the benchmark word similarity datasets.\nEvaluation results of GM_KL model on the entailment datasets such as entailment pairs dataset created from WordNet, crowdsourced dataset of 79 semantic relations labelled as entailed or not and annotated distributionally similar nouns dataset.", "Given a query word and component id, the set of nearest neighbours along with their respective component ids are listed"], "all_classes": null, "length": 2220}
{"pred": "The baseline is a weak NMT model without using any monolingual data.", "answers": ["pivot-based translation relying on a helping language BIBREF10, nduction of phrase tables from monolingual data BIBREF14 , attentional RNN-based model (RNMT) BIBREF2, Transformer model BIBREF18, bi-directional model BIBREF11, multi-to-multi (M2M) model BIBREF8, back-translation BIBREF17", "M2M Transformer"], "all_classes": null, "length": 4542}
{"pred": "Improves F1 by +0.58 for MRPC and +0.73 for QQP.", "answers": ["Using DSC loss improves the F1 score by +0.58 for MRPC and +0.73 for QQP", "+0.58"], "all_classes": null, "length": 3566}
{"pred": "Asymptotic variance is calculated using Fisher Information Matrix.", "answers": ["reducing the variance of an estimator,  EGL method in BIBREF3 is almost the same as Eq. ( EQREF8 ), except the gradient's norm is not squared in BIBREF3", " Fisher Information Ratio"], "all_classes": null, "length": 1671}
{"pred": "LSTM encoder", "answers": ["LSTM", "LSTM"], "all_classes": null, "length": 2289}
{"pred": "Natural language questions are present in the dataset.", "answers": ["These 8 tasks require different competencies and a different level of understanding of the document to be well answered"], "all_classes": null, "length": 3817}
{"pred": "Yes", "answers": ["SVM, No-Answer Baseline (NA) , Word Count Baseline, Human Performance", "No-Answer Baseline (NA), Word Count Baseline, Human Performance"], "all_classes": null, "length": 3855}
{"pred": "53", "answers": ["53 documents", "53 documents"], "all_classes": null, "length": 2667}
{"pred": "Food.com", "answers": ["from Food.com"], "all_classes": null, "length": 2649}
{"pred": "Intrinsic evaluations (word similarity and word analogy tasks) and downstream tasks (chunking, sentiment and question classification, and natural language identification) from the VecEval suite.", "answers": ["We also evaluate all five models on downstream tasks from the VecEval suite BIBREF13 , using only the tasks for which training and evaluation data is freely available: chunking, sentiment and question classification, and natural language identification (NLI). The default settings from the suite are used, but we run only the fixed settings, where the embeddings themselves are not tunable parameters of the models, forcing the system to use only the information already in the embeddings."], "all_classes": null, "length": 2083}
{"pred": "Number of Strongly Connected Components (SCC), Size of the Largest Strongly Connected Component (LSCC), Number of Weakly Connected Components (WCC), Size of the Largest Weakly Connected Component (LWCC), Diameter of the Largest Weakly Connected Component (DWCC), Average Clustering Coefficient (CC), Main K-core Number (KC), Density (d), Structural virality (SV)", "answers": ["Number of Strongly Connected Components (SCC), Size of the Largest Strongly Connected Component (LSCC), Number of Weakly Connected Components (WCC), Size of the Largest Weakly Connected Component (LWCC), Diameter of the Largest Weakly Connected Component (DWCC), Average Clustering Coefficient (CC), Main K-core Number (KC), Density (d)"], "all_classes": null, "length": 4906}
{"pred": "Lookup table embedding", "answers": ["QA PGNet, Multi-decoder QA PGNet with lookup table embedding", "QA PGNet and Multi-decoder QA PGNet"], "all_classes": null, "length": 4600}
{"pred": "Unanswerable (The article only lists 15 annotated phenotypes)", "answers": ["Adv. Heart Disease, Adv. Lung Disease, Alcohol Abuse, Chronic Neurologic Dystrophies, Dementia, Depression, Developmental Delay, Obesity, Psychiatric disorders and Substance Abuse"], "all_classes": null, "length": 1651}
{"pred": "Relation detection", "answers": ["answer questions by obtaining information from KB tuples ", "hierarchical matching between questions and relations with residual learning"], "all_classes": null, "length": 4527}
{"pred": "Unanswerable (average length is not provided in the article)", "answers": ["204 tokens", "Most texts, however, range roughly from 150 to 250 tokens."], "all_classes": null, "length": 1898}
{"pred": "Gradient-based reward learning algorithm from BIBREF7", "answers": ["BIBREF7", " reward learning algorithm BIBREF7"], "all_classes": null, "length": 4841}
{"pred": "They used BioASQ dataset.", "answers": ["BioASQ  dataset", "A dataset provided by BioASQ consisting of questions, gold standard documents, snippets, concepts  and ideal and ideal answers."], "all_classes": null, "length": 6810}
{"pred": "Patterns over words and part-of-speech (POS) tags are extracted.", "answers": ["(VVD shop_VV0 II, VVD shopping_VVG II)", "patterns for generating all types of errors"], "all_classes": null, "length": 2133}
{"pred": "Semi-manual Pyramid scores are used.", "answers": [" higher tiers of the pyramid", "following the pyramid framework, we design an annotation scheme"], "all_classes": null, "length": 4771}
{"pred": "Unanswerable (The article does not mention the study of numerical properties such as orthogonality of their obtained vectors.)", "answers": ["No", "No"], "all_classes": null, "length": 3974}
{"pred": "The models decide the importance of output words based on the integrated gradients method.", "answers": ["Given the contribution matrix, we can obtain the word importance of each input word to the entire output sentence. ", "They compute the gradient of the output at each time step with respect to the input words to decide the importance."], "all_classes": null, "length": 4253}
{"pred": "Random Kitchen Sink approach", "answers": ["Random Kitchen Sink method uses a kernel function to map data vectors to a space where linear separation is possible.", "explicitly maps data vectors to a space where linear separation is possible, RKS method provides an approximate kernel function via explicit mapping"], "all_classes": null, "length": 2361}
{"pred": "The state of the art models are those by BIBREF9 and BIBREF8.", "answers": ["BIBREF9 , BIBREF8 ", "BIBREF9 , BIBREF8"], "all_classes": null, "length": 4855}
{"pred": "They compare to a Big Transformer model and a variant where they share token embeddings between the encoder and decoder.", "answers": ["BIBREF11 , BIBREF26 "], "all_classes": null, "length": 1912}
{"pred": "Improved in both low data regime and class-imbalance problems.", "answers": ["Low data: SST-5, TREC, IMDB around 1-2 accuracy points better than baseline\nImbalanced labels: the improvement over the base model increases as the data gets more imbalanced, ranging from around 6 accuracy points on 100:1000 to over 20 accuracy points on 20:1000"], "all_classes": null, "length": 4880}
{"pred": "Improvements for error detection on both datasets.", "answers": ["Combining  pattern based and Machine translation approaches gave the best overall F0.5 scores. It was 49.11 for FCE dataset  , 21.87 for the first annotation of  CoNLL-14, and 30.13 for the second annotation of CoNLL-14. "], "all_classes": null, "length": 2164}
{"pred": "Multiple choice question answering.", "answers": ["MULTIPLE CHOICE QUESTION ANSWERING", "multiple-choice"], "all_classes": null, "length": 6396}
{"pred": "Named Entity Recognition, POS tagging, text classification, and language modeling.", "answers": ["None"], "all_classes": null, "length": 2473}
{"pred": "Waseem and Hovy, Davidson et al.", "answers": ["Waseem-dataset, Davidson-dataset,", "Waseem and Hovey BIBREF5, Davidson et al. BIBREF9"], "all_classes": null, "length": 4090}
{"pred": "Seven experts with legal training", "answers": ["Individuals with legal training", "Yes"], "all_classes": null, "length": 3846}
{"pred": "Transformer and RNN-Search", "answers": [" Transformer BIBREF1 model and the conventional RNN-Search model BIBREF0", "Transformer, RNN-Search model"], "all_classes": null, "length": 4240}
{"pred": "Machine learning-based methods have been applied to solve word segmentation in Vietnamese.", "answers": ["Maximum Entropy, Weighted Finite State Transducer (WFST),  support vector machines (SVM), conditional random fields (CRF)", "Maximum matching, Hidden Markov model , Maximum Entropy, Conditional Random Fields , Support Vector Machines"], "all_classes": null, "length": 3471}
{"pred": "\"By calculating the average unique predictions produced by the model.\"", "answers": ["average unique predictions, illustrate the difference of predictions between our proposed models, we show an example chosen from the KP20k validation set"], "all_classes": null, "length": 4576}
{"pred": "Evaluation protocol and baseline are proposed.", "answers": ["Answer with content missing: (Evaluation Metrics section) Precision, Recall, F1-scores, Strict match, METEOR, ROUGE-2"], "all_classes": null, "length": 4263}
{"pred": "Three named entity recognition models were evaluated: Stanford NER, spaCy 2.0, and a recurrent model with a CRF top layer.", "answers": ["Stanford NER, spaCy 2.0 , recurrent model with a CRF top layer", "Stanford NER, spaCy 2.0, recurrent model with a CRF top layer"], "all_classes": null, "length": 2759}
{"pred": "They compared 6-layers and 9-layers LSTM models.", "answers": ["Unidirectional LSTM networks with 2, 6, 7, 8, and  9 layers."], "all_classes": null, "length": 4286}
{"pred": "WN18 and FB15K", "answers": ["WordNet BIBREF0, Freebase BIBREF1, WN18 (a subset of WordNet) BIBREF24 , FB15K (a subset of Freebase) BIBREF2"], "all_classes": null, "length": 3367}
{"pred": "Both professional translation and machine translation introduce the artifacts.", "answers": ["Yes"], "all_classes": null, "length": 4073}
{"pred": "\"LastStateRNN\"", "answers": [" LastStateRNN, AvgRNN, AttentionRNN", "LastStateRNN, AvgRNN, AttentionRNN "], "all_classes": null, "length": 2823}
{"pred": "Personal attack, racism, and sexism", "answers": ["personal attack, racism, and sexism", "racism, sexism, personal attack, not specifically about any single topic"], "all_classes": null, "length": 3244}
{"pred": "Yes", "answers": ["Yes", "Yes"], "all_classes": null, "length": 3634}
{"pred": "Knowledge Aided Reader (KAR) is an end-to-end Machine Reading Comprehension (MRC) model.", "answers": ["Lexicon Embedding Layer, Context Embedding Layer, Coarse Memory Layer, Refined Memory Layer, Answer Span Prediction Layer"], "all_classes": null, "length": 4133}
{"pred": "Annotated Twitter dataset constructed based on a hierarchical model of depression-related symptoms", "answers": ["BIBREF12 , BIBREF13", "an existing, annotated Twitter dataset that was constructed based on a hierarchical model of depression-related symptoms BIBREF12 , BIBREF13"], "all_classes": null, "length": 1939}
{"pred": "The Nguni languages are similar to each other. The same is true of the Sotho languages.", "answers": ["Nguni languages (zul, xho, nbl, ssw), Sotho languages (nso, sot, tsn)", "The Nguni languages are similar to each other, The same is true of the Sotho languages"], "all_classes": null, "length": 1877}
{"pred": "IMDb dataset", "answers": ["IMDb dataset of movie reviews", "IMDb"], "all_classes": null, "length": 2327}
{"pred": "Improving the sensationalism scorer and investigating the applications of dynamic balancing methods between RL and MLE in textGAN.", "answers": ["ethical questions about generating sensational headlines, which can be further explored,  improving the sensationalism scorer, investigating the applications of dynamic balancing methods between RL and MLE"], "all_classes": null, "length": 4104}
{"pred": "89.6% and 89.2% accuracy and F1-score, respectively.", "answers": ["accuracy and F1-score of 89.6% and 89.2%, respectively", "accuracy and F1-score of 89.6% and 89.2%, respectively"], "all_classes": null, "length": 3313}
{"pred": "The dataset models character's profiles based on Human Level Attributes (HLAs) collected from TV Tropes.", "answers": ["attributes are determined by human viewers and their impressions of the characters, and are correlated with human-like characteristics"], "all_classes": null, "length": 5136}
{"pred": "Reuters database", "answers": ["Reuters-8 dataset without stop words", "The Reuters-8 dataset (with stop words removed)"], "all_classes": null, "length": 5147}
{"pred": "Out-performs K-means, LEM, and DPEMM.", "answers": ["K-means, LEM BIBREF13, DPEMM BIBREF14", "K-means, LEM, DPEMM"], "all_classes": null, "length": 3841}
{"pred": "Accuracy is demonstrated through empirical evaluation.", "answers": ["significant improvements clearly demonstrate that our approach is effective at improving model performance", "By evaluating the performance of the approach using accuracy and AUC"], "all_classes": null, "length": 4489}
{"pred": "8 languages: English, German, Spanish, Mandarin, Polish, Russian, Korean, Serbian.", "answers": ["English, German, Spanish, Mandarin, Polish, Russian, Korean and Serbian", "English (Edinburgh), German (Berlin), Spanish (Madrid), Mandarin (Taipei), Polish (Warsaw), Russian (Moscow), Korean (Seoul), and Serbian (Belgrade)"], "all_classes": null, "length": 2754}
{"pred": "The datasets are not explicitly stated in the article.", "answers": ["rupnik2016news", "rupnik2016news, Deutsche Welle's news website"], "all_classes": null, "length": 3160}
{"pred": "The authors present evidence that the model can capture some biases in data annotation and collection by examining the results and conducting a manual inspection on a subset of the data.", "answers": ["The authors showed few tweets where neither and implicit hatred content exist but the model was able to discriminate"], "all_classes": null, "length": 4119}
{"pred": "SimpleQuestions and WebQSP", "answers": ["SimpleQuestions, WebQSP", "WebQSP, SimpleQuestions"], "all_classes": null, "length": 4524}
{"pred": "Unanswerable (The article does not specify whether the lexicon is the same for all languages or not.)", "answers": ["Yes", "Yes"], "all_classes": null, "length": 1868}
{"pred": "Grammatical, spelling and word order errors", "answers": ["grammatical, spelling and word order errors", "spelling, word order and grammatical errors"], "all_classes": null, "length": 4579}
{"pred": "InferSent, Universal Sentence Encoder, and average GloVe embeddings are evaluated.", "answers": ["GloVe, BERT, Universal Sentence Encoder, TF-IDF, InferSent", "Avg. GloVe embeddings, Avg. fast-text embeddings, Avg. BERT embeddings, BERT CLS-vector, InferSent - GloVe and Universal Sentence Encoder."], "all_classes": null, "length": 3862}
{"pred": "Crawled over 2M tweets from twitter.", "answers": ["They developed a classifier to find ironic sentences in twitter data", "by crawling"], "all_classes": null, "length": 4599}
{"pred": "SentEval transfer tasks are evaluated.", "answers": ["MR, CR, SUBJ, MPQA, SST, TREC, MRPC", "MR: Sentiment prediction for movie reviews snippets on a five start scale BIBREF25.\n\nCR: Sentiment prediction of customer product reviews BIBREF26.\n\nSUBJ: Subjectivity prediction of sentences from movie reviews and plot summaries BIBREF27.\n\nMPQA: Phrase level opinion polarity classification from newswire BIBREF28.\n\nSST: Stanford Sentiment Treebank with binary labels BIBREF29.\n\nTREC: Fine grained question-type classification from TREC BIBREF30.\n\nMRPC: Microsoft Research Paraphrase Corpus from parallel news sources BIBREF31.", "Semantic Textual Similarity, sentiment prediction, subjectivity prediction, phrase level opinion polarity classification, Stanford Sentiment Treebank, fine grained question-type classification."], "all_classes": null, "length": 3861}
{"pred": "Unanswerable (the article does not provide information about the size of the vocabulary)", "answers": ["33,663", "33,663 distinct review keywords "], "all_classes": null, "length": 3305}
{"pred": "Context tweets are proposed as additional features.", "answers": ["using tweets that one has replied or quoted to as contextual information", "text sequences of context tweets"], "all_classes": null, "length": 2060}
{"pred": "Yes", "answers": ["No", "No"], "all_classes": null, "length": 1906}
{"pred": "Global context refers to the representation of the whole document, while local context refers to the representation of the topic segment (e.g., section/topic) of a sentence.", "answers": ["global (the whole document), local context (e.g., the section/topic)", "global (the whole document) and the local context (e.g., the section/topic) "], "all_classes": null, "length": 4287}
{"pred": "Knowledge Base Question Answering (KBQA)", "answers": ["Knowledge Base Question Answering", "Knowledge Base Question Answering "], "all_classes": null, "length": 4521}
{"pred": "No. The article describes the creation of maps reflecting demographic, linguistic, and psycholinguistic properties of a dataset of bloggers, but does not mention building a model to automatically detect these dimensions.", "answers": ["No", "No"], "all_classes": null, "length": 1443}
{"pred": "They utilize LDA and Gibbs sampling to learn a topic model and obtain the topic models of ISWC and WWW publications.", "answers": ["the LDA approaches to recommendation systems and given the importance of research, we have studied recent impressive articles on this subject and presented a taxonomy of recommendation systems based on LDA of the recent research, we evaluated ISWC and WWW conferences articles from DBLP website and used the Gibbs sampling algorithm as an evaluation parameter", "discover the trends of the topics and find relationship between LDA topics and paper features and generate trust tags,  learn a LDA model with 100 topics; $\\alpha =0.01$, $\\beta = 0.01$ and using Gibbs sampling as a parameter estimation"], "all_classes": null, "length": 4322}
{"pred": "Yes.", "answers": ["Yes", "Yes"], "all_classes": null, "length": 4127}
{"pred": "Imbalanced (33.16% women, 66.84% men)", "answers": ["Women represent 33.16% of the speakers"], "all_classes": null, "length": 4055}
{"pred": "Ensemble+ of (r4, r7, r12) is ranked 4th in SLC task. Ensemble+ of (II and IV) is ranked 3rd in FLC task.", "answers": ["For SLC task, the \"ltuorp\" team  has the best performing  model (0.6323/0.6028/0.6649 for F1/P/R  respectively) and for FLC task the \"newspeak\" team  has the best performing  model (0.2488/0.2863/0.2201 for F1/P/R respectively)."], "all_classes": null, "length": 1541}
{"pred": "Baseline model was always \"Yes\".", "answers": ["by answering always YES (in batch 2 and 3) "], "all_classes": null, "length": 6817}
{"pred": "DTA18 and DTA19", "answers": ["DTA18, DTA19", "Diachronic Usage Relatedness (DURel) gold standard data set"], "all_classes": null, "length": 1908}
{"pred": "13,757 question-answer pairs", "answers": ["13,757", "10,898 articles, 17,794 tweets, and 13,757 crowdsourced question-answer pairs"], "all_classes": null, "length": 3704}
{"pred": "0.7033 (for List-type question answering task)", "answers": ["0.7033", "0.7033"], "all_classes": null, "length": 6810}
{"pred": "KNN, Random Forest, Support Vector Machine, and Multi-layer Perceptron", "answers": ["KNN\nRF\nSVM\nMLP", " K Nearest Neighbors (KNN), Random Forest (RF), Support Vector Machine (SVM), Multi-layer Perceptron (MLP)"], "all_classes": null, "length": 1639}
{"pred": "BLEU, NIST, METEOR, ROUGE-L, and CIDEr metrics were used to evaluate the generated text.", "answers": ["BLEU , NIST , METEOR , ROUGE-L, CIDEr , evaluation script, automatic evaluation, human evaluation, minimum edit evaluation, word error rate (WER), factual errors and their types, fluency issues, acceptability of the output for production use in a news agency", "BLEU, NIST, METEOR, ROUGE-L, CIDEr"], "all_classes": null, "length": 4738}
{"pred": "They obtain the new context representation by splitting the contexts into three disjoint regions based on the two relation arguments: the left context, the middle context and the right context.", "answers": ["They use two independent convolutional and max-pooling layers on (1) a combination of the left context, the left entity and the middle context; and (2) a combination of the middle context, the right entity and the right context. They concatenated the two results after pooling to get the new context representation."], "all_classes": null, "length": 2435}
{"pred": "Multinomial Naive Bayes classifier", "answers": ["AllWords model by counting the frequencies of all the remaining words and training a multinomial Naive Bayes classifier"], "all_classes": null, "length": 4177}
{"pred": "Multi-granularity and multi-tasking in neural architecture design.", "answers": ["An output layer for each task", "Multi-tasking is addressed by neural sequence tagger based on LSTM-CRF and linguistic features, while multi-granularity is addressed by ensemble of LSTM-CRF and BERT."], "all_classes": null, "length": 1514}
{"pred": "Two real-world datasets, CyberAttack and PoliticianDeath, are used.", "answers": ["Tweets related to CyberAttack and tweets related to PoliticianDeath", "cyber security (CyberAttack), death of politicians (PoliticianDeath)"], "all_classes": null, "length": 4481}
{"pred": "Logistic Regression and Deep Neural Networks (DNNs)", "answers": ["Logistic Regression, neural networks"], "all_classes": null, "length": 7257}
{"pred": "Conditional Copy (CC) model", "answers": ["Conditional Copy (CC) model ", "delayed copy model (DEL),  template system (TEM), conditional copy (CC), NCP+CC (NCP)"], "all_classes": null, "length": 4746}
{"pred": "The CORD-19 dataset is a collection of over 45,000 scholarly articles about COVID-19, SARS-CoV-2, and related coronaviruses.", "answers": ["which contains over 45,000 scholarly articles, including over 33,000 with full text, about COVID-19, SARS-CoV-2, and related coronaviruses", "contains over 45,000 scholarly articles, including over 33,000 with full text, about COVID-19, SARS-CoV-2, and related coronaviruses"], "all_classes": null, "length": 2156}
{"pred": "4528 employees", "answers": ["26972", "26972 sentences"], "all_classes": null, "length": 3040}
{"pred": "Performs favorably against recent neural network-based approaches to grammar induction.", "answers": ["Unanswerable", "Unanswerable"], "all_classes": null, "length": 2533}
{"pred": "Invertibility condition: The neural projector must have two requirements: (1) it must be invertible and (2) its inverse must exist.", "answers": ["The neural projector must be invertible.", "we constrain our neural projector with two requirements: (1) INLINEFORM0 and (2) INLINEFORM1 exists"], "all_classes": null, "length": 4323}
{"pred": "Logistic Regression and Multilayer Perceptron", "answers": ["probabilistic model", "Logistic Regression, Multilayer Perceptron"], "all_classes": null, "length": 4475}
{"pred": "Backoff strategies pass the input as is, back off to a neutral word, or fall back upon a more generic word recognizer trained on a larger corpus when the foreground model predicts UNK.", "answers": ["In pass-through, the recognizer passes on the possibly misspelled word, backoff to neutral word backs off to a word with similar distribution across classes and backoff to background model backs off to a more generic word recognition model trained with larger and less specialized corpus.", "Pass-through passes the possibly misspelled word as is, backoff to neutral word backs off to a word with similar distribution across classes and backoff to background model backs off to a more generic word recognition model trained with larger and less specialized corpus.", "Backoff to \"a\" when an UNK-predicted word is encountered, backoff to a more generic word recognition model when the model predicts UNK"], "all_classes": null, "length": 4210}
{"pred": "The size of the real-world civil case dataset is not explicitly stated in the article.", "answers": ["100 000 documents", " INLINEFORM1 cases"], "all_classes": null, "length": 4104}
{"pred": "Crowdsourcing on Amazon Mechanical Turk.", "answers": ["The data was collected using 3 components: describe a series of pilot studies that were conducted to collect commonsense inference questions, then discuss the resulting data collection of questions, texts and answers via crowdsourcing on Amazon Mechanical Turk and gives information about some necessary postprocessing steps and the dataset validation."], "all_classes": null, "length": 4536}
{"pred": "The Neural User Simulator (NUS) is learned from a corpus of recorded dialogues.", "answers": ["DSTC2", "The manual transcriptions of the DSTC2 training set "], "all_classes": null, "length": 4820}
{"pred": "Data augmentation methods were used to increase the amount of training data.", "answers": ["Back Translation, Mix-Source Approach", "data augmentation"], "all_classes": null, "length": 4123}
{"pred": "BLEU-4, NIST-4, and ROUGE-4", "answers": ["BLEU-4, NIST-4, ROUGE-4", "BLEU-4, NIST-4, ROUGE-4"], "all_classes": null, "length": 4460}
{"pred": "Outperformance of proposed model compared to baselines.", "answers": ["Metric difference between Aloha and best baseline score:\nHits@1/20: +0.061 (0.3642 vs 0.3032)\nMRR: +0.0572(0.5114 vs 0.4542)\nF1: -0.0484 (0.3901 vs 0.4385)\nBLEU: +0.0474 (0.2867 vs 0.2393)"], "all_classes": null, "length": 5151}
{"pred": "r-net and AoA", "answers": ["SVM , CNN , GRU , CNN/GRU+law, r-net , AoA ", "SVM with lexical features in accordance with previous works BIBREF16 , BIBREF17 , BIBREF1 , BIBREF15 , BIBREF4, attention-based method BIBREF3 and other methods we deem important, some off-the-shelf RC models, including r-net BIBREF5 and AoA BIBREF6 , which are the leading models on SQuAD leaderboard"], "all_classes": null, "length": 4106}
{"pred": "Surface, morphological, and syntactic features", "answers": ["POS, gender/number and stem POS"], "all_classes": null, "length": 4719}
{"pred": "Larger values along the dimension associated with the semantic concept.", "answers": ["dimension corresponding to the concept that the particular word belongs to"], "all_classes": null, "length": 6182}
{"pred": "Characteristics of Arabic offensive language include animal analogies, insults to family members, sexually-related insults, damnation, attacks on morals and ethics, and name alteration.", "answers": ["Frequent use of direct animal name calling, using simile and metaphors, through indirect speech like sarcasm, wishing evil to others, name alteration, societal stratification, immoral behavior and sexually related uses.", "Direct name calling, Simile and metaphor, Indirect speech, Wishing Evil, Name alteration, Societal stratification, Immoral behavior, Sexually related"], "all_classes": null, "length": 4566}
{"pred": "The article does not specify the language of the data.", "answers": ["English , German, French"], "all_classes": null, "length": 4173}
{"pred": "Unanswerable (The article does not provide information about whether the framework automatically optimizes for hyperparameters.)", "answers": ["Unanswerable", "Unanswerable"], "all_classes": null, "length": 4465}
{"pred": "Disinformation and mainstream news", "answers": ["mainstream news and disinformation", "mainstream and disinformation news"], "all_classes": null, "length": 4856}
{"pred": "The authors show that their learned policy generalizes better than existing solutions to unseen games by achieving a higher score in the zero-shot setting of CookingWorld games.", "answers": ["promising results by solving almost half of the unseen games, most of the lost games are in the hardest set, where a very long sequence of actions is required for winning the game"], "all_classes": null, "length": 4964}
{"pred": "CookingWorld and CoinCollector", "answers": ["CoinCollector , CookingWorld ", "CoinCollector, CookingWorld"], "all_classes": null, "length": 4924}
{"pred": "F @k and F @10", "answers": ["average unique predictions, randomly sample 2000 decoder hidden states at INLINEFORM4 steps following a delimiter ( INLINEFORM5 ) and apply an unsupervised clustering method (t-SNE BIBREF35 )"], "all_classes": null, "length": 4581}
{"pred": "Investigating NLP gender bias specifically in the news broadcast domain and Anchor role aims to understand the impact of gender disparity on ASR performance.", "answers": ["create fair systems", " broadcast recordings are also a valuable source of data for the speech processing community, recent works uncovering gender bias in several natural language processing (NLP) tools"], "all_classes": null, "length": 4063}
{"pred": "Their model captures biases in the process of collecting or annotating datasets.", "answers": ["Data annotation biases where tweet containing disrespectful words are annotated as hate or offensive without any presumption about the social context of tweeters"], "all_classes": null, "length": 4111}
{"pred": "They build a predictive model for dogmatism using linguistic features.", "answers": ["logistic regression models", "logistic regression models based on unigram bag-of-words features (BOW), sentiment signals (SENT), the linguistic features from our earlier analyses (LING), and combinations of these features."], "all_classes": null, "length": 4208}
{"pred": "Yes", "answers": ["No", "Unanswerable"], "all_classes": null, "length": 4181}
{"pred": "\"Operation-guided networks and further constraining the model on the data structure\"", "answers": ["rther constrain the model on the data structure in order to prevent inaccurate of even contradictory descriptions", "to further constrain the model on the data structure in order to prevent inaccurate of even contradictory descriptions"], "all_classes": null, "length": 4704}
{"pred": "Message Passing Attention network for Document understanding (MPAD)", "answers": ["doc2vec , CNN, DAN, Tree-LSTM, DRNN, LSTMN, C-LSTM, SPGK, WMD, S-WMD, Semantic-CNN, LSTM-GRNN, HN-ATT"], "all_classes": null, "length": 4169}
{"pred": "Additive modification to the objective function is a term that encourages embedding vectors of a given concept word-group to achieve deliberately increased values along an associated dimension.", "answers": ["The cost function for any one of the words of concept word-groups is modified by the introduction of an additive term to the cost function. . Each embedding vector dimension is first associated with a concept. For a word belonging to any one of the word-groups representing these concepts, the modified cost term favors an increase for the value of this word's embedding vector dimension corresponding to the concept that the particular word belongs to,", "An additive term added to the cost function for any one of the words of concept word-groups"], "all_classes": null, "length": 6244}
{"pred": "Yes", "answers": ["Yes", "Yes"], "all_classes": null, "length": 7837}
{"pred": "They measure under-translated words by comparing words of least importance with human-annotated under-translated words.", "answers": ["They measured the under-translated words with low word importance score as calculated by Attribution.\nmethod", "we ask ten human annotators to manually label the under-translated input words, and at least two annotators label each input-hypothesis pair"], "all_classes": null, "length": 4246}
{"pred": "It is based on Bert.", "answers": ["Bert model have a maximum length of 512; we overcome this limitation by adding more position embeddings, we insert external [cls] tokens at the start of each sentence, and each [cls] symbol collects features for the sentence preceding it, document representations are learned hierarchically"], "all_classes": null, "length": 4404}
{"pred": "Wikipedia and CMV datasets", "answers": [" `Conversations Gone Awry' dataset, subreddit ChangeMyView", "An expanded version of the existing 'Conversations Gone Awry' dataset and the ChangeMyView dataset, a subreddit whose only annotation is whether the conversation required action by the Reddit moderators. "], "all_classes": null, "length": 4718}
{"pred": "Yes", "answers": ["No"], "all_classes": null, "length": 4117}
{"pred": "Europarl corpus", "answers": ["Europarl corpus , WMT newstest 2014, News-Commentary-11, Wikipedia from WMT 2014, Multi-UN, EU-Bookshop, Rapid, Common-Crawl (WMT 2017)", "Europarl tests from 2006, 2007, 2008; WMT newstest 2014."], "all_classes": null, "length": 4184}
{"pred": "Improves through sparsity and adaptivity of attention heads.", "answers": ["the attention heads in the proposed adaptively sparse Transformer can specialize more and with higher confidence", "We introduce sparse attention into the Transformer architecture"], "all_classes": null, "length": 4902}
{"pred": "Yes", "answers": ["No", "No"], "all_classes": null, "length": 4484}
{"pred": "The article does not provide a quantitative comparison of the improvement in the attention mechanism.", "answers": ["Unanswerable", "Unanswerable"], "all_classes": null, "length": 5331}
{"pred": "22,880 users", "answers": ["22,880 users", "20,000"], "all_classes": null, "length": 4160}
{"pred": "Instance is a sentence.", "answers": ["sentence"], "all_classes": null, "length": 4369}
{"pred": "Harassment, personal attacks, general toxicity, and derailment of online conversations.", "answers": ["The Conversations Gone Awry dataset is labelled as either containing a personal attack from withint (i.e. hostile behavior by one user in the conversation directed towards another) or remaining civil throughout. The Reddit Change My View dataset is labelled with whether or not a coversation eventually had a comment removed by a moderator for violation of Rule 2: \"Don't be rude or hostile to others users.\""], "all_classes": null, "length": 4779}
{"pred": "A second-order co-occurrence matrix is a matrix where the similarity between two words is not strictly based on their co-occurrence frequencies, but rather on the frequencies of the other words which occur with both of them (i.e., second order co-occurrences).", "answers": ["frequencies of the other words which occur with both of them (i.e., second order co–occurrences)", "The matrix containing co-occurrences of the words which occur with the both words of every given pair of words."], "all_classes": null, "length": 4271}
{"pred": "Datasets constructed from China Judgments Online are used in the experiment.", "answers": ["build a new one, collect INLINEFORM0 cases from China Judgments Online"], "all_classes": null, "length": 4109}
{"pred": "Precision, recall, F1 and accuracy", "answers": ["precision, recall, F1 and accuracy", "precision, recall, F1 , accuracy "], "all_classes": null, "length": 4101}
{"pred": "They measure style transfer success using human evaluation.", "answers": ["Unanswerable"], "all_classes": null, "length": 4572}
