{"pred": "Foxsetified dataset data as (development: Time, CNN, is (un-based set is used for training: unanswered-wise: Guard, Sponot2) BIB's or set, yes, sad, yes, or (yes,1 orchestred, or (Guard) or B-no: is, or un-ret, or-ent, is un-S- (F- (S-wise-un-super, or-super) data, is) or-emotion- or- or- S- S- for-m, or-S-S", "answers": ["FoxNews, CNN, ESPN, New York Times, Time magazine, Huffington Post Weird News, The Guardian, Cartoon Network, Cooking Light, Home Cooking Adventure, Justin Bieber, Nickelodeon, Spongebob, Disney", "FoxNews, CNN, ESPN, New York Times, Time magazine, Huffington Post Weird News, The Guardian, Cartoon Network, Cooking Light, Home Cooking Adventure, Justin Bieber, Nickelodeon, Spongebob, Disney."], "all_classes": null, "length": 3411}
{"pred": "Latent (Unig3: unmodels INLINEFORM6, or or unspecifically/un or INFORM0 and INLINEFORM6 is INFORM6 is not.", "answers": ["the series of posts that trigger an intervention"], "all_classes": null, "length": 3732}
{"pred": "\"Yes (articlesfasm (unigoused inference-t of thecite-based on-sarc-un-unanswering (yes, learned-of-reg (un-answer, unprov-no-un (un, unod (un, unanswer, or \"sarc) or yes, un, \" un-in-no, un- yes, yes, the improvement, when-un-s-un-of, unanswer--sarc-score, un-no-the-no-un- the- no-s, the un, yes, s", "answers": ["F-score, Kappa", "Unanswerable"], "all_classes": null, "length": 3544}
{"pred": "The article-LST-p-dears out or \" yes\"\".\".", "answers": ["(i) models that use plain stacked LSTMs, (ii) models with different INLINEFORM0, (iii) models without INLINEFORM1, (iv) models that integrate lower contexts via peephole connections"], "all_classes": null, "length": 3224}
{"pred": "No: Yes or (unl (yes, Yes! ALso) uni (unless:) (jiant) or \"un\"jiant (un pull-m)n) une (un) pull, Yes:) jian (, un (,) un i (G) or pull) or \"unl\",) (S) (ji (b,) jiant) (un,) (super) (un, super) (bi, super) (SIL) (yes,) (S) (yes) super) (yes, and un)\n (un, and", "answers": ["Yes", "Unanswerable"], "all_classes": null, "length": 2284}
{"pred": "Unrelated to the introduction of the questions abouti-ans PQREF1 or-Elder, by-question-ans as-no-E Et-Et-ALPrivacy questions thata Unanswer-E-Ener-Ref, yes, unanswer-E-E-no-Privis-E-policy of-E-E-E-E-C-E-Priv- no-Un-Art-yes-no-C-Ana-E-E-yes, E-1 un-E-E-E-E-E-E-E-27", "answers": ["No"], "all_classes": null, "length": 3843}
{"pred": "Modestic: Yes or aids (BIBSynthesever's (9 or-1BIBIs) and a (sy) or BIBREF1, or BIBSTHEGs from (sBIBPERRREF (or) or \"yes or (yes-1) the tasks or the label or BIB1, or \"he or ':1,R, or\nSECH, or (1) or (w) or (8) the mSyno-probes\n\nNo BIB1:yes (20-un BIBREF20", "answers": ["Yes", "No"], "all_classes": null, "length": 2317}
{"pred": "Four sets of coraising on-domain-provable (yes. (un BOTBSC) and AMBSF-unanswer) means thata on the information \"research: \"yes\", orals from BOT and unclassa: yes, A-RNN-unanswer: unanswer or A RNN, A (yes, A B, or RNN or- A, The A RNN approach, RNN-based approach: English and A, A, A, RNN, A, A, BIBLREF5, A, B, B, RNN, lex", "answers": ["SemEval-2016 Challenge Task 5 BIBREF27 , BIBREF28", " English reviews ,  restaurant reviews from four different languages (Spanish, Turkish, Dutch, Russian)"], "all_classes": null, "length": 2720}
{"pred": "Improder improvements are un-f-s as \"unanswer-ROREFREF_EL_unanswer: yes (unclear (unanswer: topic-attention) (topic-tun_rep, improvements, model: yes (un-context:topic-s-medial-DREM, unenhancement of-topic:fabs, under:s_word, improvements).", "answers": ["7.36% on accuracy and 9.69% on F1 score", "it has 0.024 improvement in accuracy comparing to ELMO Only and  0.006 improvement in F1 score  comparing to ELMO Only too"], "all_classes": null, "length": 2890}
{"pred": "They use \"unf's or the proposed models (yes or not-error-INLINE or or un-un-the or the proposed models or the transcripts, no, yes or-the-their-un\". HMM- un or, H- or or, the audio-un, un-the IEMODE or- the unform-un- or-B-un or- the paper or- or-un- the article, the un- the audio, the IECODER or-un-the method as- or or- or- or, the un-un- or", "answers": ["They use text transcription.", "both"], "all_classes": null, "length": 3198}
{"pred": "Closcizing \"S, unanswer\". Yes-n-ALS, (or LAP BCLBREF1, unanswer-A Clusty, Clustered noun4.", "answers": ["CLUTO, Carrot2 Lingo", "simple clustering algorithm which uses the cosine similarity between word embeddings"], "all_classes": null, "length": 3039}
{"pred": "BERT-QAZZAsk, BIBS-dREF1 questions are unanswerable as-Echoz questions that share-QA, BIBREF-QA yes, yes-QA no-BIBRT-o-QA is 10.10 is the question is-class-1-1, yesAQ-A, yes/1754-10-1 is 17-5-1-1- and evidence-18-E is the QA-1-A-18-4-3-1-quest-", "answers": ["Bert + Unanswerable", "CNN, BERT"], "all_classes": null, "length": 3845}
{"pred": "PVT or BFores-vowers-to-zero-reference-BIBSTRM, \"BERT-Bes-BRLM, BPEBIBREF-BABBiling BilingB, or BMT-to-Biberset-m B-Bibow--A-r-BRE-language,BRE-BRE-BERT-language-v, the question for the p-zero-B-BRLM-A, B-BRE-M, p-source-B-m-m-MLM-B-m-B", "answers": ["pivoting, pivoting$_{\\rm m}$", "firstly translates a source language into the pivot language which is later translated to the target language"], "all_classes": null, "length": 3815}
{"pred": "Em-conversed-sub-task-un-tune-s: \"es-based-form or \"W\"\n BIBREF: \"W\" of \"W-W\" are \"W, Chat-t\" or competition-emotion \"W\" or experiment-W in the detail-80W\" un-s-W: \"W\", the experiment-based on the question-s-form-s competition-un-based-t-ChatB-c-m-W-\"-s\" pre-t-un-Emotion- \"W\" and section-s", "answers": ["Friends, EmotionPush", "EmotionLines BIBREF6"], "all_classes": null, "length": 3178}
{"pred": "Foxsetified dataset data as (development: Time, CNN, is (un-based set is used for training: unanswered-wise: Guard, Sponot2) BIB's or set, yes, sad, yes, or (yes,1 orchestred, or (Guard) or B-no: is, or un-ret, or-ent, is un-S- (F- (S-wise-un-super, or-super) data, is) or-emotion- or- or- S- S- for-m, or-S-S", "answers": ["FoxNews, CNN, ESPN, New York Times, Time magazine, Huffington Post Weird News, The Guardian, Cartoon Network, Cooking Light, Home Cooking Adventure, Justin Bieber, Nickelodeon, Spongebob, Disney", "FoxNews, CNN, ESPN, New York Times, Time magazine, Huffington Post Weird News, The Guardian, Cartoon Network, Cooking Light, Home Cooking Adventure, Justin Bieber, Nickelodeon, Spongebob, Disney."], "all_classes": null, "length": 3411}
{"pred": "Latent (Unig3: unmodels INLINEFORM6, or or unspecifically/un or INFORM0 and INLINEFORM6 is INFORM6 is not.", "answers": ["the series of posts that trigger an intervention"], "all_classes": null, "length": 3732}
{"pred": "\"Yes (articlesfasm (unigoused inference-t of thecite-based on-sarc-un-unanswering (yes, learned-of-reg (un-answer, unprov-no-un (un, unod (un, unanswer, or \"sarc) or yes, un, \" un-in-no, un- yes, yes, the improvement, when-un-s-un-of, unanswer--sarc-score, un-no-the-no-un- the- no-s, the un, yes, s", "answers": ["F-score, Kappa", "Unanswerable"], "all_classes": null, "length": 3544}
{"pred": "The article-LST-p-dears out or \" yes\"\".\".", "answers": ["(i) models that use plain stacked LSTMs, (ii) models with different INLINEFORM0, (iii) models without INLINEFORM1, (iv) models that integrate lower contexts via peephole connections"], "all_classes": null, "length": 3224}
{"pred": "No: Yes or (unl (yes, Yes! ALso) uni (unless:) (jiant) or \"un\"jiant (un pull-m)n) une (un) pull, Yes:) jian (, un (,) un i (G) or pull) or \"unl\",) (S) (ji (b,) jiant) (un,) (super) (un, super) (bi, super) (SIL) (yes,) (S) (yes) super) (yes, and un)\n (un, and", "answers": ["Yes", "Unanswerable"], "all_classes": null, "length": 2284}
{"pred": "Unrelated to the introduction of the questions abouti-ans PQREF1 or-Elder, by-question-ans as-no-E Et-Et-ALPrivacy questions thata Unanswer-E-Ener-Ref, yes, unanswer-E-E-no-Privis-E-policy of-E-E-E-E-C-E-Priv- no-Un-Art-yes-no-C-Ana-E-E-yes, E-1 un-E-E-E-E-E-E-E-27", "answers": ["No"], "all_classes": null, "length": 3843}
{"pred": "Modestic: Yes or aids (BIBSynthesever's (9 or-1BIBIs) and a (sy) or BIBREF1, or BIBSTHEGs from (sBIBPERRREF (or) or \"yes or (yes-1) the tasks or the label or BIB1, or \"he or ':1,R, or\nSECH, or (1) or (w) or (8) the mSyno-probes\n\nNo BIB1:yes (20-un BIBREF20", "answers": ["Yes", "No"], "all_classes": null, "length": 2317}
{"pred": "Four sets of coraising on-domain-provable (yes. (un BOTBSC) and AMBSF-unanswer) means thata on the information \"research: \"yes\", orals from BOT and unclassa: yes, A-RNN-unanswer: unanswer or A RNN, A (yes, A B, or RNN or- A, The A RNN approach, RNN-based approach: English and A, A, A, RNN, A, A, BIBLREF5, A, B, B, RNN, lex", "answers": ["SemEval-2016 Challenge Task 5 BIBREF27 , BIBREF28", " English reviews ,  restaurant reviews from four different languages (Spanish, Turkish, Dutch, Russian)"], "all_classes": null, "length": 2720}
{"pred": "Improder improvements are un-f-s as \"unanswer-ROREFREF_EL_unanswer: yes (unclear (unanswer: topic-attention) (topic-tun_rep, improvements, model: yes (un-context:topic-s-medial-DREM, unenhancement of-topic:fabs, under:s_word, improvements).", "answers": ["7.36% on accuracy and 9.69% on F1 score", "it has 0.024 improvement in accuracy comparing to ELMO Only and  0.006 improvement in F1 score  comparing to ELMO Only too"], "all_classes": null, "length": 2890}
{"pred": "They use \"unf's or the proposed models (yes or not-error-INLINE or or un-un-the or the proposed models or the transcripts, no, yes or-the-their-un\". HMM- un or, H- or or, the audio-un, un-the IEMODE or- the unform-un- or-B-un or- the paper or- or-un- the article, the un- the audio, the IECODER or-un-the method as- or or- or- or, the un-un- or", "answers": ["They use text transcription.", "both"], "all_classes": null, "length": 3198}
{"pred": "Closcizing \"S, unanswer\". Yes-n-ALS, (or LAP BCLBREF1, unanswer-A Clusty, Clustered noun4.", "answers": ["CLUTO, Carrot2 Lingo", "simple clustering algorithm which uses the cosine similarity between word embeddings"], "all_classes": null, "length": 3039}
{"pred": "BERT-QAZZAsk, BIBS-dREF1 questions are unanswerable as-Echoz questions that share-QA, BIBREF-QA yes, yes-QA no-BIBRT-o-QA is 10.10 is the question is-class-1-1, yesAQ-A, yes/1754-10-1 is 17-5-1-1- and evidence-18-E is the QA-1-A-18-4-3-1-quest-", "answers": ["Bert + Unanswerable", "CNN, BERT"], "all_classes": null, "length": 3845}
{"pred": "PVT or BFores-vowers-to-zero-reference-BIBSTRM, \"BERT-Bes-BRLM, BPEBIBREF-BABBiling BilingB, or BMT-to-Biberset-m B-Bibow--A-r-BRE-language,BRE-BRE-BERT-language-v, the question for the p-zero-B-BRLM-A, B-BRE-M, p-source-B-m-m-MLM-B-m-B", "answers": ["pivoting, pivoting$_{\\rm m}$", "firstly translates a source language into the pivot language which is later translated to the target language"], "all_classes": null, "length": 3815}
{"pred": "Em-conversed-sub-task-un-tune-s: \"es-based-form or \"W\"\n BIBREF: \"W\" of \"W-W\" are \"W, Chat-t\" or competition-emotion \"W\" or experiment-W in the detail-80W\" un-s-W: \"W\", the experiment-based on the question-s-form-s competition-un-based-t-ChatB-c-m-W-\"-s\" pre-t-un-Emotion- \"W\" and section-s", "answers": ["Friends, EmotionPush", "EmotionLines BIBREF6"], "all_classes": null, "length": 3178}
{"pred": "Several-e-t-n-related-rows for-based-dat-t-related-trial-related-t-no- and over-s-tr-yes-s-t-tri-trial (un-e-t- is text-independent-based trials-t-t-rows-e-t-row-row-tri-trials, en-t-t- trials are-t-e-t-row-s-e-s-t-row-t- row-t-row-e-row-s-t-e-", "answers": ["three experimental setups with different numbers of speakers in the evaluation set, three experimental setups with different number of speaker in the evaluation set are defined,  first one, respondents with at least 17 recording sessions are included to the evaluation set, respondents with 16 sessions to the development and the rest of respondents to the background set, second setup, respondents with at least 8 sessions are included to the evaluation set, respondents with 6 or 7 sessions to the development and the rest of respondents to the background set"], "all_classes": null, "length": 3880}
{"pred": "Gaussian-attention: Yes or \"unanswer\" or unanswer\". Yes, \"unanswer:-related or-der-attention.", "answers": ["pays attentions to adjacent characters and casts a localness relationship between the characters as a fixed Gaussian weight assuming the weight relies on the distance between characters", "Gaussian-masked directional attention can be described as a function to map queries and key-value pairs to the representation of input, Gaussian-masked directional attention expects to pay attention to the adjacent characters of each positions and cast the localness relationship between characters as a fix Gaussian weight for attention, Gaussian weight only relys on the distance between characters"], "all_classes": null, "length": 3612}
{"pred": "The-t: \"un-non, orally-aligned or  thatBIBV and un-provides: FB, bip$_sensitive in our-system, is, BIB, or-un. (BERT andun, self-f, un-B-t, is-t-extracta, the V, BIB-BIB:W-15 and $B-t, BIB:X-type, is tuning, BIB-W-BW-language SE:, un-B, is, BIB-B, in (1-A", "answers": ["No data. Pretrained model is used."], "all_classes": null, "length": 3409}
{"pred": "Different or (or) \"AER:BIBREF0, (un-coded-C, or case: \"yes, un-input-des-E-feated losses (yes, C-A-E-the, B-alkC (-C-E,C, of the non-re-Et, average, IN-BIBC) BIBER, BIB, B-Et-C, E-C-E-the-words (C, BIBREF-c-C-E-the, BIBREF-E-G-C-C", "answers": ["For certain POS tags, e.g. VERB, PRON.", "most word alignments only involve one or a few words, attention can be distributed more freely"], "all_classes": null, "length": 3366}
{"pred": "Recised-yes (INZARD BIBREF1 isos for the most likelyyespoon (INformed of labeling, Informers samples (INLINEFORM7) or (INformed (BIBIBELY, RELFYES andCIT is unarticleININ SectionINININLINE) In un EB- BIBF, formostIN sections-\" is undat as) RELG)", "answers": ["RNN", " Recurrent Neural Network (RNN)"], "all_classes": null, "length": 1644}
{"pred": "The sample-bo-yes or \"un-un-bas-2 (or un-word-y (yes-un-bibore-20-un-20-tome-line-b-bibo)-baseline-unore-bas (un-bibref-l-un-20-un-un-bas-3-l-b-2-bibrefbib-1-l-bibref-2-un-l-bun-bibref-l-un-look-bib-bibib-l-un", "answers": ["CNN modelBIBREF0, Stanford CRF modelBIBREF21", "Bam et al. SVM, Ma and Hovy w/glove, Lample et al. w/fastText, Lample et al. w/word2vec"], "all_classes": null, "length": 2836}
{"pred": "Unanswering here-2-length is-bubbleed decor: yes-language-un-answer. (Eq-2-l-2 is: \"bert-sub-answer-1-like- is out-unbsoft-likes-is un-is-l sub-view-question: Un-l: it is un-sub-l- \" Un-sub-sub- is-word-sub-2-no- Un- L- is the super-l-sub-ref4-l-l-sub-l-l sub-l-l-", "answers": ["Unanswerable"], "all_classes": null, "length": 3885}
{"pred": "Around 16 Wikibosomysba is involved in the evaluation sets of information evaluation study of the BIBREF3-DGLRG2 or RG-C is for WikiR2 and RG, D2-evaluated's was of: 4, where RG: Precent (yes was from", "answers": ["about 500", "Unanswerable"], "all_classes": null, "length": 3831}
{"pred": "CNN, and univ1: \"un-question\" or the \"un-frequised by the article's offs and annotation offt-un-d-un-d, un-form-f-unanswer or un, \"un.\n un- orart-f-f-system, un-un-f-f-un-no-un-dat-art-answer-f-un-f-f-un-f-un-form-un-word-un-un-f-f-un-f-un- or-f-in-f", "answers": ["linear SVM, bidirectional Long Short-Term-Memory (BiLSTM), Convolutional Neural Network (CNN)", "linear SVM, bidirectional Long Short-Term-Memory (BiLSTM), Convolutional Neural Network (CNN)", "linear SVM trained on word unigrams,  bidirectional Long Short-Term-Memory (BiLSTM),  Convolutional Neural Network (CNN) "], "all_classes": null, "length": 2250}
{"pred": "Bi-170-un-l-2 (un-3-17-BIB-yes-B-to-be-B-NER-yla- oro-1-B-2-BIB-1-V-B-20-1-un-un-to-un-state-be-B-1-un-B-1-un-B-un-B-un-20-B-1-from-0-2-3-B-B-30-B-1-un-B-un-1-1-", "answers": ["BiLSTM, BiLSTM-CNN, BiLSTM-CRF, BiLSTM-CNN-CRF", "BiLSTMBIBREF14, BiLSTM+CNNBIBREF20, BiLSTM+CRFBIBREF1, BiLSTM+CNN+CRFBIBREF2, CNN modelBIBREF0 and Stanford CRF modelBIBREF21"], "all_classes": null, "length": 2838}
{"pred": "Unsupered or out-relevant (unanswer-no-based orphon INLINEFORM0 , or-TD or INLINE-v_ or (re-to-phon-C-ed-like-based of un-re-no, Un- or-AUD-IN-v-line-e, the unin INLINE-bib-v-e (unanswer-unph-or-0- or-INLINE-a-un-o-INLINE-0-e (un-C-e-un-i-un-un-un-in", "answers": ["Zero Resource Toolkit (ZRTools) BIBREF7"], "all_classes": null, "length": 3381}
{"pred": "BERT-DBREF's or BIBREF-N-pro's or-unified (unanswer-con-n, BIBREF3, \"un-pro--ab\" is unsuper-sabor-ex-PN is reduction-s and-BERT-a-class is beneficial BERT- is the input, they are-ab-unclass-R: BERT is used-in-b-ab-results, it is beneficial on-BIB-s in the ab-dis-BERT, they is redu-class- is-b, so--", "answers": ["BERTbase", "BERTbase"], "all_classes": null, "length": 3852}
{"pred": "Five models: REBilleters (re-assessed extraction was not-assessed (unfortunately, or).", "answers": ["Answer with content missing: (LVL1, LVL2, LVL3) \n- Stanford CoreNLP\n- Optical Character Recognition (OCR) system, ParsCIT \n- further abridge the input text from level 2 preprocessed documents to the following: title, headers, abstract, introduction, related work, background and conclusion."], "all_classes": null, "length": 1822}
{"pred": "Yesbs20 points in the encorbidu1 (onward-repeo under-neural (unneural-neural)\n\n\nUn-reas-reward-form-on)\n\nYesure:un-ne (un-dou-un-answer)\n\nYes (unew) or IN-neural)\n\nYes-ne-ne-t-re-neural-neural-\nun-un)\nun-unne-ne-re-ne-ne-un-ne-ne-ne) and un-ne-be", "answers": ["Yes", "Yes"], "all_classes": null, "length": 2077}
{"pred": "M-INIC-AN-ANN-INALSs-INCRESCODAL:137: \"for the testedal's\" for\" or BIBLear or not-ward sum-FormALS0.", "answers": ["MIMIC-III", "MIMIC-III"], "all_classes": null, "length": 2992}
{"pred": "Thesis sub-lised offensive/callyed INBCOREFFORM1001.yes: OLEDTWO10: \"Offsive-sub-offensive posts OLID, there is \"unilised\" in-related\". uni-leveled, unanswer: \"unavailable\" (yes Off\". Unanswer: \"Off-BIO20, yes, unanswer\" OLID\" is included in Off-T, the shared in un-guarded (Offens) and task A-BLI) inL, the, un-s, L", "answers": ["Level A: 14100 Tweets\nLevel B: 4640 Tweets\nLevel C: 4089 Tweets"], "all_classes": null, "length": 2255}
{"pred": "Attels (yesht-EWR-EtAlk-Et_Et-nmt-SM-NMT is the concu-E-attention-Eng-EMG-Et-talu-n E-IM-B1-un-attEt-s-s.\n\n yes,INPRM-Et-M-IBBM-IBM:BIBMDP-t-shon-refs-EM-ng.s-P-s-Et-t-IM-s-N-s-N-ANM-", "answers": ["it captures other information rather than only the translational equivalent in the case of verbs", "Alignment points of the POS tags."], "all_classes": null, "length": 3372}
{"pred": "Bag-form or experiment baselines onset sublies\"s\" is the number of dialogue BERT for the given the unswerddes \" or BERT, R, yes or BERT: (un-no-sentiment, unanswer. The question: \"yes, unanswerable over dialogue datasets\" in the article is (BOW, LAT datasets\" (yes, the article R.", "answers": ["BOW-LR, BOW-RF. TFIDF-RF, TextCNN, C-TextCNN", "bag-of-words (BOW), term frequencyâ€“inverse document frequency (TFIDF), neural-based word embedding, Logistic Regression (LR), Random Forest (RF), TextCNN BIBREF10 with initial word embedding as GloVe"], "all_classes": null, "length": 3181}
{"pred": "Theyal0 IN INFORMulate27, \"yes: 5 for INFORMERFORM1 and INFORMINEFOR5, they use \"unanswer2, does not recommend:lets1: unavailable:unlineFORM0\", yes\", \"no\", INFORM3, or INFORM, or \"no\", \"INFORM0, yes, yes2, un 5, Amazon IN, un- IN, and INLINE5, BIBIB, INLINE, BIB, Amazon and D2, INFORM5, yes, e-0, they, and INFORM5, the Amazon,", "answers": ["Unanswerable", "48,705"], "all_classes": null, "length": 3307}
{"pred": "\"Model unprovide \"unsubside: un-B, unanswer the multilinguploversonet: CoV-un or-C-un or unprovide-based-sub-un-to-1-un-m-un-d6-sub-c-un-1-1-mult-un-un-un-un-un-un-un-un--C0. or1-A-un-C-1-un-un-un-1-un:-un-un-un-C-un-Call-ascription: Question", "answers": ["follow the architecture in berard2018end, but have 3 decoder layers like that in pino2019harnessing"], "all_classes": null, "length": 2424}
{"pred": "Pennised-state-of the authors (severify the PRU, WD: yes, or WBIBREF37 Do-BIBREF7 or Wiki, BIBREF32 and WTBIBREF1 and WTBIBRREF3BREF3 (un, orphammay7 yes-BIBREF3 and LR22 and3BIBREF3B16 and TBIBREF33 and R6BREF, EQR3 and LR6BREF3 and WBREF3 and R7, respectively, R6 T3", "answers": [" Penn Treebank, WikiText2", "Penn Treebank (PTB) , WikiText2 (WT-2)"], "all_classes": null, "length": 3302}
{"pred": "Unanswer is \"un (yes (in the article)", "answers": ["No", "No"], "all_classes": null, "length": 3158}
{"pred": "Prior due to priorising the article BIB organisation BIB17's util (bertBASE, knowledge (student model BERT, in BERT2 or [Bibot-question BIB, the prior-un BIBSG-BERTAB, in D, is un-changed is effective BREF BibREF B- BIB, the article, Bib-BERT-B-art (BREF BIB-b- BREF- D-BIB- BIBREF- B- B-B-B-R-B-BERT-B-D- B-B-", "answers": ["While there has been existing work on reducing NLP model vocabulary sizes BIBREF15, distillation techniques cannot utilize these, since they require the student and teacher models to share the same vocabulary and output space. This profoundly limits their potential to further reduce model sizes.", "distillation techniques cannot utilize these, since they require the student and teacher models to share the same vocabulary and output space. This profoundly limits their potential to further reduce model sizes."], "all_classes": null, "length": 3570}
{"pred": "word2nores for English BIBMised or not on this question (B) \"B\"): \"do\" or \"given or\" is un-answer in \"yes\" or B, \"yes, Bib\" or \"appro or \"do, BIB or \"B\" or, B\" or \"do\" or \"word\" or in BIB: BIB: or B or \"do-B\" or\" BIB or \"B\" or \"do\" or\" or \"word\" or \" or \" or BI\" or \"do\" or \"B\" or \"B\" or \"", "answers": ["using word2vec to create features that are used as input to the SVM", "use the word2vec algorithm, create several unsupervised hand-crafted features, generate document vectors and feed them as input into the support vector machines (SVM) approach"], "all_classes": null, "length": 3820}
{"pred": "From ancient-moded ancient-mod \"unised-mod\" INLINE-anciental ancient-based-modern-fusionally-un-lineIN-test:-ancient-un-man-d-INLINE-INL ancient-un (Dev-un-un-fraction ancient-mod-INLIN-mod-modern-IN-f-un-un-f-modun-f-L9-IN-mod-un-mod-N-mod-INLINE-INLINE-f-mod-IN-mod-IN-mod-f-un", "answers": ["ancient Chinese history records in several dynasties (about 1000BC-200BC) and articles written by celebrities of that era", "Ancient Chinese history records in several dynasties and articles written by celebrities during 1000BC-200BC collected from the internet "], "all_classes": null, "length": 3722}
{"pred": "Unsetionised: Yes or \"yes/unanswer\"\".\" (unanswer\" or \"un\", \"unanswer\" \"article\" (answher) for the article conci's, Bibbed (art (d) for-up-reading-posed: (art:answer/art \"set\" (set \"user) Yes: Yes:quora (: \"un\" (b) and BIB (set) (answer-question). Bibb (un) and proset (b) for-type-un-of-ill- for-: B (re", "answers": ["No"], "all_classes": null, "length": 1561}
{"pred": "Words's-unpredicting-re-st-re-to-account-level-B-class-BIB0-B-1-No-BIBLIB-un-BIB-un-un-B-t-class-t-B-un-No-F-F-B-B-I-BIB-B-un-t-t-I-B-t-un-t-I-t-B-un-t-B-No-t-I-un-V-F-1-t-L-F-L-t", "answers": ["words embeddings, style, and morality features", "words embeddings, style, and morality features"], "all_classes": null, "length": 2091}
{"pred": "United-superport, un-research isole, \"un-W-ad-length-Wib-N, and-passed-t-un-W-1 (i, language-dev-sub-W-v-D-v-ud-data-bib2BIB10 (v2N-ad, or monolum-part forW-W-N, and v-v, LAS for X-B-W-B, v2-un-v-t-X-large-t-BERT and v1-W from English-Ar", "answers": ["United Nations Parallel Corpus, IIT Bombay corpus, OpenSubtitles 2018"], "all_classes": null, "length": 3405}
{"pred": "Unised-word2: \"Corpus (uncis or \"Synthetic or morphou\" is-2 (word) (Greek-n-we, or \"un-7-un-word is, is is- Morph-word-ne\" or-word (Wor-morpher-word-un-Question-un ' morp morph-do or-word) results (un-corpus (un-G\", or-or-word-ve-un-word-un-un-we, or-Glo-do-word) or-un", "answers": ["Unanswerable", "English"], "all_classes": null, "length": 2009}
{"pred": "Unites in the article: Yes: (Yes, or for future work, unspecified CBT: for D) or unanswer: DIBREF, that is not, unified at the article: Corpuses in sections: are un, in the article, and un, A: unavailable in: un: C, of the article, annot, or NLP, BIBREF: C, annotation, BIBREF, un, PEAP, A, C:, un: Bibref, un, un, bib, A1, and un, BIB, A: and", "answers": ["No", "No"], "all_classes": null, "length": 1899}
{"pred": "Over  or \"unanswer iso Overly-unc-19, sentences-over20, ormedicording Over-19,000000-19 is \"unabrid-over-19 dataset, or, MTC-1-was- is BIBD?", "answers": ["45,000 scholarly articles, including over 33,000 with full text"], "all_classes": null, "length": 2150}
{"pred": "Complearable unanswer-unferences (unanswer:, for-generated-abvi-ref0. un-related data-data-attention-un is-curi-attention, unbi-attention-dis-attended-classical-an-o-abbrerefs-att-M-s-abstraves:un, is class-abbre-un-model-model-class-un, are-evalu-un-class-att-dun-an-un-attention-att-d-att-un-d-att-un-", "answers": ["support vector machine classifier (SVM), logistic regression classifier (LR), Naive Bayes classifier (NB), random forest (RF), CNN, LSTM , LSTM-soft, LSTM-self", "support vector machine classifier (SVM), logistic regression classifier (LR), Naive Bayes classifier (NB), random forest (RF), CNN, LSTM , LSTM-soft, LSTM-self"], "all_classes": null, "length": 2895}
{"pred": "Unward: Is the karnetmatrices: \"artful auto-no or rest-form (u) for the article, or phonetic: unanswerable, \"un-no\", or speech-br-mat- or- (un-) or the 'yes\", in unanswer: \"yes\", or/re-: (inter-un:ref-un- (...) or /-n-play- or- \"a-K I\", or \"yes-un-or-u-\" is: un- (un-in-no-un- no-no-k-", "answers": ["1913 signals", "Unanswerable"], "all_classes": null, "length": 2361}
{"pred": "Conquest: [yes: [unggereml (Furous).)\n\n [unanswer: yes]\nModule: \"Telegram\" (MM): unanswer: BIR: Module Macaw: MMacaw'sification: [un]\n\n: Macaw's dialog FIG: B: [un [un:] Mac: un: un, un Macaw. (un: DH: Telegram: un)\n\n\n Mac: T: Viz: un: un-g: Scient: un: Macaw F: Macaw's Mac: un", "answers": ["Co-Reference Resolution, Query Generation, Retrieval Model, Result Generation", "Co-Reference Resolution, Query Generation, Retrieval Model, Result Generation"], "all_classes": null, "length": 1701}
{"pred": "Unaaron' or \"S\" or-0 for WikiQBIBREFINEA-dom's Quesa or correlated questions in, unified Wikipedia, yesa or un'a or SMT-0, is a orIBOM or no BIB or SESROS, un-data: Un BIBREF4 or comes or WS-SQ and SQ, or, is an un-SQUA or BIBREF1, is a method or ornament or IQ or or, and un P- or BIB or SQuAD- is a, B", "answers": ["Unanswerable"], "all_classes": null, "length": 1913}
{"pred": "Unanswerable-t-t-li-Both-row-106-t-t-no-level-s-sthat-1-3, English is-t is unanswer-tri-t-un-t-speakers- un-t-t-tri-s are-t-set-b-t-t- un-t-speakers are-t-t-t-tri-t-t is-t-t-t-t-t-t-t-t-t-independent-t-t-tri-t- is-", "answers": ["Unanswerable", "Unanswerable"], "all_classes": null, "length": 3794}
{"pred": "SQ (or SQuizards: Article or BIB1, yes, yes-Depreciable (unfortunately or D: SQuad B2 is or (10)SQuD20, and Qu20 or \"unor or SQu2 (un or Pro27, or SQu27, or (S-Qu21 or).\n\n\nSQu2: BIBREF8 or BIB2, R20, Qu-A QuT: \" is (v: the question generation BIB4: SQu: 80S-SQu2", "answers": ["SQuAD", "SQuAD"], "all_classes": null, "length": 3757}
{"pred": "Semitzzilla \"Cle (or) for, or (yes or-answer or on, un-unig: SemEval-RNN-D1-R-un-d, or the-17, and, or, or the dataset (RNN:s, and- and, or un-un-un- (un, connection layers, un-R-Context- and RNN-1, pool, and, and, and, and, and, and, and the best un- and, and, and-un-un- and, un- un-R-20", "answers": ["relation classification dataset of the SemEval 2010 task 8", "SemEval 2010 task 8 BIBREF8"], "all_classes": null, "length": 2393}
{"pred": "The results on the English WSD (non-or-un-un-relateds (20-word-word, or) and-based, or-the UDNN (non-answer-3, or: BIB- Is not the table BIBREF6-not-un-contextualized, BIB, are: 9: yes, are-the NIP-F-3: SELA WI-un-bod-the BIBREF-un-cor:9-un-bib, or-un, English: yes-7):no-un", "answers": ["2174000000, 989000000", "2174 million tokens for English and 989 million tokens for Russian"], "all_classes": null, "length": 2958}
{"pred": "Qualiton: un-s: Answer: Yes, the answer (unanswer: Multi(yes) (yes/sales (yes) for the answer: no-question) on the following score, question:\nS, unanswer: Qualities arealentled, upper and and and\n\n\nAnswer: words areas) are-KL) is theiv. The paper:\n\nRCB, the question: Answer: the KL-lower and A, and un:\n\n\nIn the question:\n\nRC1: yeseras: un-K: the lower-", "answers": ["Spearman correlation values of GM_KL model evaluated on the benchmark word similarity datasets.\nEvaluation results of GM_KL model on the entailment datasets such as entailment pairs dataset created from WordNet, crowdsourced dataset of 79 semantic relations labelled as entailed or not and annotated distributionally similar nouns dataset.", "Given a query word and component id, the set of nearest neighbours along with their respective component ids are listed"], "all_classes": null, "length": 2220}
{"pred": "Improises-F-1-F1-F1-un-F1-A-A-yes-score of \"es conco-n-F1-I-I is-s-F-1-F-F-F-F-F-F-L-F-F for MRC-F-task is \"I--I-P-L-s \"s-\"- \"-F-F--1-ab-F-I-T-un-F-F--O-0, N-1. F1-1-s-s", "answers": ["Using DSC loss improves the F1 score by +0.58 for MRPC and +0.73 for QQP", "+0.58"], "all_classes": null, "length": 3566}
{"pred": "Assetted-un answer ( BIBLINE: T-R) on BLS (BIBREF1 ) isotop (BIBRI ) iso-m BIB, BIBRE (BIB)B0 orBIBREF0 ) is (T) for question, or LINELINE (E) ) EGL is un-m-BIBL (IN-) in subsequent in BIBBIBIB) (0) T-BIBBIB) ( EGL).\n\nE ) (BIB1) is the EGL (INLINE) (T-IB)", "answers": ["reducing the variance of an estimator,  EGL method in BIBREF3 is almost the same as Eq. ( EQREF8 ), except the gradient's norm is not squared in BIBREF3", " Fisher Information Ratio"], "all_classes": null, "length": 1671}
{"pred": "LBED isoversed inference (for auxiliary form or encoder-sequence-context-NOR (s) or or INLINEFORMO'solution or form-unanswer, Pat (yes: ... or INO, or the answer: L-answer is treated as is a-paper-s-B-system iso-in-sequence, the form is the-s, the MSD, or for four-ref-generation-form-B-iscal is-like- A system is conc- for the system, INLINE-L-systems is al form,", "answers": ["LSTM", "LSTM"], "all_classes": null, "length": 2289}
{"pred": "Natural language questions basedyes of the article: \"un yes or no\" or un-an-t un-no-un-no-no-un\" BIBEF ofun-an-ans-no, \"un-on un natural-un-no\" or an un-un-language-cl-no-BIBIB-un-no-un-no-an-un-no-the-B-a-un-un-natural-cl-un-un-un-SQU or-un-an-cl-yes-yes-un-art-data-un-", "answers": ["These 8 tasks require different competencies and a different level of understanding of the document to be well answered"], "all_classes": null, "length": 3817}
{"pred": "Yes-unanswerable questions from-class basics, a question. BIBREF-article-PRA100 was-Eg. PrivacyQABjects BIBREF-EUaspect-un-def-quest- BIB Privian policies, BIBREF-1 b-E-15-un's,Privy, BIBREF article- SAB1, Sala-BIBREF15, BIBREF, BIB-E-E-E un, E-E Et-E annot-E-K, unanswerable is a question.", "answers": ["SVM, No-Answer Baseline (NA) , Word Count Baseline, Human Performance", "No-Answer Baseline (NA), Word Count Baseline, Human Performance"], "all_classes": null, "length": 3855}
{"pred": "230 (LKSCD) (SEITD) (int-K) sub-L1-number of entities are?\n\nNumber of unanswerable) (unanswer)\n\nun-g (unanswer) (yes) or \"med-un-K) (unanswerDIT-K)\nL-un- (un-un-un-K) (unment-K) (L-un-un-un-un-un-b-un-un-gu-un-un-un-un-un-un-un-un-un", "answers": ["53 documents", "53 documents"], "all_classes": null, "length": 2667}
{"pred": "Food-recipes and personal-user-recipe-ex from (inference). (from: p-k-related:recipe or Cocktail-attions or calci:ment-recipe, or recipe-unified recipes) or recipe-high, or prior-reciop:recimentions (PW) (recipe) for, it is for the food-recipe) or prior-reci:, the Food. (recipe, Food.rank, or, the recipe-divers, or recipe-prior-1, and recipes, or not p, the recipe-", "answers": ["from Food.com"], "all_classes": null, "length": 2649}
{"pred": "Incorared-sy (quick) on the word-leveled-un-yes, un-word-unwords (from LexVec, the article, unanswer on, unchanged and un-un is incorporated, \"syps, un-un the out-S down-text-down), is evaluated on the-un-word-unables in the proposed here is unwords-un and 'the models. The out and the unanswer is the un-ve (unanswer is given-the resulting-on the \"on-unsuper-un\" is, the paper. The Morp's", "answers": ["We also evaluate all five models on downstream tasks from the VecEval suite BIBREF13 , using only the tasks for which training and evaluation data is freely available: chunking, sentiment and question classification, and natural language identification (NLI). The default settings from the suite are used, but we run only the fixed settings, where the embeddings themselves are not tunable parameters of the models, forcing the system to use only the information already in the embeddings."], "all_classes": null, "length": 2083}
{"pred": "Un concise-s: 13, BIB-dise (YT, or unanswer: Philotically and 15, T, unanswerable: un answer: 10 (for) [N, and [co-, co-med: un. [d: Philo,] N, and phenot, [M, and: BIB-d: 15 un] and co-an- 15, and operators (1, and [co-un, and Oper- or and [co- and [oper-B(H) and] T-", "answers": ["Adv. Heart Disease, Adv. Lung Disease, Alcohol Abuse, Chronic Neurologic Dystrophies, Dementia, Depression, Developmental Delay, Obesity, Psychiatric disorders and Substance Abuse"], "all_classes": null, "length": 1651}
{"pred": "Unan-no-N-unanswer: \"Is-yes-un- for future-freques-A1\".yes-un-un-un-BIB-un-unanswer-un-C2-n-un-un-un-un-un-un-un-un-un-un-un-un-un-un-n-un-un-L1-un-un-un-un-un-un-un-un-un-un-un-un-n-L1-un-L-un-un-un-un-", "answers": ["204 tokens", "Most texts, however, range roughly from 150 to 250 tokens."], "all_classes": null, "length": 1898}
{"pred": "Pattern-un-un-d-un-or: (no-dised-3 or-un-concise-un- is-un- un-P-un-un-un-d-error-un-d-un-m-un-un-un-P-P-S-un-d-un-d-un-un-un-system-performs-un-un-un-c-an-un-d-un-d-un-un-un-d-un-un-un-no-un-un-un-un-d", "answers": ["(VVD shop_VV0 II, VVD shopping_VVG II)", "patterns for generating all types of errors"], "all_classes": null, "length": 2133}
{"pred": "Unanswer: Un, yes or no-line (un-scaling the-regularized-un-un: or unanswer unanswer: No, unanswerable.", "answers": ["No", "No"], "all_classes": null, "length": 3974}
{"pred": "Random organisation for-sentised utilised data scientific classification data from article, or Randomized-determ, or \"Random-random-random-random-random-H-approsent- Random Random RKS approach\"-random-Random-used-method, implemented in the Random Random Kitchen-method, or otak-SFLRS BIBREF-RKS, or RKS-Ryes-BIBLE-RKS-un-c-un-off-un-un-off, or- kitchen-sent, un-off-un-random-un-un-R-un-", "answers": ["Random Kitchen Sink method uses a kernel function to map data vectors to a space where linear separation is possible.", "explicitly maps data vectors to a space where linear separation is possible, RKS method provides an approximate kernel function via explicit mapping"], "all_classes": null, "length": 2361}
{"pred": "They is-based on-the Turkish SIT-18 (Inferred BIBM, ornament, no", "answers": ["BIBREF11 , BIBREF26 "], "all_classes": null, "length": 1912}
{"pred": "Impro realised-is-unified-on: unions-correct-yes or un-random-d-random-randomly-per-random-on: (un-un-based-un-no-un-error-correction-re-corpus-random-con-un-random-re-errors: Improce-un-un-d-un-correct-m-errors-un-cor-V-un-corro-random-un-error-re-V-un-un-errors-on-un-errors-errors-un-PCE-random-", "answers": ["Combining  pattern based and Machine translation approaches gave the best overall F0.5 scores. It was 49.11 for FCE dataset  , 21.87 for the first annotation of  CoNLL-14, and 30.13 for the second annotation of CoNLL-14. "], "all_classes": null, "length": 2164}
