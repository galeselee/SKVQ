{"pred": "Foxsetified dataset data as (development: Time, CNN, is (un-based set is used for training: unanswered-wise: Guard, Sponot2) BIB's or set, yes, sad, yes, or (yes,1 orchestred, or (Guard) or B-no: is, or un-ret, or-ent, is un-S- (F- (S-wise-un-super, or-super) data, is) or-emotion- or- or- S- S- for-m, or-S-S", "answers": ["FoxNews, CNN, ESPN, New York Times, Time magazine, Huffington Post Weird News, The Guardian, Cartoon Network, Cooking Light, Home Cooking Adventure, Justin Bieber, Nickelodeon, Spongebob, Disney", "FoxNews, CNN, ESPN, New York Times, Time magazine, Huffington Post Weird News, The Guardian, Cartoon Network, Cooking Light, Home Cooking Adventure, Justin Bieber, Nickelodeon, Spongebob, Disney."], "all_classes": null, "length": 3411}
{"pred": "Latent (Unig3: unmodels INLINEFORM6, or or unspecifically/un or INFORM0 and INLINEFORM6 is INFORM6 is not.", "answers": ["the series of posts that trigger an intervention"], "all_classes": null, "length": 3732}
{"pred": "\"Yes (articlesfasm (unigoused inference-t of thecite-based on-sarc-un-unanswering (yes, learned-of-reg (un-answer, unprov-no-un (un, unod (un, unanswer, or \"sarc) or yes, un, \" un-in-no, un- yes, yes, the improvement, when-un-s-un-of, unanswer--sarc-score, un-no-the-no-un- the- no-s, the un, yes, s", "answers": ["F-score, Kappa", "Unanswerable"], "all_classes": null, "length": 3544}
{"pred": "The article-LST-p-dears out or \" yes\"\".\".", "answers": ["(i) models that use plain stacked LSTMs, (ii) models with different INLINEFORM0, (iii) models without INLINEFORM1, (iv) models that integrate lower contexts via peephole connections"], "all_classes": null, "length": 3224}
{"pred": "No: Yes or (unl (yes, Yes! ALso) uni (unless:) (jiant) or \"un\"jiant (un pull-m)n) une (un) pull, Yes:) jian (, un (,) un i (G) or pull) or \"unl\",) (S) (ji (b,) jiant) (un,) (super) (un, super) (bi, super) (SIL) (yes,) (S) (yes) super) (yes, and un)\n (un, and", "answers": ["Yes", "Unanswerable"], "all_classes": null, "length": 2284}
{"pred": "Unrelated to the introduction of the questions abouti-ans PQREF1 or-Elder, by-question-ans as-no-E Et-Et-ALPrivacy questions thata Unanswer-E-Ener-Ref, yes, unanswer-E-E-no-Privis-E-policy of-E-E-E-E-C-E-Priv- no-Un-Art-yes-no-C-Ana-E-E-yes, E-1 un-E-E-E-E-E-E-E-27", "answers": ["No"], "all_classes": null, "length": 3843}
{"pred": "Modestic: Yes or aids (BIBSynthesever's (9 or-1BIBIs) and a (sy) or BIBREF1, or BIBSTHEGs from (sBIBPERRREF (or) or \"yes or (yes-1) the tasks or the label or BIB1, or \"he or ':1,R, or\nSECH, or (1) or (w) or (8) the mSyno-probes\n\nNo BIB1:yes (20-un BIBREF20", "answers": ["Yes", "No"], "all_classes": null, "length": 2317}
{"pred": "Four sets of coraising on-domain-provable (yes. (un BOTBSC) and AMBSF-unanswer) means thata on the information \"research: \"yes\", orals from BOT and unclassa: yes, A-RNN-unanswer: unanswer or A RNN, A (yes, A B, or RNN or- A, The A RNN approach, RNN-based approach: English and A, A, A, RNN, A, A, BIBLREF5, A, B, B, RNN, lex", "answers": ["SemEval-2016 Challenge Task 5 BIBREF27 , BIBREF28", " English reviews ,  restaurant reviews from four different languages (Spanish, Turkish, Dutch, Russian)"], "all_classes": null, "length": 2720}
{"pred": "Improder improvements are un-f-s as \"unanswer-ROREFREF_EL_unanswer: yes (unclear (unanswer: topic-attention) (topic-tun_rep, improvements, model: yes (un-context:topic-s-medial-DREM, unenhancement of-topic:fabs, under:s_word, improvements).", "answers": ["7.36% on accuracy and 9.69% on F1 score", "it has 0.024 improvement in accuracy comparing to ELMO Only and  0.006 improvement in F1 score  comparing to ELMO Only too"], "all_classes": null, "length": 2890}
{"pred": "They use \"unf's or the proposed models (yes or not-error-INLINE or or un-un-the or the proposed models or the transcripts, no, yes or-the-their-un\". HMM- un or, H- or or, the audio-un, un-the IEMODE or- the unform-un- or-B-un or- the paper or- or-un- the article, the un- the audio, the IECODER or-un-the method as- or or- or- or, the un-un- or", "answers": ["They use text transcription.", "both"], "all_classes": null, "length": 3198}
{"pred": "Closcizing \"S, unanswer\". Yes-n-ALS, (or LAP BCLBREF1, unanswer-A Clusty, Clustered noun4.", "answers": ["CLUTO, Carrot2 Lingo", "simple clustering algorithm which uses the cosine similarity between word embeddings"], "all_classes": null, "length": 3039}
{"pred": "BERT-QAZZAsk, BIBS-dREF1 questions are unanswerable as-Echoz questions that share-QA, BIBREF-QA yes, yes-QA no-BIBRT-o-QA is 10.10 is the question is-class-1-1, yesAQ-A, yes/1754-10-1 is 17-5-1-1- and evidence-18-E is the QA-1-A-18-4-3-1-quest-", "answers": ["Bert + Unanswerable", "CNN, BERT"], "all_classes": null, "length": 3845}
{"pred": "PVT or BFores-vowers-to-zero-reference-BIBSTRM, \"BERT-Bes-BRLM, BPEBIBREF-BABBiling BilingB, or BMT-to-Biberset-m B-Bibow--A-r-BRE-language,BRE-BRE-BERT-language-v, the question for the p-zero-B-BRLM-A, B-BRE-M, p-source-B-m-m-MLM-B-m-B", "answers": ["pivoting, pivoting$_{\\rm m}$", "firstly translates a source language into the pivot language which is later translated to the target language"], "all_classes": null, "length": 3815}
{"pred": "Em-conversed-sub-task-un-tune-s: \"es-based-form or \"W\"\n BIBREF: \"W\" of \"W-W\" are \"W, Chat-t\" or competition-emotion \"W\" or experiment-W in the detail-80W\" un-s-W: \"W\", the experiment-based on the question-s-form-s competition-un-based-t-ChatB-c-m-W-\"-s\" pre-t-un-Emotion- \"W\" and section-s", "answers": ["Friends, EmotionPush", "EmotionLines BIBREF6"], "all_classes": null, "length": 3178}
{"pred": "Foxsetified dataset data as (development: Time, CNN, is (un-based set is used for training: unanswered-wise: Guard, Sponot2) BIB's or set, yes, sad, yes, or (yes,1 orchestred, or (Guard) or B-no: is, or un-ret, or-ent, is un-S- (F- (S-wise-un-super, or-super) data, is) or-emotion- or- or- S- S- for-m, or-S-S", "answers": ["FoxNews, CNN, ESPN, New York Times, Time magazine, Huffington Post Weird News, The Guardian, Cartoon Network, Cooking Light, Home Cooking Adventure, Justin Bieber, Nickelodeon, Spongebob, Disney", "FoxNews, CNN, ESPN, New York Times, Time magazine, Huffington Post Weird News, The Guardian, Cartoon Network, Cooking Light, Home Cooking Adventure, Justin Bieber, Nickelodeon, Spongebob, Disney."], "all_classes": null, "length": 3411}
{"pred": "Latent (Unig3: unmodels INLINEFORM6, or or unspecifically/un or INFORM0 and INLINEFORM6 is INFORM6 is not.", "answers": ["the series of posts that trigger an intervention"], "all_classes": null, "length": 3732}
{"pred": "\"Yes (articlesfasm (unigoused inference-t of thecite-based on-sarc-un-unanswering (yes, learned-of-reg (un-answer, unprov-no-un (un, unod (un, unanswer, or \"sarc) or yes, un, \" un-in-no, un- yes, yes, the improvement, when-un-s-un-of, unanswer--sarc-score, un-no-the-no-un- the- no-s, the un, yes, s", "answers": ["F-score, Kappa", "Unanswerable"], "all_classes": null, "length": 3544}
{"pred": "The article-LST-p-dears out or \" yes\"\".\".", "answers": ["(i) models that use plain stacked LSTMs, (ii) models with different INLINEFORM0, (iii) models without INLINEFORM1, (iv) models that integrate lower contexts via peephole connections"], "all_classes": null, "length": 3224}
{"pred": "No: Yes or (unl (yes, Yes! ALso) uni (unless:) (jiant) or \"un\"jiant (un pull-m)n) une (un) pull, Yes:) jian (, un (,) un i (G) or pull) or \"unl\",) (S) (ji (b,) jiant) (un,) (super) (un, super) (bi, super) (SIL) (yes,) (S) (yes) super) (yes, and un)\n (un, and", "answers": ["Yes", "Unanswerable"], "all_classes": null, "length": 2284}
{"pred": "Unrelated to the introduction of the questions abouti-ans PQREF1 or-Elder, by-question-ans as-no-E Et-Et-ALPrivacy questions thata Unanswer-E-Ener-Ref, yes, unanswer-E-E-no-Privis-E-policy of-E-E-E-E-C-E-Priv- no-Un-Art-yes-no-C-Ana-E-E-yes, E-1 un-E-E-E-E-E-E-E-27", "answers": ["No"], "all_classes": null, "length": 3843}
{"pred": "Modestic: Yes or aids (BIBSynthesever's (9 or-1BIBIs) and a (sy) or BIBREF1, or BIBSTHEGs from (sBIBPERRREF (or) or \"yes or (yes-1) the tasks or the label or BIB1, or \"he or ':1,R, or\nSECH, or (1) or (w) or (8) the mSyno-probes\n\nNo BIB1:yes (20-un BIBREF20", "answers": ["Yes", "No"], "all_classes": null, "length": 2317}
{"pred": "Four sets of coraising on-domain-provable (yes. (un BOTBSC) and AMBSF-unanswer) means thata on the information \"research: \"yes\", orals from BOT and unclassa: yes, A-RNN-unanswer: unanswer or A RNN, A (yes, A B, or RNN or- A, The A RNN approach, RNN-based approach: English and A, A, A, RNN, A, A, BIBLREF5, A, B, B, RNN, lex", "answers": ["SemEval-2016 Challenge Task 5 BIBREF27 , BIBREF28", " English reviews ,  restaurant reviews from four different languages (Spanish, Turkish, Dutch, Russian)"], "all_classes": null, "length": 2720}
{"pred": "Improder improvements are un-f-s as \"unanswer-ROREFREF_EL_unanswer: yes (unclear (unanswer: topic-attention) (topic-tun_rep, improvements, model: yes (un-context:topic-s-medial-DREM, unenhancement of-topic:fabs, under:s_word, improvements).", "answers": ["7.36% on accuracy and 9.69% on F1 score", "it has 0.024 improvement in accuracy comparing to ELMO Only and  0.006 improvement in F1 score  comparing to ELMO Only too"], "all_classes": null, "length": 2890}
{"pred": "They use \"unf's or the proposed models (yes or not-error-INLINE or or un-un-the or the proposed models or the transcripts, no, yes or-the-their-un\". HMM- un or, H- or or, the audio-un, un-the IEMODE or- the unform-un- or-B-un or- the paper or- or-un- the article, the un- the audio, the IECODER or-un-the method as- or or- or- or, the un-un- or", "answers": ["They use text transcription.", "both"], "all_classes": null, "length": 3198}
{"pred": "Closcizing \"S, unanswer\". Yes-n-ALS, (or LAP BCLBREF1, unanswer-A Clusty, Clustered noun4.", "answers": ["CLUTO, Carrot2 Lingo", "simple clustering algorithm which uses the cosine similarity between word embeddings"], "all_classes": null, "length": 3039}
{"pred": "BERT-QAZZAsk, BIBS-dREF1 questions are unanswerable as-Echoz questions that share-QA, BIBREF-QA yes, yes-QA no-BIBRT-o-QA is 10.10 is the question is-class-1-1, yesAQ-A, yes/1754-10-1 is 17-5-1-1- and evidence-18-E is the QA-1-A-18-4-3-1-quest-", "answers": ["Bert + Unanswerable", "CNN, BERT"], "all_classes": null, "length": 3845}
{"pred": "PVT or BFores-vowers-to-zero-reference-BIBSTRM, \"BERT-Bes-BRLM, BPEBIBREF-BABBiling BilingB, or BMT-to-Biberset-m B-Bibow--A-r-BRE-language,BRE-BRE-BERT-language-v, the question for the p-zero-B-BRLM-A, B-BRE-M, p-source-B-m-m-MLM-B-m-B", "answers": ["pivoting, pivoting$_{\\rm m}$", "firstly translates a source language into the pivot language which is later translated to the target language"], "all_classes": null, "length": 3815}
{"pred": "Em-conversed-sub-task-un-tune-s: \"es-based-form or \"W\"\n BIBREF: \"W\" of \"W-W\" are \"W, Chat-t\" or competition-emotion \"W\" or experiment-W in the detail-80W\" un-s-W: \"W\", the experiment-based on the question-s-form-s competition-un-based-t-ChatB-c-m-W-\"-s\" pre-t-un-Emotion- \"W\" and section-s", "answers": ["Friends, EmotionPush", "EmotionLines BIBREF6"], "all_classes": null, "length": 3178}
{"pred": "Several-e-t-n-related-rows for-based-dat-t-related-trial-related-t-no- and over-s-tr-yes-s-t-tri-trial (un-e-t- is text-independent-based trials-t-t-rows-e-t-row-row-tri-trials, en-t-t- trials are-t-e-t-row-s-e-s-t-row-t- row-t-row-e-row-s-t-e-", "answers": ["three experimental setups with different numbers of speakers in the evaluation set, three experimental setups with different number of speaker in the evaluation set are defined,  first one, respondents with at least 17 recording sessions are included to the evaluation set, respondents with 16 sessions to the development and the rest of respondents to the background set, second setup, respondents with at least 8 sessions are included to the evaluation set, respondents with 6 or 7 sessions to the development and the rest of respondents to the background set"], "all_classes": null, "length": 3880}
{"pred": "Gaussian-attention: Yes or \"unanswer\" or unanswer\". Yes, \"unanswer:-related or-der-attention.", "answers": ["pays attentions to adjacent characters and casts a localness relationship between the characters as a fixed Gaussian weight assuming the weight relies on the distance between characters", "Gaussian-masked directional attention can be described as a function to map queries and key-value pairs to the representation of input, Gaussian-masked directional attention expects to pay attention to the adjacent characters of each positions and cast the localness relationship between characters as a fix Gaussian weight for attention, Gaussian weight only relys on the distance between characters"], "all_classes": null, "length": 3612}
{"pred": "The-t: \"un-non, orally-aligned or  thatBIBV and un-provides: FB, bip$_sensitive in our-system, is, BIB, or-un. (BERT andun, self-f, un-B-t, is-t-extracta, the V, BIB-BIB:W-15 and $B-t, BIB:X-type, is tuning, BIB-W-BW-language SE:, un-B, is, BIB-B, in (1-A", "answers": ["No data. Pretrained model is used."], "all_classes": null, "length": 3409}
{"pred": "Different or (or) \"AER:BIBREF0, (un-coded-C, or case: \"yes, un-input-des-E-feated losses (yes, C-A-E-the, B-alkC (-C-E,C, of the non-re-Et, average, IN-BIBC) BIBER, BIB, B-Et-C, E-C-E-the-words (C, BIBREF-c-C-E-the, BIBREF-E-G-C-C", "answers": ["For certain POS tags, e.g. VERB, PRON.", "most word alignments only involve one or a few words, attention can be distributed more freely"], "all_classes": null, "length": 3366}
{"pred": "Recised-yes (INZARD BIBREF1 isos for the most likelyyespoon (INformed of labeling, Informers samples (INLINEFORM7) or (INformed (BIBIBELY, RELFYES andCIT is unarticleININ SectionINININLINE) In un EB- BIBF, formostIN sections-\" is undat as) RELG)", "answers": ["RNN", " Recurrent Neural Network (RNN)"], "all_classes": null, "length": 1644}
{"pred": "The sample-bo-yes or \"un-un-bas-2 (or un-word-y (yes-un-bibore-20-un-20-tome-line-b-bibo)-baseline-unore-bas (un-bibref-l-un-20-un-un-bas-3-l-b-2-bibrefbib-1-l-bibref-2-un-l-bun-bibref-l-un-look-bib-bibib-l-un", "answers": ["CNN modelBIBREF0, Stanford CRF modelBIBREF21", "Bam et al. SVM, Ma and Hovy w/glove, Lample et al. w/fastText, Lample et al. w/word2vec"], "all_classes": null, "length": 2836}
{"pred": "Unanswering here-2-length is-bubbleed decor: yes-language-un-answer. (Eq-2-l-2 is: \"bert-sub-answer-1-like- is out-unbsoft-likes-is un-is-l sub-view-question: Un-l: it is un-sub-l- \" Un-sub-sub- is-word-sub-2-no- Un- L- is the super-l-sub-ref4-l-l-sub-l-l sub-l-l-", "answers": ["Unanswerable"], "all_classes": null, "length": 3885}
{"pred": "Around 16 Wikibosomysba is involved in the evaluation sets of information evaluation study of the BIBREF3-DGLRG2 or RG-C is for WikiR2 and RG, D2-evaluated's was of: 4, where RG: Precent (yes was from", "answers": ["about 500", "Unanswerable"], "all_classes": null, "length": 3831}
{"pred": "CNN, and univ1: \"un-question\" or the \"un-frequised by the article's offs and annotation offt-un-d-un-d, un-form-f-unanswer or un, \"un.\n un- orart-f-f-system, un-un-f-f-un-no-un-dat-art-answer-f-un-f-f-un-f-un-form-un-word-un-un-f-f-un-f-un- or-f-in-f", "answers": ["linear SVM, bidirectional Long Short-Term-Memory (BiLSTM), Convolutional Neural Network (CNN)", "linear SVM, bidirectional Long Short-Term-Memory (BiLSTM), Convolutional Neural Network (CNN)", "linear SVM trained on word unigrams,  bidirectional Long Short-Term-Memory (BiLSTM),  Convolutional Neural Network (CNN) "], "all_classes": null, "length": 2250}
{"pred": "Bi-170-un-l-2 (un-3-17-BIB-yes-B-to-be-B-NER-yla- oro-1-B-2-BIB-1-V-B-20-1-un-un-to-un-state-be-B-1-un-B-1-un-B-un-B-un-20-B-1-from-0-2-3-B-B-30-B-1-un-B-un-1-1-", "answers": ["BiLSTM, BiLSTM-CNN, BiLSTM-CRF, BiLSTM-CNN-CRF", "BiLSTMBIBREF14, BiLSTM+CNNBIBREF20, BiLSTM+CRFBIBREF1, BiLSTM+CNN+CRFBIBREF2, CNN modelBIBREF0 and Stanford CRF modelBIBREF21"], "all_classes": null, "length": 2838}
{"pred": "Unsupered or out-relevant (unanswer-no-based orphon INLINEFORM0 , or-TD or INLINE-v_ or (re-to-phon-C-ed-like-based of un-re-no, Un- or-AUD-IN-v-line-e, the unin INLINE-bib-v-e (unanswer-unph-or-0- or-INLINE-a-un-o-INLINE-0-e (un-C-e-un-i-un-un-un-in", "answers": ["Zero Resource Toolkit (ZRTools) BIBREF7"], "all_classes": null, "length": 3381}
{"pred": "BERT-DBREF's or BIBREF-N-pro's or-unified (unanswer-con-n, BIBREF3, \"un-pro--ab\" is unsuper-sabor-ex-PN is reduction-s and-BERT-a-class is beneficial BERT- is the input, they are-ab-unclass-R: BERT is used-in-b-ab-results, it is beneficial on-BIB-s in the ab-dis-BERT, they is redu-class- is-b, so--", "answers": ["BERTbase", "BERTbase"], "all_classes": null, "length": 3852}
{"pred": "Five models: REBilleters (re-assessed extraction was not-assessed (unfortunately, or).", "answers": ["Answer with content missing: (LVL1, LVL2, LVL3) \n- Stanford CoreNLP\n- Optical Character Recognition (OCR) system, ParsCIT \n- further abridge the input text from level 2 preprocessed documents to the following: title, headers, abstract, introduction, related work, background and conclusion."], "all_classes": null, "length": 1822}
{"pred": "Yesbs20 points in the encorbidu1 (onward-repeo under-neural (unneural-neural)\n\n\nUn-reas-reward-form-on)\n\nYesure:un-ne (un-dou-un-answer)\n\nYes (unew) or IN-neural)\n\nYes-ne-ne-t-re-neural-neural-\nun-un)\nun-unne-ne-re-ne-ne-un-ne-ne-ne) and un-ne-be", "answers": ["Yes", "Yes"], "all_classes": null, "length": 2077}
{"pred": "M-INIC-AN-ANN-INALSs-INCRESCODAL:137: \"for the testedal's\" for\" or BIBLear or not-ward sum-FormALS0.", "answers": ["MIMIC-III", "MIMIC-III"], "all_classes": null, "length": 2992}
{"pred": "Thesis sub-lised offensive/callyed INBCOREFFORM1001.yes: OLEDTWO10: \"Offsive-sub-offensive posts OLID, there is \"unilised\" in-related\". uni-leveled, unanswer: \"unavailable\" (yes Off\". Unanswer: \"Off-BIO20, yes, unanswer\" OLID\" is included in Off-T, the shared in un-guarded (Offens) and task A-BLI) inL, the, un-s, L", "answers": ["Level A: 14100 Tweets\nLevel B: 4640 Tweets\nLevel C: 4089 Tweets"], "all_classes": null, "length": 2255}
{"pred": "Attels (yesht-EWR-EtAlk-Et_Et-nmt-SM-NMT is the concu-E-attention-Eng-EMG-Et-talu-n E-IM-B1-un-attEt-s-s.\n\n yes,INPRM-Et-M-IBBM-IBM:BIBMDP-t-shon-refs-EM-ng.s-P-s-Et-t-IM-s-N-s-N-ANM-", "answers": ["it captures other information rather than only the translational equivalent in the case of verbs", "Alignment points of the POS tags."], "all_classes": null, "length": 3372}
{"pred": "Bag-form or experiment baselines onset sublies\"s\" is the number of dialogue BERT for the given the unswerddes \" or BERT, R, yes or BERT: (un-no-sentiment, unanswer. The question: \"yes, unanswerable over dialogue datasets\" in the article is (BOW, LAT datasets\" (yes, the article R.", "answers": ["BOW-LR, BOW-RF. TFIDF-RF, TextCNN, C-TextCNN", "bag-of-words (BOW), term frequencyâ€“inverse document frequency (TFIDF), neural-based word embedding, Logistic Regression (LR), Random Forest (RF), TextCNN BIBREF10 with initial word embedding as GloVe"], "all_classes": null, "length": 3181}
{"pred": "Theyal0 IN INFORMulate27, \"yes: 5 for INFORMERFORM1 and INFORMINEFOR5, they use \"unanswer2, does not recommend:lets1: unavailable:unlineFORM0\", yes\", \"no\", INFORM3, or INFORM, or \"no\", \"INFORM0, yes, yes2, un 5, Amazon IN, un- IN, and INLINE5, BIBIB, INLINE, BIB, Amazon and D2, INFORM5, yes, e-0, they, and INFORM5, the Amazon,", "answers": ["Unanswerable", "48,705"], "all_classes": null, "length": 3307}
{"pred": "\"Model unprovide \"unsubside: un-B, unanswer the multilinguploversonet: CoV-un or-C-un or unprovide-based-sub-un-to-1-un-m-un-d6-sub-c-un-1-1-mult-un-un-un-un-un-un-un-un--C0. or1-A-un-C-1-un-un-un-1-un:-un-un-un-C-un-Call-ascription: Question", "answers": ["follow the architecture in berard2018end, but have 3 decoder layers like that in pino2019harnessing"], "all_classes": null, "length": 2424}
{"pred": "Pennised-state-of the authors (severify the PRU, WD: yes, or WBIBREF37 Do-BIBREF7 or Wiki, BIBREF32 and WTBIBREF1 and WTBIBRREF3BREF3 (un, orphammay7 yes-BIBREF3 and LR22 and3BIBREF3B16 and TBIBREF33 and R6BREF, EQR3 and LR6BREF3 and WBREF3 and R7, respectively, R6 T3", "answers": [" Penn Treebank, WikiText2", "Penn Treebank (PTB) , WikiText2 (WT-2)"], "all_classes": null, "length": 3302}
{"pred": "Unanswer is \"un (yes (in the article)", "answers": ["No", "No"], "all_classes": null, "length": 3158}
{"pred": "Prior due to priorising the article BIB organisation BIB17's util (bertBASE, knowledge (student model BERT, in BERT2 or [Bibot-question BIB, the prior-un BIBSG-BERTAB, in D, is un-changed is effective BREF BibREF B- BIB, the article, Bib-BERT-B-art (BREF BIB-b- BREF- D-BIB- BIBREF- B- B-B-B-R-B-BERT-B-D- B-B-", "answers": ["While there has been existing work on reducing NLP model vocabulary sizes BIBREF15, distillation techniques cannot utilize these, since they require the student and teacher models to share the same vocabulary and output space. This profoundly limits their potential to further reduce model sizes.", "distillation techniques cannot utilize these, since they require the student and teacher models to share the same vocabulary and output space. This profoundly limits their potential to further reduce model sizes."], "all_classes": null, "length": 3570}
{"pred": "word2nores for English BIBMised or not on this question (B) \"B\"): \"do\" or \"given or\" is un-answer in \"yes\" or B, \"yes, Bib\" or \"appro or \"do, BIB or \"B\" or, B\" or \"do\" or \"word\" or in BIB: BIB: or B or \"do-B\" or\" BIB or \"B\" or \"do\" or\" or \"word\" or \" or \" or BI\" or \"do\" or \"B\" or \"B\" or \"", "answers": ["using word2vec to create features that are used as input to the SVM", "use the word2vec algorithm, create several unsupervised hand-crafted features, generate document vectors and feed them as input into the support vector machines (SVM) approach"], "all_classes": null, "length": 3820}
{"pred": "From ancient-moded ancient-mod \"unised-mod\" INLINE-anciental ancient-based-modern-fusionally-un-lineIN-test:-ancient-un-man-d-INLINE-INL ancient-un (Dev-un-un-fraction ancient-mod-INLIN-mod-modern-IN-f-un-un-f-modun-f-L9-IN-mod-un-mod-N-mod-INLINE-INLINE-f-mod-IN-mod-IN-mod-f-un", "answers": ["ancient Chinese history records in several dynasties (about 1000BC-200BC) and articles written by celebrities of that era", "Ancient Chinese history records in several dynasties and articles written by celebrities during 1000BC-200BC collected from the internet "], "all_classes": null, "length": 3722}
{"pred": "Unsetionised: Yes or \"yes/unanswer\"\".\" (unanswer\" or \"un\", \"unanswer\" \"article\" (answher) for the article conci's, Bibbed (art (d) for-up-reading-posed: (art:answer/art \"set\" (set \"user) Yes: Yes:quora (: \"un\" (b) and BIB (set) (answer-question). Bibb (un) and proset (b) for-type-un-of-ill- for-: B (re", "answers": ["No"], "all_classes": null, "length": 1561}
{"pred": "Words's-unpredicting-re-st-re-to-account-level-B-class-BIB0-B-1-No-BIBLIB-un-BIB-un-un-B-t-class-t-B-un-No-F-F-B-B-I-BIB-B-un-t-t-I-B-t-un-t-I-t-B-un-t-B-No-t-I-un-V-F-1-t-L-F-L-t", "answers": ["words embeddings, style, and morality features", "words embeddings, style, and morality features"], "all_classes": null, "length": 2091}
{"pred": "United-superport, un-research isole, \"un-W-ad-length-Wib-N, and-passed-t-un-W-1 (i, language-dev-sub-W-v-D-v-ud-data-bib2BIB10 (v2N-ad, or monolum-part forW-W-N, and v-v, LAS for X-B-W-B, v2-un-v-t-X-large-t-BERT and v1-W from English-Ar", "answers": ["United Nations Parallel Corpus, IIT Bombay corpus, OpenSubtitles 2018"], "all_classes": null, "length": 3405}
{"pred": "Unised-word2: \"Corpus (uncis or \"Synthetic or morphou\" is-2 (word) (Greek-n-we, or \"un-7-un-word is, is is- Morph-word-ne\" or-word (Wor-morpher-word-un-Question-un ' morp morph-do or-word) results (un-corpus (un-G\", or-or-word-ve-un-word-un-un-we, or-Glo-do-word) or-un", "answers": ["Unanswerable", "English"], "all_classes": null, "length": 2009}
{"pred": "Unites in the article: Yes: (Yes, or for future work, unspecified CBT: for D) or unanswer: DIBREF, that is not, unified at the article: Corpuses in sections: are un, in the article, and un, A: unavailable in: un: C, of the article, annot, or NLP, BIBREF: C, annotation, BIBREF, un, PEAP, A, C:, un: Bibref, un, un, bib, A1, and un, BIB, A: and", "answers": ["No", "No"], "all_classes": null, "length": 1899}
{"pred": "Over  or \"unanswer iso Overly-unc-19, sentences-over20, ormedicording Over-19,000000-19 is \"unabrid-over-19 dataset, or, MTC-1-was- is BIBD?", "answers": ["45,000 scholarly articles, including over 33,000 with full text"], "all_classes": null, "length": 2150}
{"pred": "Complearable unanswer-unferences (unanswer:, for-generated-abvi-ref0. un-related data-data-attention-un is-curi-attention, unbi-attention-dis-attended-classical-an-o-abbrerefs-att-M-s-abstraves:un, is class-abbre-un-model-model-class-un, are-evalu-un-class-att-dun-an-un-attention-att-d-att-un-d-att-un-", "answers": ["support vector machine classifier (SVM), logistic regression classifier (LR), Naive Bayes classifier (NB), random forest (RF), CNN, LSTM , LSTM-soft, LSTM-self", "support vector machine classifier (SVM), logistic regression classifier (LR), Naive Bayes classifier (NB), random forest (RF), CNN, LSTM , LSTM-soft, LSTM-self"], "all_classes": null, "length": 2895}
{"pred": "Unward: Is the karnetmatrices: \"artful auto-no or rest-form (u) for the article, or phonetic: unanswerable, \"un-no\", or speech-br-mat- or- (un-) or the 'yes\", in unanswer: \"yes\", or/re-: (inter-un:ref-un- (...) or /-n-play- or- \"a-K I\", or \"yes-un-or-u-\" is: un- (un-in-no-un- no-no-k-", "answers": ["1913 signals", "Unanswerable"], "all_classes": null, "length": 2361}
{"pred": "Conquest: [yes: [unggereml (Furous).)\n\n [unanswer: yes]\nModule: \"Telegram\" (MM): unanswer: BIR: Module Macaw: MMacaw'sification: [un]\n\n: Macaw's dialog FIG: B: [un [un:] Mac: un: un, un Macaw. (un: DH: Telegram: un)\n\n\n Mac: T: Viz: un: un-g: Scient: un: Macaw F: Macaw's Mac: un", "answers": ["Co-Reference Resolution, Query Generation, Retrieval Model, Result Generation", "Co-Reference Resolution, Query Generation, Retrieval Model, Result Generation"], "all_classes": null, "length": 1701}
{"pred": "Unaaron' or \"S\" or-0 for WikiQBIBREFINEA-dom's Quesa or correlated questions in, unified Wikipedia, yesa or un'a or SMT-0, is a orIBOM or no BIB or SESROS, un-data: Un BIBREF4 or comes or WS-SQ and SQ, or, is an un-SQUA or BIBREF1, is a method or ornament or IQ or or, and un P- or BIB or SQuAD- is a, B", "answers": ["Unanswerable"], "all_classes": null, "length": 1913}
{"pred": "Unanswerable-t-t-li-Both-row-106-t-t-no-level-s-sthat-1-3, English is-t is unanswer-tri-t-un-t-speakers- un-t-t-tri-s are-t-set-b-t-t- un-t-speakers are-t-t-t-tri-t-t is-t-t-t-t-t-t-t-t-t-independent-t-t-tri-t- is-", "answers": ["Unanswerable", "Unanswerable"], "all_classes": null, "length": 3794}
{"pred": "SQ (or SQuizards: Article or BIB1, yes, yes-Depreciable (unfortunately or D: SQuad B2 is or (10)SQuD20, and Qu20 or \"unor or SQu2 (un or Pro27, or SQu27, or (S-Qu21 or).\n\n\nSQu2: BIBREF8 or BIB2, R20, Qu-A QuT: \" is (v: the question generation BIB4: SQu: 80S-SQu2", "answers": ["SQuAD", "SQuAD"], "all_classes": null, "length": 3757}
{"pred": "Semitzzilla \"Cle (or) for, or (yes or-answer or on, un-unig: SemEval-RNN-D1-R-un-d, or the-17, and, or, or the dataset (RNN:s, and- and, or un-un-un- (un, connection layers, un-R-Context- and RNN-1, pool, and, and, and, and, and, and, and the best un- and, and, and-un-un- and, un- un-R-20", "answers": ["relation classification dataset of the SemEval 2010 task 8", "SemEval 2010 task 8 BIBREF8"], "all_classes": null, "length": 2393}
{"pred": "The results on the English WSD (non-or-un-un-relateds (20-word-word, or) and-based, or-the UDNN (non-answer-3, or: BIB- Is not the table BIBREF6-not-un-contextualized, BIB, are: 9: yes, are-the NIP-F-3: SELA WI-un-bod-the BIBREF-un-cor:9-un-bib, or-un, English: yes-7):no-un", "answers": ["2174000000, 989000000", "2174 million tokens for English and 989 million tokens for Russian"], "all_classes": null, "length": 2958}
{"pred": "Qualiton: un-s: Answer: Yes, the answer (unanswer: Multi(yes) (yes/sales (yes) for the answer: no-question) on the following score, question:\nS, unanswer: Qualities arealentled, upper and and and\n\n\nAnswer: words areas) are-KL) is theiv. The paper:\n\nRCB, the question: Answer: the KL-lower and A, and un:\n\n\nIn the question:\n\nRC1: yeseras: un-K: the lower-", "answers": ["Spearman correlation values of GM_KL model evaluated on the benchmark word similarity datasets.\nEvaluation results of GM_KL model on the entailment datasets such as entailment pairs dataset created from WordNet, crowdsourced dataset of 79 semantic relations labelled as entailed or not and annotated distributionally similar nouns dataset.", "Given a query word and component id, the set of nearest neighbours along with their respective component ids are listed"], "all_classes": null, "length": 2220}
{"pred": "Improises-F-1-F1-F1-un-F1-A-A-yes-score of \"es conco-n-F1-I-I is-s-F-1-F-F-F-F-F-F-L-F-F for MRC-F-task is \"I--I-P-L-s \"s-\"- \"-F-F--1-ab-F-I-T-un-F-F--O-0, N-1. F1-1-s-s", "answers": ["Using DSC loss improves the F1 score by +0.58 for MRPC and +0.73 for QQP", "+0.58"], "all_classes": null, "length": 3566}
{"pred": "Assetted-un answer ( BIBLINE: T-R) on BLS (BIBREF1 ) isotop (BIBRI ) iso-m BIB, BIBRE (BIB)B0 orBIBREF0 ) is (T) for question, or LINELINE (E) ) EGL is un-m-BIBL (IN-) in subsequent in BIBBIBIB) (0) T-BIBBIB) ( EGL).\n\nE ) (BIB1) is the EGL (INLINE) (T-IB)", "answers": ["reducing the variance of an estimator,  EGL method in BIBREF3 is almost the same as Eq. ( EQREF8 ), except the gradient's norm is not squared in BIBREF3", " Fisher Information Ratio"], "all_classes": null, "length": 1671}
{"pred": "LBED isoversed inference (for auxiliary form or encoder-sequence-context-NOR (s) or or INLINEFORMO'solution or form-unanswer, Pat (yes: ... or INO, or the answer: L-answer is treated as is a-paper-s-B-system iso-in-sequence, the form is the-s, the MSD, or for four-ref-generation-form-B-iscal is-like- A system is conc- for the system, INLINE-L-systems is al form,", "answers": ["LSTM", "LSTM"], "all_classes": null, "length": 2289}
{"pred": "Natural language questions basedyes of the article: \"un yes or no\" or un-an-t un-no-un-no-no-un\" BIBEF ofun-an-ans-no, \"un-on un natural-un-no\" or an un-un-language-cl-no-BIBIB-un-no-un-no-an-un-no-the-B-a-un-un-natural-cl-un-un-un-SQU or-un-an-cl-yes-yes-un-art-data-un-", "answers": ["These 8 tasks require different competencies and a different level of understanding of the document to be well answered"], "all_classes": null, "length": 3817}
{"pred": "Yes-unanswerable questions from-class basics, a question. BIBREF-article-PRA100 was-Eg. PrivacyQABjects BIBREF-EUaspect-un-def-quest- BIB Privian policies, BIBREF-1 b-E-15-un's,Privy, BIBREF article- SAB1, Sala-BIBREF15, BIBREF, BIB-E-E-E un, E-E Et-E annot-E-K, unanswerable is a question.", "answers": ["SVM, No-Answer Baseline (NA) , Word Count Baseline, Human Performance", "No-Answer Baseline (NA), Word Count Baseline, Human Performance"], "all_classes": null, "length": 3855}
{"pred": "230 (LKSCD) (SEITD) (int-K) sub-L1-number of entities are?\n\nNumber of unanswerable) (unanswer)\n\nun-g (unanswer) (yes) or \"med-un-K) (unanswerDIT-K)\nL-un- (un-un-un-K) (unment-K) (L-un-un-un-un-un-b-un-un-gu-un-un-un-un-un-un-un-un-un", "answers": ["53 documents", "53 documents"], "all_classes": null, "length": 2667}
{"pred": "Food-recipes and personal-user-recipe-ex from (inference). (from: p-k-related:recipe or Cocktail-attions or calci:ment-recipe, or recipe-unified recipes) or recipe-high, or prior-reciop:recimentions (PW) (recipe) for, it is for the food-recipe) or prior-reci:, the Food. (recipe, Food.rank, or, the recipe-divers, or recipe-prior-1, and recipes, or not p, the recipe-", "answers": ["from Food.com"], "all_classes": null, "length": 2649}
{"pred": "Incorared-sy (quick) on the word-leveled-un-yes, un-word-unwords (from LexVec, the article, unanswer on, unchanged and un-un is incorporated, \"syps, un-un the out-S down-text-down), is evaluated on the-un-word-unables in the proposed here is unwords-un and 'the models. The out and the unanswer is the un-ve (unanswer is given-the resulting-on the \"on-unsuper-un\" is, the paper. The Morp's", "answers": ["We also evaluate all five models on downstream tasks from the VecEval suite BIBREF13 , using only the tasks for which training and evaluation data is freely available: chunking, sentiment and question classification, and natural language identification (NLI). The default settings from the suite are used, but we run only the fixed settings, where the embeddings themselves are not tunable parameters of the models, forcing the system to use only the information already in the embeddings."], "all_classes": null, "length": 2083}
{"pred": "Un concise-s: 13, BIB-dise (YT, or unanswer: Philotically and 15, T, unanswerable: un answer: 10 (for) [N, and [co-, co-med: un. [d: Philo,] N, and phenot, [M, and: BIB-d: 15 un] and co-an- 15, and operators (1, and [co-un, and Oper- or and [co- and [oper-B(H) and] T-", "answers": ["Adv. Heart Disease, Adv. Lung Disease, Alcohol Abuse, Chronic Neurologic Dystrophies, Dementia, Depression, Developmental Delay, Obesity, Psychiatric disorders and Substance Abuse"], "all_classes": null, "length": 1651}
{"pred": "Unan-no-N-unanswer: \"Is-yes-un- for future-freques-A1\".yes-un-un-un-BIB-un-unanswer-un-C2-n-un-un-un-un-un-un-un-un-un-un-un-un-un-un-n-un-un-L1-un-un-un-un-un-un-un-un-un-un-un-un-n-L1-un-L-un-un-un-un-", "answers": ["204 tokens", "Most texts, however, range roughly from 150 to 250 tokens."], "all_classes": null, "length": 1898}
{"pred": "Pattern-un-un-d-un-or: (no-dised-3 or-un-concise-un- is-un- un-P-un-un-un-d-error-un-d-un-m-un-un-un-P-P-S-un-d-un-d-un-un-un-system-performs-un-un-un-c-an-un-d-un-d-un-un-un-d-un-un-un-no-un-un-un-un-d", "answers": ["(VVD shop_VV0 II, VVD shopping_VVG II)", "patterns for generating all types of errors"], "all_classes": null, "length": 2133}
{"pred": "Unanswer: Un, yes or no-line (un-scaling the-regularized-un-un: or unanswer unanswer: No, unanswerable.", "answers": ["No", "No"], "all_classes": null, "length": 3974}
{"pred": "Random organisation for-sentised utilised data scientific classification data from article, or Randomized-determ, or \"Random-random-random-random-random-H-approsent- Random Random RKS approach\"-random-Random-used-method, implemented in the Random Random Kitchen-method, or otak-SFLRS BIBREF-RKS, or RKS-Ryes-BIBLE-RKS-un-c-un-off-un-un-off, or- kitchen-sent, un-off-un-random-un-un-R-un-", "answers": ["Random Kitchen Sink method uses a kernel function to map data vectors to a space where linear separation is possible.", "explicitly maps data vectors to a space where linear separation is possible, RKS method provides an approximate kernel function via explicit mapping"], "all_classes": null, "length": 2361}
{"pred": "They is-based on-the Turkish SIT-18 (Inferred BIBM, ornament, no", "answers": ["BIBREF11 , BIBREF26 "], "all_classes": null, "length": 1912}
{"pred": "Impro realised-is-unified-on: unions-correct-yes or un-random-d-random-randomly-per-random-on: (un-un-based-un-no-un-error-correction-re-corpus-random-con-un-random-re-errors: Improce-un-un-d-un-correct-m-errors-un-cor-V-un-corro-random-un-error-re-V-un-un-errors-on-un-errors-errors-un-PCE-random-", "answers": ["Combining  pattern based and Machine translation approaches gave the best overall F0.5 scores. It was 49.11 for FCE dataset  , 21.87 for the first annotation of  CoNLL-14, and 30.13 for the second annotation of CoNLL-14. "], "all_classes": null, "length": 2164}
{"pred": "ND_Preduction (un-o-f) Out-coder-GRU-j-embed-based-is-level-sp or- Out-un-c- N-is-super-s-c-vec-super-c-s--s-s-optim-these-d-c--model--the-character-s-the-em-bas-voc-hashtag-of-v-pred-is-require-un-un-d-un-v-thes-Out-f-Pred-embeds-em-", "answers": ["None"], "all_classes": null, "length": 2473}
{"pred": "Seven experts worked on the privacy corpus (unanswerable questions in the questions posed bylines for the privacy qa in the privacy policy of the questions.", "answers": ["Individuals with legal training", "Yes"], "all_classes": null, "length": 3846}
{"pred": "Machine un-un BIBREF: yes, yes or question\"un BIBREF B-to-D-BIBRE- BIN the study, BIB- B no B BREF is B-I-B B-BIB-BIB-BIB BIB-3, BIB- B- BIB- BIB- BIBREF-- yes- B- B- I\n B, is: B- I-, BIB- B- B-L- yes: B- B: B-B- B no-B-BIB'- BIBREF- B", "answers": ["Maximum Entropy, Weighted Finite State Transducer (WFST),  support vector machines (SVM), conditional random fields (CRF)", "Maximum matching, Hidden Markov model , Maximum Entropy, Conditional Random Fields , Support Vector Machines"], "all_classes": null, "length": 3471}
{"pred": "Three questions (unsafe (yes\" Armenian HERE, unanswer or) unanswer: unod) in,known and  solutionof (LOC) (unanswer (automised) was not used) incorations, unanswered entities were unanswer asanswer the article. (un solution, HER: (un,  is an article) (unaddress) was used, is un-un annot (un, or the article, or the scores, the article, un-arm the solution, un (unanswer, solution, un, unanswer, un- un-annoted, and", "answers": ["Stanford NER, spaCy 2.0 , recurrent model with a CRF top layer", "Stanford NER, spaCy 2.0, recurrent model with a CRF top layer"], "all_classes": null, "length": 2759}
{"pred": "WN1, or BIB, or \"J@1, BOT1 and BPJointed(Jointing, or BWBREF43 and BI-3, orBIB, or W-1 and BIB1, BIBP, BIB, C3 K, BIBREF5 B-1 B- orB-3, orBIB, or evaluation, W-1 B-1, B-d, or B-1, B- L-B, B-E, B-1, B-to-1, B-3, B-", "answers": ["WordNet BIBREF0, Freebase BIBREF1, WN18 (a subset of WordNet) BIBREF24 , FB15K (a subset of Freebase) BIBREF2"], "all_classes": null, "length": 3367}
{"pred": "\"No or \"yes, unanswer: yes (un-harised, or-1) in the proposed informat, unanswer:, unanswer-pol, unb-d. un-unaccounted: un-op-Anb-multi-RNN, un-projected-w-v-state-b-un-h-un-used--rest-v-v-un-embed-used-un--mod-d-project-v,-An-EC-att-mat-v-sub-K, un-un-v-v-un-", "answers": [" LastStateRNN, AvgRNN, AttentionRNN", "LastStateRNN, AvgRNN, AttentionRNN "], "all_classes": null, "length": 2823}
{"pred": "Personalised cyberbulary or \"un\" onwards to an anonymous or \"yes\" or \"yes\" on sexism on Q INLINE univeros (Art INSB, or un-cyber\") on cyberbullying with-un un SMPM or un or form or B2 as class un SMPRESIL-\" LST on the same as the definition of racism on the Personal TL1.A un the S is un.", "answers": ["personal attack, racism, and sexism", "racism, sexism, personal attack, not specifically about any single topic"], "all_classes": null, "length": 3244}
{"pred": "Yes-article or a \"unanswerable\" diffled or \"unanswered articles are-answer-no-documents-yes-LSE or ISIS and ISISIS or ISun-organ\" (PL-LDA-doc IS-art) approach of-LDA-doc and N-ISIS-LUNISISISIS-IS-un articles-doc-art-art-art-doc topics in ISIS and-doc-art-doc-doc-doc-doc and N-doc-doc of \"un-L-un methods.\n", "answers": ["Yes", "Yes"], "all_classes": null, "length": 3634}
{"pred": "Anset or is utiled synthentic in the F-o. Is the positive-level-NO: Is the tweeted or yes- the 5-lead-level- annoted-scores (yes-level- e. of the positive tril- L- the percentiles-level-tiles- e.e. Yes-score- Is, the percent-emot- sc. the percentage-level-sc-s- of feature- the percentage of scor- the le- performance-t-t- un-level- Is: F-sc-t- sc-", "answers": ["BIBREF12 , BIBREF13", "an existing, annotated Twitter dataset that was constructed based on a hierarchical model of depression-related symptoms BIBREF12 , BIBREF13"], "all_classes": null, "length": 1939}
{"pred": "The DIDVizward, \"un-un- or \"English\" (or ') or \"un- or \"un- the N-language, \" in-language\" or \"VIL-V (LID-dis-article of the article- or- or- \"un-V- V\" (V-un- V- (or- or V) (un- \" (V) or- or-V- or- or \"un- or \"un- or-V-V- or-V- or \"un- or \" or \" or \" or-V\"- or", "answers": ["Nguni languages (zul, xho, nbl, ssw), Sotho languages (nso, sot, tsn)", "The Nguni languages are similar to each other, The same is true of the Sotho languages"], "all_classes": null, "length": 1877}
{"pred": "IMM or \"unbalion\" or \"unanswerable\" or \"un or S \"W83199\", (unanswer: total, on I (SA or \"totally\" is: \"unanswer or the article\" or \"NGB\" or \" M30-unanswer:IBREF: un-un or \"ungoogle\", or \"un-un-un-un-180, I-un-un-bal: \"yes, I or CI or 'un-optual' un or-3-un-1 or-un-un-un-", "answers": ["IMDb dataset of movie reviews", "IMDb"], "all_classes": null, "length": 2327}
{"pred": "8 to the apparent or offensive speechment of 80 and t-subreddies: 8595-yes: INline-unpossible of 10-unclear: 8-sub-reddit-sub-classified-offensive:  \"offensive speech in the main-off-sub-un-offensive-v-un-class:UN-authors of offensive speech.", "answers": ["accuracy and F1-score of 89.6% and 89.2%, respectively", "accuracy and F1-score of 89.6% and 89.2%, respectively"], "all_classes": null, "length": 3313}
{"pred": "Outline yes-h- \"yes-de-AEM, unanswer- (organ-dir-based-LE-spec-ch-un, B-dis-vis-organ-\ns-ven-no-hot-h-un-show (Art-INLINE-form-vis-event-me, BIBREF3,in-s-is-s-s-AEM-s-organ-s-s-s-s-out-the-s-s-extract-s-s-m-out-s-s-s-s-s-un-", "answers": ["K-means, LEM BIBREF13, DPEMM BIBREF14", "K-means, LEM, DPEMM"], "all_classes": null, "length": 3841}
{"pred": "8 (unified in whats or 1, \"unised\" or yes/no. responses, or or related to c, or \"unwit\" oranges or reset or booking 1 or no, or-context, reset or or yes-related, or un-to, sc-screen-imed scre-\"BIBREF1 or, or yes, or reset or scre-avere sub-im or (B, un-1, un-refer to-0 or-1 or BIBREF0, or Restaurantz-BIBREF,\nBibref", "answers": ["English, German, Spanish, Mandarin, Polish, Russian, Korean and Serbian", "English (Edinburgh), German (Berlin), Spanish (Madrid), Mandarin (Taipei), Polish (Warsaw), Russian (Moscow), Korean (Seoul), and Serbian (Belgrade)"], "all_classes": null, "length": 2754}
{"pred": "The question-scised (y-on-state or BIB4 are BINLINE-y on the Cluste:R1 or. (B-answer: B-sc-we-b-state- BIB-type (in-3 was BIB-do-onRub-for the English or-BIB-scR-BIB-1-the-un-state-of-sc-cl-BIB-the- Cl-we-sc, the- R-state.B-R-sc-R-sc-the-R-sc-the-un", "answers": ["rupnik2016news", "rupnik2016news, Deutsche Welle's news website"], "all_classes": null, "length": 3160}
{"pred": "Unicised in the les: \"unanswered\" or \"un\" in the article\": \"unanswerable\" or \"tshi-sh\" or \"unwised\" in the LID- or \"dis\" or \"sc- or 'un\" or \"un- or \"un- or \"un-\" or \"tsh-w-shared\" \"un- or \"un- or\" or \"un\" or \"un- or t- or \" or- or \"un- or \" or\": in \"un-un-\"-un- or \"un-k- or", "answers": ["Yes", "Yes"], "all_classes": null, "length": 1868}
{"pred": "Inferred: InferSent utilization, universal or un-Nov (yes\", you\", or \"unanswer: STS-different-or, yes-b-datal-unsuperised\". GLS, G. BIBDREF:\". Yeszeres are or BIBR: so-N,poly-d-d-t-b-s-d-article-un-un-b-b: un-d-2-d-B-t-sim-un-d-BIBREF-d-the-B-STS-un-B-", "answers": ["GloVe, BERT, Universal Sentence Encoder, TF-IDF, InferSent", "Avg. GloVe embeddings, Avg. fast-text embeddings, Avg. BERT embeddings, BERT CLS-vector, InferSent - GloVe and Universal Sentence Encoder."], "all_classes": null, "length": 3862}
{"pred": "Sentsens are answered wither or Sentised and SSTS, un-defined: Sentimentask (yes-o-un-60-2-no-s-d-dent-N-SSTS-1, Sent-un-un-d-s-s-yes-no-un-un-d-un-s-un-S-s-box-S-S: B-un-s-od-un, SS-un-un,-d-un-of-un-d-un-the-d-d", "answers": ["MR, CR, SUBJ, MPQA, SST, TREC, MRPC", "MR: Sentiment prediction for movie reviews snippets on a five start scale BIBREF25.\n\nCR: Sentiment prediction of customer product reviews BIBREF26.\n\nSUBJ: Subjectivity prediction of sentences from movie reviews and plot summaries BIBREF27.\n\nMPQA: Phrase level opinion polarity classification from newswire BIBREF28.\n\nSST: Stanford Sentiment Treebank with binary labels BIBREF29.\n\nTREC: Fine grained question-type classification from TREC BIBREF30.\n\nMRPC: Microsoft Research Paraphrase Corpus from parallel news sources BIBREF31.", "Semantic Textual Similarity, sentiment prediction, subjectivity prediction, phrase level opinion polarity classification, Stanford Sentiment Treebank, fine grained question-type classification."], "all_classes": null, "length": 3861}
{"pred": "Unseting-based e-book INLINEFORM2 (i.INLINEFORM10 INLINEFORM (i (i.0 for the Amazon's INLINEFORM2 INLINEFORM2.1.no INLINE1.INLINE-no INBook, the number of INLINE.no-based the article IN INFORM i IN FOR IN.INLINE-book IN. IN.i (unanswer IN-i.INLINE-IN- IN. IN. Is FIN. IN. IN  i.i. INLINE.i approaches. IN-book. (i. IN,", "answers": ["33,663", "33,663 distinct review keywords "], "all_classes": null, "length": 3305}
{"pred": "Context-ised and HU-based-context: Yes, or \"unfiernt in-quoted for \"yes\" or \"yes-\" or for \"unbal\" or \"un-bas, or T-abusive\" or \"yes\", \"yes\" or \"qu\" or\" for \"surv\" or \"yes\" for \"h. Yes, or \"yes-d or answer-quoted-d: Yes,\nB-quo\" yes-captos the-yes-qu.\n\"\" or- B-based and, yes-quiz-based representations B", "answers": ["using tweets that one has replied or quoted to as contextual information", "text sequences of context tweets"], "all_classes": null, "length": 2060}
{"pred": "Yes- do-spaced \"yes\" (or, BIBREF) BIBREF is, or SVM, or BIBSO-down, yes, BI-th, unsuper-t, or \"no\" (yes, BIBM, or, or, BIB, BIB- similar, or, BI- or BIB- or, yes- or \"un-th, or \"yes-sh, or \"un, and, or \"yes\" (BIBER0- or, or BIBREF0-1, and R, BIB-DBIB,1", "answers": ["No", "No"], "all_classes": null, "length": 1906}
{"pred": "No-1-yes-ch (1, blog-these Michigan Maps or...) (yes, blogposts (blog-Geocised) (art-lite-1, BAB-unanswerable: They: The question)", "answers": ["No", "No"], "all_classes": null, "length": 1443}
{"pred": "En \"`System (``yes`yes/DAB, B`unset: '`yes` (system)`yes-system`, or system/yes:B`nno``{yes}yes (yes\", unno`yes, yes:unset2`X`system: BIB-v`no` L`yes`Enset`yes-yes`unset`yes`yes, unset-`System`yes`yes`un-set`yes-v`yes-set`set-M-yes`yes`yes-un-set`yes`yes", "answers": ["For SLC task, the \"ltuorp\" team  has the best performing  model (0.6323/0.6028/0.6649 for F1/P/R  respectively) and for FLC task the \"newspeak\" team  has the best performing  model (0.2488/0.2863/0.2201 for F1/P/R respectively)."], "all_classes": null, "length": 1541}
{"pred": "DTA cora cora (unless, oracle, or for the gold corpus, and the number of D, SGNS, C, D, D, or OP, or OI Score: is the same,12,1, for) was set up,) was un, unanswer, for, is the cor M, DSMH, and, D, D, un, and, Bibl, and, was the conc, was, the D, D, and D, the baseline, and the ev, was for the D, the same, D, the D, was", "answers": ["DTA18, DTA19", "Diachronic Usage Relatedness (DURel) gold standard data set"], "all_classes": null, "length": 1908}
{"pred": "50-no, or \"unanswer\" in the article BIBLEOM question-noi BIBREF or BLEC BIBREF: un-no-sO-no-answer-no-labeled bas, BLE-12, unanswer-labeled or un-labeled inunin un-related BIBL: uninform un-no B-s-C-un- B-no-un-o-un-un-CO-un-label in the data-label-BIB: un-un-un BIBREF4- in-", "answers": ["13,757", "10,898 articles, 17,794 tweets, and 13,757 crowdsourced question-answer pairs"], "all_classes": null, "length": 3704}
{"pred": "KNN, \"Car-speak, 'car-speak' (es (e. e = the article:car) or '?'", "answers": ["KNN\nRF\nSVM\nMLP", " K Nearest Neighbors (KNN), Random Forest (RF), Support Vector Machine (SVM), Multi-layer Perceptron (MLP)"], "all_classes": null, "length": 1639}
{"pred": "They does the article-unanswerable-context-represented-answer-answer:un-biblium-article:fant organisation, that ors: or the, IN-word, or with:\n\n\n\nthe: \"combined-un-\n\n\nor:\nunanswer:\n\nAns: \"yes:\n\n(b:\n\nComb the:\n\n\n1.\n\nContext-C: extended-context, simple:\n\ncontext-b\n\n\n\n\nmiddle context,\n\n\n\nC concatm-\n\n\nyes:", "answers": ["They use two independent convolutional and max-pooling layers on (1) a combination of the left context, the left entity and the middle context; and (2) a combination of the middle context, the right entity and the right context. They concatenated the two results after pooling to get the new context representation."], "all_classes": null, "length": 2435}
{"pred": "Multi-``System-FL-v-:System (multi-v (System,System:System of Syt-v-v\"System{System BSL-un-un-unarch-C-v-System, yes-v,X-v-System-System-v-System-un-un-i-v-System,System-S-un-v-System,System-un-v-v-System,BERT-System-v-System`X-read-System-un-System-i-Art-X,BIB-v-System-v", "answers": ["An output layer for each task", "Multi-tasking is addressed by neural sequence tagger based on LSTM-CRF and linguistic features, while multi-granularity is addressed by ensemble of LSTM-CRF and BERT."], "all_classes": null, "length": 1514}
{"pred": "The article univous for the COVID-19 (sent un-1, or unstructured is un-vised: or the introduction, the dataset-19, the ARI-dataset unanswer, is the un-1, the dataset-1)1 (un-1) the COVID-1, the CORD-1 containing the C-1, unatt, and S unav-1 showing, un-1, unav-1 un-1 dataset, un-1, un-un-1, un-1 un-1 un-1 un-un-un-1", "answers": ["which contains over 45,000 scholarly articles, including over 33,000 with full text, about COVID-19, SARS-CoV-2, and related coronaviruses", "contains over 45,000 scholarly articles, including over 33,000 with full text, about COVID-19, SARS-CoV-2, and related coronaviruses"], "all_classes": null, "length": 2156}
{"pred": "17045433 (SUGSUG BIBS1 (summer, 53 (self-app3 (self-aspect-quota45, 45 (IN3)3) (Algorithm3) (unanswer, un3, SUGGET5, nouns4-3, SUG-LIN1 (4)4, INLINE23) (4 SUGE, (45 BIBLE201 (unanswer4) SVM, INLINE112) WEAK (5-3 (multi-4) S", "answers": ["26972", "26972 sentences"], "all_classes": null, "length": 3040}
{"pred": "Per-B: \"unlished, or \"articles\" or \"unsupervised PCFB\" or \"unanswerable\" or \"BIBPREF1\" (unsupervised, unanswer un BIBREF state, unBIBREF0\": GIBREF'plised or \"BIBREF3: B-art F (unanswer unanswer- un,yes, or \"super\", or \"unavailable, or alignation, BIBREF17, TBIBREF21, un:s B IB4-or, BIBREF2, I, RIBIB", "answers": ["Unanswerable", "Unanswerable"], "all_classes": null, "length": 2533}
{"pred": "Backospect to the question type-spec, or neutral word-correct is words is back-sc, question type-level, UN- and out-sentiment-backowers, when a back-spe, back-through UN-s.", "answers": ["In pass-through, the recognizer passes on the possibly misspelled word, backoff to neutral word backs off to a word with similar distribution across classes and backoff to background model backs off to a more generic word recognition model trained with larger and less specialized corpus.", "Pass-through passes the possibly misspelled word as is, backoff to neutral word backs off to a word with similar distribution across classes and backoff to background model backs off to a more generic word recognition model trained with larger and less specialized corpus.", "Backoff to \"a\" when an UNK-predicted word is encountered, backoff to a more generic word recognition model when the model predicts UNK"], "all_classes": null, "length": 4210}
{"pred": "The NUS (P policies unanswer-NUS forms the NUS is learned from the behavior, the article's policy is used-SARI2-modular-discental-cor-t-yes-unprovided-no-dialog-turn-inline-form-t- T-R25-the-formed- is used- is-the system-cor-state-form-pop-dialog-turn- or- policies- no-dialogue-the article-DST-S- real-formed- on- the article-go-form-dialog- is- or", "answers": ["DSTC2", "The manual transcriptions of the DSTC2 training set "], "all_classes": null, "length": 4820}
{"pred": "BLE-40 and the article of on the English dataset-noo field-based yes-field: RO\nun- the models of the above-on-0 (field- BIB-field-focused information: English, the values are used on the- the model of the article of-un-field-models of-the article of the infob-reference0, B-o: the information of the article of the article of the bi-field: the articles, unanswer-un- the an article: the article-the- the article? the model with g-dataset-1:", "answers": ["BLEU-4, NIST-4, ROUGE-4", "BLEU-4, NIST-4, ROUGE-4"], "all_classes": null, "length": 4460}
{"pred": "rresults (yes or the authors's input, i. yes or unanswerable of the LRC or the article, yes, is \"yes, unanswer or the proposed law-of-the answer-models in real-re-form-tow is or un-unanswer. or inline the question-based-of the m-l-unanswer). Yes-un or the unanswer: is un-proposed input-of.", "answers": ["SVM , CNN , GRU , CNN/GRU+law, r-net , AoA ", "SVM with lexical features in accordance with previous works BIBREF16 , BIBREF17 , BIBREF1 , BIBREF15 , BIBREF4, attention-based method BIBREF3 and other methods we deem important, some off-the-shelf RC models, including r-net BIBREF5 and AoA BIBREF6 , which are the leading models on SQuAD leaderboard"], "all_classes": null, "length": 4106}
{"pred": "Sur-Levoice-based, yes oros: \"su-f-f, unigadd-mod-s (e-set: 25.)- are-word-set:).-feature-end: (su-f-concat- \"d\" and-set:), surface, features: surface features are-unmod-un-b-un-set-test-word-un-mod-feature-mod-f-word-word-error-fore-extra-ex-mod-word-un-pos-un.\nun---b--features-", "answers": ["POS, gender/number and stem POS"], "all_classes": null, "length": 4719}
{"pred": "Largedal or 'un or un-dimensional (BIBREF12 words that or LINGREF0 or the proposed or larger words are-dim or In thews INMT, Word similarity are un' Led to the author LOS1 (B I INLINEFORM0 words that word- (or) or to", "answers": ["dimension corresponding to the concept that the particular word belongs to"], "all_classes": null, "length": 6182}
{"pred": "The question is used in the questionedalon un-to-de-nmt is unavailable in the article's article, the question-un-yes is efficient encod-BIBREF data is un-un-yes-un-de data is used in-st training-source data is used in N-d data, the same data is-d-f-does INLINE IN- English-n-to the data with the Neural-LMT-se-n-n and INLINE-G-h-marked data is trained with INLINE-n-data is available-", "answers": ["English , German, French"], "all_classes": null, "length": 4173}
{"pred": "Unswer-no-resourced or to the article's question in-un-un-unanswer-inline-source-res-w-organ or-un-resh-do the NMT article is automatically--inline-multis-res-G-NMT-un-un-un-v-best-back-un-during-attention-the article-Gather-w-w is-G-R-bas-un-res-res-un-MT-G, the-un-w-res-res-res-w-sh-res-", "answers": ["Unanswerable", "Unanswerable"], "all_classes": null, "length": 4465}
{"pred": "Disarticle onsetion orchestric recognised news articles on \"unin both â€“  (or BASE:) onset-multi-set-based-set-layer:re-categor-w. or Disstandard-on, M: or-the-set:â€“â€“two, orchestraded-multi-) categories, den-based-set, according-set, in the class-w-set-class-w:\n\n\n\n\nArticle:: \"The multi-bi: \"un:\n\nDis:\n-s:\n\nQuestion:\n\n\n- artificial", "answers": ["mainstream news and disinformation", "mainstream and disinformation news"], "all_classes": null, "length": 4856}
{"pred": "Cooked Games (d) BIBREFROBIBREF3 and \"yes\" is a single: Experiments are performed in the V-Text-based- e. (un-gone-Explore Go-BIBREF2 and un$20-1:exper experiments are performed in text--Explise-Imitation learning BIBREF-rosc-Expol-AD-sample-Ex-I-1 are-g-AD-I:BIB-I-1 using-un-d-Ex-D-LST-3-I-I-6,", "answers": ["CoinCollector , CookingWorld ", "CoinCollector, CookingWorld"], "all_classes": null, "length": 4924}
{"pred": "F Score INLINEFRIREF4,5 and F-t and concise, FINLINEFORM0 and and, and-I: \"F\", are used F-IREF: I- Score (INLINEF: INLINEFORM1 are not KP (unI, 5)4 and R-I5, models, are notF IINLINEFormI-INLINEFORM on the values on INLINEForm I-2P INLINEFREF4 and R-F: I1, I- I2 area, in the same ones:\nINLINEForm0 models:IN", "answers": ["average unique predictions, randomly sample 2000 decoder hidden states at INLINEFORM4 steps following a delimiter ( INLINEFORM5 ) and apply an unsupervised clustering method (t-SNE BIBREF35 )"], "all_classes": null, "length": 4581}
{"pred": "Their article ornamented-educit ors ornaments as-t-s-based mis-sar-un-d-biases's-eodur-encodes-e-embed-BIBER-d are-enc-p-the-d-e-un-s-d- or-d-s-t-d-pro-ref-t-d-BIB-P-P-m-t-1-system- BERT-d-no-:w-BIB-:pro-P-BIB-t-BIBREF-", "answers": ["Data annotation biases where tweet containing disrespectful words are annotated as hate or offensive without any presumption about the social context of tweeters"], "all_classes": null, "length": 4111}
{"pred": "\"un-23, or en-refresh1 or mentions BASES: unanswer-based-ment BIBREF10\" (un-t = unsuper-un-hierarchy-hierarch2-gu are (un-no-2, RED-b \"un-no-no short-no-hier-short- or-ment) is un-un-su-no-hier-1-plan-un-un-plan-13 (DIS-h-B-BIBREF2-1, un-2,2-h-un", "answers": ["rther constrain the model on the data structure in order to prevent inaccurate of even contradictory descriptions", "to further constrain the model on the data structure in order to prevent inaccurate of even contradictory descriptions"], "all_classes": null, "length": 4704}
{"pred": "Addedpos or encasted semantic or semantic or unanswer (or unanswer or additive for the added to additional or not proported or any one or un answerise or or not, the unanswer: or or: or, the or not-vise, or unanswer, or, is", "answers": ["The cost function for any one of the words of concept word-groups is modified by the introduction of an additive term to the cost function. . Each embedding vector dimension is first associated with a concept. For a word belonging to any one of the word-groups representing these concepts, the modified cost term favors an increase for the value of this word's embedding vector dimension corresponding to the concept that the particular word belongs to,", "An additive term added to the cost function for any one of the words of concept word-groups"], "all_classes": null, "length": 6244}
{"pred": "Yes, or NODEXIA on providing or \"super\" for the ones or \"unanswer2\" or, for the entity-entity, R, R, or the number of, is unanswer: \"unlc\" and the entity-wise, is the approach, and-NOLINE, is or un, uninlineing, INLINE, and the ground-tr, or ground-tr, and INLINEFORM, INLINE, for, un-L, and INLINEFORM0 , and un-, and the news-no, and INLINE, INLINE-, and INLINE, and INLINE", "answers": ["Yes", "Yes"], "all_classes": null, "length": 7837}
{"pred": "It is a-up-free-w-to-A: Bert-sent-based on-wise: (from the article-level, or not-F2, and-univ) is the novel and -BIB, it-\nThe- Answer- It-: The proposed-the-F-sum: (Sent-w-Fine-F-A- (e-extracted and: S-30-I- The: The S-3: S-F: extract-d-S- (extractive or extractive: (extract), and extract and extractive:", "answers": ["Bert model have a maximum length of 512; we overcome this limitation by adding more position embeddings, we insert external [cls] tokens at the start of each sentence, and each [cls] symbol collects features for the sentence preceding it, document representations are learned hierarchically"], "all_classes": null, "length": 4404}
{"pred": "Improvers A concistent-entty can (or!!START-! STREF4 and sparse or can \" or sparse-ent-entf'-! and sp with the article- and A pos. or 9-attention: the soft Transst the proposedhead's sparse and!, A-pro-entmax and soft-with with the r and sp! and sparse and sparsemax A-entmax and sparsemax-entref  and sp with. The question-max and sp-ent. The unique threshold  is softmax-refmax-entmax", "answers": ["the attention heads in the proposed adaptively sparse Transformer can specialize more and with higher confidence", "We introduce sparse attention into the Transformer architecture"], "all_classes": null, "length": 4902}
{"pred": "The article corpus corpus for the RNNREF6 corpus size of the experiment is used informat used in the exact experiment is used in the RNNMRRNN1, is: \"un-un-size of the rel-RNN informat, the scope, unanswerally, no-based?\", unanswer the exact improvement? for the improvement of the article. The improvement? parameters, un-RNN61.", "answers": ["Unanswerable", "Unanswerable"], "all_classes": null, "length": 5331}
{"pred": "91 \"unfine yes\" or \"Yester\" or \"un\" (un\" or \"nutrition\" or unanswerable classifications\". The number of the words that are closest in \"un\" or \"N-CONFORM0\" are not unions have\". The number of the existing\". The authors of the\". (or \"un\" or \" or \"e\" or \"un-mult-n or \"e\" in\" or \"un\".\n\n\n The \"Techn\" or \"e\" or \"IN\" or \"un\" or \"cloud\" or \"un\" or \"", "answers": ["22,880 users", "20,000"], "all_classes": null, "length": 4160}
{"pred": "Instance-BIBQQ-R:patient or expert and expert annoting of the most difficult scores to expert annotating-R-difficulty or re-annotator and-pat R results would be (unanswer is pat to be a difference between instances are training of answer of the article toscoring an abstractly-R to and i.patel R or i.d to the most difficult and expert annot to experts and an i.", "answers": ["sentence"], "all_classes": null, "length": 4369}
{"pred": "Har Answer:iBIBBREFREFREF1. (yesterday-taken-der-solve-of-f-recent-t\", or are are-fore-t-the-case-s-4- in-c-c-s-i-question--s-l-comment-any-t- or-mod-s-art-s-is-fore-un- and-t-art-the-at-x-con-f-cent-cent-t-B-1: \"yes-t-c-pre-question-t-art", "answers": ["The Conversations Gone Awry dataset is labelled as either containing a personal attack from withint (i.e. hostile behavior by one user in the conversation directed towards another) or remaining civil throughout. The Reddit Change My View dataset is labelled with whether or not a coversation eventually had a comment removed by a moderator for violation of Rule 2: \"Don't be rude or hostile to others users.\""], "all_classes": null, "length": 4779}
{"pred": "Dates INLEI-Q-0, INL and INL or unsupervised or unsupervised or \"Yes: support the automatic0, Yes\" is off cases come, and unsupervised. IRC, I-LE-J orI-0, or I-LE I-0, I-L I-LRC: I-0, I-0 cases are areacles, orI-LE-J-1, IN-L, I- Yes, LE- I- I- I- I- or law-LE-LE-J, I-LE- J-LE", "answers": ["build a new one, collect INLINEFORM0 cases from China Judgments Online"], "all_classes": null, "length": 4109}
{"pred": "Theyups. (unavailable-conventa-dorne-format-shared-form-un-case: INLINE-to-un-to- or-to-un-on 2-low-un-un-un-un-format-un-un:\nis-un-con-data-un-answer is: (un-un-con-noise: \"un-un-un-format-un, transfer-reference-un-un-con-an-un-ad-on-un-improvision: they.", "answers": ["Unanswerable"], "all_classes": null, "length": 4572}
{"pred": "Un-per-F \"unconditional\" or \"unanswer-t-uncoverhead-ARL-S-t-S-Sens-un-un-unanswer-un-AR-S-t-S-S-L-R-RL--S-S. The-S-S-head-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S", "answers": ["absolute improvement of 18.2% over the Pointer-Gen baseline"], "all_classes": null, "length": 4091}
{"pred": "Using a \"yes/no\" or \"non\". is a select of the concider-br\" (yes\" unanswer a yes unsupervised corpus used for the human-RNN-l-to-the question. or the article, \"un-no or \"un-un-\" is or the \"un-un\" or \"no\" or-yes-im-yes\" is conc-yes-un-is-no- or-the-m\" the availability-no-yes-un is the-no-un-is-\" is- the L-un-from-no", "answers": ["50 human annotators ranked a random sample of 100 translations by Adequacy, Fluency and overall ranking on a 5-point scale.", "adequacy, precision and ranking values"], "all_classes": null, "length": 5344}
{"pred": "They use the question model with consistentently or \"yes (onward-no) models\" or \"yes (Wiki-gram-model or \"un-D-class\" is or J-S-based-con-the-of-model (w-article-wiki-model). The article focuses on document quality label-no-text-art-ar-D-un-C-ub-un-D-e-D-art-art-J-art-ass-art-quality-art-ass-article-art-w-in--D-article-D models-quality", "answers": ["visual model is based on fine-tuning an Inception V3 model BIBREF1 over visual renderings of documents, while our textual model is based on a hierarchical biLSTM. We further combine the two into a joint model. , neural network models", "Inception V3, biLSTM"], "all_classes": null, "length": 4217}
{"pred": "The NMT approach-1:unsafe-unclear or \"unclear\" or \"no-#1 (NMT or #1 or \"unmounted-1 and \"unanswerline-un-1 or-un-to or-un or NMT-33: IN-check at-un-R-Ru and T-IN1 and or T2 and or \"sy-0-un- and or the-1 and3 in-of-in4: or \" un-IN- and un-TAB-3 or IN0: \" and 1-3, un", "answers": ["pivot-based translation relying on a helping language BIBREF10, nduction of phrase tables from monolingual data BIBREF14 , attentional RNN-based model (RNMT) BIBREF2, Transformer model BIBREF18, bi-directional model BIBREF11, multi-to-multi (M2M) model BIBREF8, back-translation BIBREF17", "M2M Transformer"], "all_classes": null, "length": 4542}
{"pred": "Number of differentally-centered-categorized-SCC-US-r:ref-t-based-of-layer: L-Undetic-categorised (SCB-US-of-graph-scores-US-t-US-un-SC-un-the-L-from-US-expercted: L-2-question:\n\nArt:et-SCB-networked-ref--BIBREF-B-compar-un-US-2-SC-r-4-k-ref-network-multi-layer-t-el", "answers": ["Number of Strongly Connected Components (SCC), Size of the Largest Strongly Connected Component (LSCC), Number of Weakly Connected Components (WCC), Size of the Largest Weakly Connected Component (LWCC), Diameter of the Largest Weakly Connected Component (DWCC), Average Clustering Coefficient (CC), Main K-core Number (KC), Density (d)"], "all_classes": null, "length": 4906}
{"pred": "Lookup-decized Medications (on the Medication withheld or frequency-1 or or-with-transcription task is un-Medications-idual extraction or-decend-bas- baseline, was \"Med-average percentage of the Med, baseline-425 oraction-cor-d-extraction-task-frequency-frequency-correlation-frequency-task-Medication-dos-seg-Medication-un-task-frequency extraction is un- Meditation evaluation-d-transcript-Medication-dos-frequency-d-m-trans-", "answers": ["QA PGNet, Multi-decoder QA PGNet with lookup table embedding", "QA PGNet and Multi-decoder QA PGNet"], "all_classes": null, "length": 4600}
{"pred": "Rel-ranking-based-sp or-to-to-to-unanswer-based question: The article. (art-based K KB is concise, even-f-ranking-to system.", "answers": ["answer questions by obtaining information from KB tuples ", "hierarchical matching between questions and relations with residual learning"], "all_classes": null, "length": 4527}
{"pred": "Gradification-base (universe-learning-based-no or the approach ofmentionedoff-t-t-RL-refing or off-learning algorithm approach (super-t-extrinsic-super-formula-Equot- RIBREF (form-formive-form-no .... BIBREF3-form-learning-form-un-formal(form-BIBREF-K-V-base-form-ment-form) is the single-learning for data-BREF6) is-mentir-Equi-BIB- learning- BIB-man", "answers": ["BIBREF7", " reward learning algorithm BIBREF7"], "all_classes": null, "length": 4841}
{"pred": "They-s for the article's data fine-mean questions (or 'B' is-yes-the- for ' SQA13-answer is 'yes-tunanswer score, was used, unanswer- 'unanswer- un-s-the question was- unanswer-data-' (B-un-the score is-the article.", "answers": ["BioASQ  dataset", "A dataset provided by BioASQ consisting of questions, gold standard documents, snippets, concepts  and ideal and ideal answers."], "all_classes": null, "length": 6810}
{"pred": "Semi-related-cutting-formally \"un-un\" or \"Pyram utilised scores from the proposed Sumers: Yes acchi-dis.\n\n\nPy-el-human scores that is: Pyramod-K-re-re-prov-n-n un, and \"Tac 20-Re-ling-re-formed-re-form012-n-un- Sum-\nand- and review, in the question-cut-n and conc-inform-re-form-re-re-evaluation-n-un-", "answers": [" higher tiers of the pyramid", "following the pyramid framework, we design an annotation scheme"], "all_classes": null, "length": 4771}
{"pred": "The article's one (universe or un-one: unanswer-yes-s or un-question (S BIB-one-import: \"Word\" or \"Input Word Important: un-Art: Import: C: Explanted-BIB-DMT Nig-one-un-one: un-Art-NMT: Import-un-B-Import: Import.", "answers": ["Given the contribution matrix, we can obtain the word importance of each input word to the entire output sentence. ", "They compute the gradient of the output at each time step with respect to the input words to decide the importance."], "all_classes": null, "length": 4253}
{"pred": "The-un-test-yes is \"yes\" from the sentence, unanswer-unanswer or \"un-art-un-the-un-sarcasm-analysis- un-art- work-s-f-the-of-sarciv-the-un-unanswer-the-the-work- un- the state-s-s- un- the-the- the method- the-the models-im-the approaches-unsuper-art-the-the-the-un- article-the method and bas-un-the-the-em-the-im", "answers": ["BIBREF9 , BIBREF8 ", "BIBREF9 , BIBREF8"], "all_classes": null, "length": 4855}
{"pred": "Improised or \"befs (or or or \"Learised-t or VDU6 or in the article or in the single algorithm approach, BIBREF2 (unified or: unanswer5 or concise or in the question is better in S-based on different concise or the binary-t or \" is the improvement of the performance\". \"unward or-based\" in the DH- The article is unanswer or the low-man extrat.\n unbined-M is un-the unanswer is un DIC: the LM-like-form-to \"un", "answers": ["Low data: SST-5, TREC, IMDB around 1-2 accuracy points better than baseline\nImbalanced labels: the improvement over the base model increases as the data gets more imbalanced, ranging from around 6 accuracy points on 100:1000 to over 20 accuracy points on 20:1000"], "all_classes": null, "length": 4880}
{"pred": "Multes (unartu-s:BIBREF23, for-Multiple-hops, orchestred-tims: BIBERT- thesitu, out-day, or concod or-Given-s-Multiple-Multiple-Multiple- QA, for the article-state-state or: or-pro- or science-to-s: science datasets prob-d: ors- conc-Answer-Given-un-Multiple-R-d-Given-Multiple-re-G-G: that is un-N-d:BIB:", "answers": ["MULTIPLE CHOICE QUESTION ANSWERING", "multiple-choice"], "all_classes": null, "length": 6396}
{"pred": "Wise-sted (or or the proposed-d or thearticle-concision, the Waseem and BIBREF1-based or hate-based-d-used-2- or, BBT-REF (un-or- (ne- or the proposed- or the proposed- the pre-un-d or an-or- the-d- the hate-t-the-proposed- the-t- the pre-t-the-t (dataset-un-the-pre-d-d-w-d-t- or the-pro-h-the-w", "answers": ["Waseem-dataset, Davidson-dataset,", "Waseem and Hovey BIBREF5, Davidson et al. BIBREF9"], "all_classes": null, "length": 4090}
{"pred": "Translised C or \"yes\" (unanswer-to-s, Moods with the results: un-ant-box\" are\" \"Transformer is employed-s\" in \"NMT NMT, importance un-s, Ier-s MTT\". \"un-important words\".", "answers": [" Transformer BIBREF1 model and the conventional RNN-Search model BIBREF0", "Transformer, RNN-Search model"], "all_classes": null, "length": 4240}
{"pred": "\"keyines INLINEFORM0 or \" and INLINEFORM4 and INLINEFORM0 forkeyline (subsequive).", "answers": ["average unique predictions, illustrate the difference of predictions between our proposed models, we show an example chosen from the KP20k validation set"], "all_classes": null, "length": 4576}
{"pred": "Evalised concept-2-consed-based orchestrated correlation-corse BIB15 (IN-con BIBREF0,6, in the proposed: \"un-\".\n\n[\" SEAN-proper-conl-sed-sumpatri- IND-se-con-no-un BIBREF \" in-cor D. IN-Ref-con-based annotation-cor, P, correlation- B. DREF1- BIB-class:  BIBREF-pil-based-per-con-import-pro- Eval-proposition- and-", "answers": ["Answer with content missing: (Evaluation Metrics section) Precision, Recall, F1-scores, Strict match, METEOR, ROUGE-2"], "all_classes": null, "length": 4263}
{"pred": "They are-wise lst-1-wise-layers-wise, un-stm-no-unanswer-wise lstered-based-un-red-C-forward: \"un-st-rest is un-wise l-st-d they-st and hard-wise-stochip-wise network-based-st-1-st-1-st-layers-wise-st-per-lay-wise-l-l-wise-st-layers-existing-st-layers-wise-l-st-is app-st-st models are-st-layers", "answers": ["Unidirectional LSTM networks with 2, 6, 7, 8, and  9 layers."], "all_classes": null, "length": 4286}
{"pred": "Both are un-unised. orover-w (unanswerable or unanswer-un-un-art-art un-ES-un-task un-yes-t-un-unanswer sets-limit-w) are-like un-XNLI- when-art, un-un-recons-art brought-entu-un-N1 WBIBREF6, or translated-art-art art-based-un-un-  or-un-un-test- N-Test-test-test-art-test- sets are check-XLI-art", "answers": ["Yes"], "all_classes": null, "length": 4073}
{"pred": "Knowset INDB- InTO-AR is a question-un-o-enot-to-o-im-or-d is un-inline-int-read-IN-t-AR is-NO-4 a part Mnetover-f-iD-un-question-AR, when-att-AR and BIBREF2-no-un-f-un-the-AR-un-un-answer-o-IN-inline-bo-un-AR when In-no-backed-no-un-o- Is-un-AR-un-un", "answers": ["Lexicon Embedding Layer, Context Embedding Layer, Coarse Memory Layer, Refined Memory Layer, Answer Span Prediction Layer"], "all_classes": null, "length": 4133}
{"pred": "Improving models for unclose orchestral-based model'sale (unanswer or- RL. (un realised- \"Sensational\" in) B-RL-unanswer- (un-sens: generating headline-).", "answers": ["ethical questions about generating sensational headlines, which can be further explored,  improving the sensationalism scorer, investigating the applications of dynamic balancing methods between RL and MLE"], "all_classes": null, "length": 4104}
{"pred": "The question utilizes character-form, determined to the Big RE: \"unanswer tolaces or \"yes, unanswer correct to \"yes\" or! \"artic\" is human-unanswer is, BIBIBSLAW, the article un, un- BIBREFINE.", "answers": ["attributes are determined by human viewers and their impressions of the characters, and are correlated with human-like characteristics"], "all_classes": null, "length": 5136}
{"pred": "Reuters-article-based-of the average orchestred as a-word-art or concen-or-art-art, \" as: Reuters-d on MNBIBREF,yes that the bag-of or the similar or MVB-f or BO-of-art-yes-on-art-art-class-of-no-art-art-features-of-of-art-the-art-art-art-sub-text-sub-art-class-article-the-un-art-of-art-un-art-art-", "answers": ["Reuters-8 dataset without stop words", "The Reuters-8 dataset (with stop words removed)"], "all_classes": null, "length": 5147}
{"pred": "Acc organisation is concise or unanswer: \"yes\".", "answers": ["significant improvements clearly demonstrate that our approach is effective at improving model performance", "By evaluating the performance of the approach using accuracy and AUC"], "all_classes": null, "length": 4489}
{"pred": "The exam of-unbiases or biased or Basefase (BIBREF0,unsy (author's- misions 2, errors) or-uns-tiboi) or mis-t-layers-t-t-bibleswerod-L-shows-t-l-un-t-L-t-L-BIBREF-bi-t-t- the pre-t-L-B-L-t-errors- errors-t-transform-t-L-L-t-L-t-L-L-t-", "answers": ["The authors showed few tweets where neither and implicit hatred content exist but the model was able to discriminate"], "all_classes": null, "length": 4119}
{"pred": "SimpleQ16, \"Bib. (un-to-to-1-top-top-yes\" or-top-to-the-to-top\". In-top-2-of-top-2) or-top---Q, they-2 SimpleQuested, the answer, they-2-un-top the proposed-2-top-201, the system-of-2-the proposed-im-2-the-un-answer: BIB-2-2-test-2- or 7- and-30-the proposed-2", "answers": ["SimpleQuestions, WebQSP", "WebQSP, SimpleQuestions"], "all_classes": null, "length": 4524}
{"pred": "Grammatic-style transfer kind-wise (or-formal (un-to-c2 INTLABS INLINE: they answer-unanswer, unanswer: \" Spelling (un-refera- unanswer, un-un-un-un-culture-c-c INLES-un, \"un and \"un-c is unclear, andes. or formal and lex-effect.", "answers": ["grammatical, spelling and word order errors", "spelling, word order and grammatical errors"], "all_classes": null, "length": 4579}
{"pred": "Crawlinered with the author's or non-intery (yes) Yes, orphan-state or reinforcement: \"non-ironic-art authors or pre-training or \"yes\" conceling from irony or not\" is not-article: The article-non-author or non-discrentic or pre-re-art or pre-re-corpus (t-infiled or author-form-intched with- orlin-ned with the authors or in the introduction-article or BIBREF0 or or-pre-inlinem-irony-filter-", "answers": ["They developed a classifier to find ironic sentences in twitter data", "by crawling"], "all_classes": null, "length": 4599}
{"pred": "Global-style-article-based-b-article utilize-randomised-of-D, the method-the-aattending-19 oracle-in-the-label-label-20-no-abstract-extracting-extractive-label-class-sum-big-method-the-unanswer-no-label-label-answer-or,the-local-a-of-I-att-art-sum-Is-label-class- Is-unanswer-st-sentences-extract-un-ground-label-global-extract-In-extract", "answers": ["global (the whole document), local context (e.g., the section/topic)", "global (the whole document) and the local context (e.g., the section/topic) "], "all_classes": null, "length": 4287}
{"pred": "Know-shas-t-to-top-1-to-1, the question-based KB-BIBQA,od-answer-of, the paper does-1-top \"yes, the system-un-1-top-the-the-un-2, yes-un-to-the-to-of-to-the-state-of relation-to-implies-the-y-the KB-im-2, the-the-t-to-is-the-the-the KB-the-the relation-un-to-the", "answers": ["Knowledge Base Question Answering", "Knowledge Base Question Answering "], "all_classes": null, "length": 4521}
{"pred": "They used \"Topic-c for the sparsey-start-based-article-log-based on YouTube, paper, conc. (articles) is DBLISWC and-based LDA and, yes.", "answers": ["the LDA approaches to recommendation systems and given the importance of research, we have studied recent impressive articles on this subject and presented a taxonomy of recommendation systems based on LDA of the recent research, we evaluated ISWC and WWW conferences articles from DBLP website and used the Gibbs sampling algorithm as an evaluation parameter", "discover the trends of the topics and find relationship between LDA topics and paper features and generate trust tags,  learn a LDA model with 100 topics; $\\alpha =0.01$, $\\beta = 0.01$ and using Gibbs sampling as a parameter estimation"], "all_classes": null, "length": 4322}
{"pred": "Yeses-state-to-2-Isomised, or-state. (unanswer-answer yes-to-inline-4 Isop-NO-state-to-answer-un-to-un-Isoline-h-state-they-state-state-state-of- Is-in--un-state-word-state-state-en-state-the-MFL-un-un-M-of-state-based MRC-with-0-state-of-from-state-state-mutal-andthe-state- IsLINE-p", "answers": ["Yes", "Yes"], "all_classes": null, "length": 4127}
{"pred": "Imbledits- orchestrated on un-answer: 45:yes 3.0.yes, or speech- 8, unanswer-error on- 4-corps-speads.t-un-  spe spe-type. 3. To, yes. (preity BIBREF.\n\nS ER. It is a, yes is 0, low-harm is smaller is. = 3.  un. un, un.  (pre-  female on un. W.", "answers": ["Women represent 33.16% of the speakers"], "all_classes": null, "length": 4055}
{"pred": "BasAS (BERT's-yes yes or Yes or QAID questions (Related the question) is for the baseline) system, the baseline system was used for \"yes\" for the test, yes was 'yes or 'I-unanswer-answer for '(un, unanswer was 'yes, the baseline-no any, the answer is '3' for UNanswer span or system for the system for the system in the question, un-distance of the question, the system was used for the system, or-no, ' yes-type, rules and system was the paper- the system B", "answers": ["by answering always YES (in batch 2 and 3) "], "all_classes": null, "length": 6817}
{"pred": "4th concised from the Factoid questions for or the Factoid and its paper system for the question for the system that had a 'A: \"unanswer from the concilld. Yes/no, was the F-nothing's in and, unanswer-type for the question-context anno in the system was fine-t-1, the B, \" F1, concise the question, the system was 5 was '3 the question-L3 (BIB on the top-focus the question-type for the article (no-type the article-type the question", "answers": ["0.7033", "0.7033"], "all_classes": null, "length": 6810}
{"pred": "BLE rate (un-unconversion or that the question-to-correcting or product-un-product-un-errors or-or- or product-un-un or event-im or in-y) or un-un-un-error or product or product, or product or- event-LE. In the article.\n\nIn-t-or or or-event evaluation steps-rep-bib-", "answers": ["BLEU , NIST , METEOR , ROUGE-L, CIDEr , evaluation script, automatic evaluation, human evaluation, minimum edit evaluation, word error rate (WER), factual errors and their types, fluency issues, acceptability of the output for production use in a news agency", "BLEU, NIST, METEOR, ROUGE-L, CIDEr"], "all_classes": null, "length": 4738}
{"pred": "Multon: Yes, \"class-no- INFLICMajor-words are out-classifications based-word-classified-classifiers in the context ofoverall the social media- Fords inferred in the resulting word: \"Ind-class (un-the SOCIAL-word class: \").\n\n\nunanswered by-word-words- Fords in the (IN-\n\nForgs-classified by: un-indust-word: ICON-e.\nund- the article:\n\n\nun-word- In the article-words: class- in", "answers": ["AllWords model by counting the frequencies of all the remaining words and training a multinomial Naive Bayes classifier"], "all_classes": null, "length": 4177}
{"pred": "Two MLP for \"yes\" yes\" is a question, or event: \"yes, \"Human-AI\" (un-AI-AI for event: BIBREF1, BIBREF16, BIBREF1, for the loop-AI-AI, BIBREF1, LR-post-e, and BIBREF1-AI-AI-based: BIB-loop-B-AI-AI-AI-AI: Two-AI: BIB, BIB1 (AI, BIB-loop.", "answers": ["Tweets related to CyberAttack and tweets related to PoliticianDeath", "cyber security (CyberAttack), death of politicians (PoliticianDeath)"], "all_classes": null, "length": 4481}
{"pred": "Logised or \"Unanswerable\".\n\n\n\n\nArticle datasets from\".\n\n\nLogistic-RQ01044 or \"B, or-RQ3 or fromBQ-RQA or from or\n\nArt inLog-Sci and experiment for the evaluation-of-R-RQE-Q:-", "answers": ["Logistic Regression, neural networks"], "all_classes": null, "length": 7257}
{"pred": "Conditionalised-to-2BIBB-CP (Second) ors: \"temporgreatt\". (Se10-model)-to-data-t-text in the given models: (yes). in the a-t-type: is \"yes\". Cond (t1- (e-model (1-t-row) or) requires\". ors-records with-row- performance (un) or Seq-related). or row-row- (score: Se-to-order-type: \"a-copy-type: or- performance (yes-", "answers": ["Conditional Copy (CC) model ", "delayed copy model (DEL),  template system (TEM), conditional copy (CC), NCP+CC (NCP)"], "all_classes": null, "length": 4746}
{"pred": "Infinity-yes-10-1-unanswer-ex: In Eq. \"yes\" or any.", "answers": ["The neural projector must be invertible.", "we constrain our neural projector with two requirements: (1) INLINEFORM0 and (2) INLINEFORM1 exists"], "all_classes": null, "length": 4323}
{"pred": "Loggedal-basedlised or, oranswer \" is yes\" or is the performance of the article. (yes-based-unw-AI-infos the loop is, concise or the approach on- concidence-BI. BIBREF2.", "answers": ["probabilistic model", "Logistic Regression, Multilayer Perceptron"], "all_classes": null, "length": 4475}
{"pred": "The size of INCOSTR0 or INLINE: INLINE10 and INLINE-an or \"Legal-LRC inference-20 or INLINEFORM1 is- The LRC models's-form0 in-answer- The proposede- The LRC-The-0 inferred- The- R- LRC is a redu-number-based-3 LRC- \"in L-w- R-2, and INLINEFORM-3 un-R-automatic LRC is the LRC-j is not-The-L-S-L-of-R", "answers": ["100 000 documents", " INLINEFORM1 cases"], "all_classes": null, "length": 4104}
{"pred": "Crowlera-art \"scripts is a multiple questions-sc BIBREF0, yes, or \" or unanswerable\" is uncommon-tur-text-based-no-ans-related-art-B- BIB-type-un. (yes- or- B-d-article-related-art dataset-based is un-s were-reference, and scripts were-un-B-A-B-un-un-un-un- and B-BIB-1-un-text-is-un-develop.", "answers": ["The data was collected using 3 components: describe a series of pilot studies that were conducted to collect commonsense inference questions, then discuss the resulting data collection of questions, texts and answers via crowdsourcing on Amazon Mechanical Turk and gives information about some necessary postprocessing steps and the dataset validation."], "all_classes": null, "length": 4536}
{"pred": "Data-machy (subset) or low-form-based-r-article-ref-form) VNIT-lo-rese-big-form-formal-form-y system, orform3-form-setting-rping-form (the-NMT, sub-BIB-m-r-no-NMT-unform5-NMT-r-system-y (B-un-un-N-NMT-is-form-NMT-un-NMT-py-NMT-NMT-data-y-y-m", "answers": ["Back Translation, Mix-Source Approach", "data augmentation"], "all_classes": null, "length": 4123}
{"pred": "Out unalongy: un, (unw2 unansweredder's performance on the BERT-unanswer (un)ed-model (A: un:difference (un in ALOHA: ALOHA: yes: un: un-performance (unanswer: unanswer un:A: un: ALOHA: ALOHA: un: un-D:A: un: un:20: language spaces un: un: BIBS: un: AlO: ALOHA: un: un: unrealization in: un: HLA: un:", "answers": ["Metric difference between Aloha and best baseline score:\nHits@1/20: +0.061 (0.3642 vs 0.3032)\nMRR: +0.0572(0.5114 vs 0.4542)\nF1: -0.0484 (0.3901 vs 0.4385)\nBLEU: +0.0474 (0.2867 vs 0.2393)"], "all_classes": null, "length": 5151}
{"pred": "Characterised class:-AthY, BIBY, or K- \"O\" is Arabic- KAKB concidingly, KxA Arabic and K-K class: Kernel K class K-A or class, K- D- In Arabic K-class, O, K \"K O \"Kh AlK Alu KA- K-K class, is K-O K K KA- K- Arabic KA-\" is K- K- is O, O-K, KA- K, K, K, K Al A-K,", "answers": ["Frequent use of direct animal name calling, using simile and metaphors, through indirect speech like sarcasm, wishing evil to others, name alteration, societal stratification, immoral behavior and sexually related uses.", "Direct name calling, Simile and metaphor, Indirect speech, Wishing Evil, Name alteration, Societal stratification, Immoral behavior, Sexually related"], "all_classes": null, "length": 4566}
{"pred": "The unanswer-to-cook-AD-ad-g6 on un-Explore, BIBREF1 un-AD: yes-no-Ex-t, G-Q-s: The existing-Coin-AD-AD-is better-AD-e-e-AD: \"state-cook-1-BIBREF3 answer-expl-im-AD, yes-AD-AD-B-Ex-AD-find-Ex-e-e-bet-impose-explor-eff-AD-AD-Ex-m-g-cook-AD-cook", "answers": ["promising results by solving almost half of the unseen games, most of the lost games are in the hardest set, where a very long sequence of actions is required for winning the game"], "all_classes": null, "length": 4964}
{"pred": "Investing the WER- 23: Yes-de- 20- NLP3 or Speaker-to- un-norm- news art- 2 or-S- 2-l-AS- 4, is-sem P- 5 Speal-  in a 1; 2-N- 1, S-the-rank-speech-4-the-AP, AS-  N- and Bing 4 speech-ad-the same or S-word-the-length, speech-the-B-the-speaker-ad13", "answers": ["create fair systems", " broadcast recordings are also a valuable source of data for the speech processing community, recent works uncovering gender bias in several natural language processing (NLP) tools"], "all_classes": null, "length": 4063}
{"pred": "They have a vicious Briw-pointed-based post-really-oriented-s is-C-high-dogmatic posts. (unanswerative or the question-standard-high-oriented-style.", "answers": ["logistic regression models", "logistic regression models based on unigram bag-of-words features (BOW), sentiment signals (SENT), the linguistic features from our earlier analyses (LING), and combinations of these features."], "all_classes": null, "length": 4208}
{"pred": "Yes or \"we (can bequest\" or \"yes ors (1\" or \"yes\" or \"yes\"\". or \"un-temporacy\" is pre-top\" or Xception\" or X, DLEs (or (s \" All the\" or \"e\" or \"can (can (e (can- and un\" or the visual or \" or the performance of \" can be- and link (can or \" $\\n\" or \"can\" and AlC- or \" and \" \" \" (un-ve \" \" \" \"un- can\" and \" or the \" question", "answers": ["No", "Unanswerable"], "all_classes": null, "length": 4181}
{"pred": "Message Graph-to-W-Citation, was tested in the author: The unanswer-unanswerites, yes or no, un-WBIBREF, \"un- document, unansweral-sent MGBREF, yes is competitive (competitive or sub-document is UN: Yes: Yes, is over, over time-multiple results are competitive document-MPs arew- AGGNN, document-yes-t-MPAD-un-MP isw-BIBREF BIBREF, un-un-w-BIBREF, or-w-MP, BIB-", "answers": ["doc2vec , CNN, DAN, Tree-LSTM, DRNN, LSTMN, C-LSTM, SPGK, WMD, S-WMD, Semantic-CNN, LSTM-GRNN, HN-ATT"], "all_classes": null, "length": 4169}
{"pred": "They under-state-un-Import words: yes? (Categories (unanswer-NMT)", "answers": ["They measured the under-translated words with low word importance score as calculated by Attribution.\nmethod", "we ask ten human annotators to manually label the under-translated input words, and at least two annotators label each input-hypothesis pair"], "all_classes": null, "length": 4246}
{"pred": "Wikipedia Talk: unanswerable-worthy model.", "answers": [" `Conversations Gone Awry' dataset, subreddit ChangeMyView", "An expanded version of the existing 'Conversations Gone Awry' dataset and the ChangeMyView dataset, a subreddit whose only annotation is whether the conversation required action by the Reddit moderators. "], "all_classes": null, "length": 4718}
{"pred": "Yes (yes or \"Yes\" orchestr?\"text-NMTPE is-label-processed-scopic orchestr corup-NMT in-stops\" or translate the monolingured-data or sub-NMT-2 the NLESEARTBIB0 or BIB- and systems used by-their or VNMT or- or-0 and-NMT-1 and ISE NMT or the systems, we-their-re-NMT the question. Yes or SMT is the T-their-the NMT for the paper- or or or", "answers": ["No"], "all_classes": null, "length": 4117}
{"pred": "Euro organisationally and-dionz and BLEG4 in-nmt use for bothal English INLIMLINEKO0 out-domain updates in MTW when the rationale in the LMT? in a yes and TBMT17 and un-during, yes OO LM and the r-no, for LM- the L in-domain and the NeLKM is used for-the in-domain0 with the article INLINEREF for the r-se and K, or O-un-domain on the question of in translation? the English BREF: L", "answers": ["Europarl corpus , WMT newstest 2014, News-Commentary-11, Wikipedia from WMT 2014, Multi-UN, EU-Bookshop, Rapid, Common-Crawl (WMT 2017)", "Europarl tests from 2006, 2007, 2008; WMT newstest 2014."], "all_classes": null, "length": 4184}
{"pred": "Yes' orbid (yes or sover (unanswer (unanswer-un-topic-based-c-t BIB-art or question). BIBREFSE, A-un-ticket-t, BIBBIBREF22 BIBREF5 and to-like-BIB-un-BIB3 or BIBovun-un,un,un-BIB0-un-un-pooling,un-BIB-BIB2BIB2BIB).BIB0-un-B inBIB2,BIB0un-un-BIB", "answers": ["No", "No"], "all_classes": null, "length": 4484}
{"pred": "A question-INLINEFORMFORM â€“ INFORM2 , \"Yes, the integration of LINLINE BIBREF0 (equ: BLAFORM2 or INLETT).", "answers": ["frequencies of the other words which occur with both of them (i.e., second order coâ€“occurrences)", "The matrix containing co-occurrences of the words which occur with the both words of every given pair of words."], "all_classes": null, "length": 4271}
