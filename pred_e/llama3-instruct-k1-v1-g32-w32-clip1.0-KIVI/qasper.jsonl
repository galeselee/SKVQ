{"pred": "Fox: (1, Fox, and the article, and the results, and the chosen 4.0, and the choice of the \"unanswerable, a set, the 10, and the performance in 24, and also, Fox, the, and 1. Fox- and 24, and 4. The choice, and the, 2, and 2, and the 1, and 4, and 2, 2, 2, and 4, and 1, and 1, and 2, and 2, and 2, and 2,", "answers": ["FoxNews, CNN, ESPN, New York Times, Time magazine, Huffington Post Weird News, The Guardian, Cartoon Network, Cooking Light, Home Cooking Adventure, Justin Bieber, Nickelodeon, Spongebob, Disney", "FoxNews, CNN, ESPN, New York Times, Time magazine, Huffington Post Weird News, The Guardian, Cartoon Network, Cooking Light, Home Cooking Adventure, Justin Bieber, Nickelodeon, Spongebob, Disney."], "all_classes": null, "length": 3411}
{"pred": "A series of posts (i.e- LASTER L.", "answers": ["the series of posts that trigger an intervention"], "all_classes": null, "length": 3732}
{"pred": "F-sarc (and other evaluation: F.", "answers": ["F-score, Kappa", "Unanswerable"], "all_classes": null, "length": 3544}
{"pred": "The question- B BIB-STRUCT R BIBST1, BIBFORM0 - L-INLINE", "answers": ["(i) models that use plain stacked LSTMs, (ii) models with different INLINEFORM0, (iii) models without INLINEFORM1, (iv) models that integrate lower contexts via peephole connections"], "all_classes": null, "length": 3224}
{"pred": "Untran", "answers": ["Yes", "Unanswerable"], "all_classes": null, "length": 2284}
{"pred": "Un privacy policies in the privacy of, crowd.", "answers": ["No"], "all_classes": null, "length": 3843}
{"pred": "The performance of cws in pretraining on a 2, c. (c) the chunk (on the) with (BIBREF, is a black training, to the 20, is not training, on the, 33, B, l, and, and c, 512, 2, 2, un, on (BIBIBREFREFREF, the, 1, on, task, quality, 2, 1, 2, 29, full, 97, 3, (B, 8, 1, 1, 2, 512,", "answers": ["Yes", "No"], "all_classes": null, "length": 2317}
{"pred": "Amazon", "answers": ["SemEval-2016 Challenge Task 5 BIBREF27 , BIBREF28", " English reviews ,  restaurant reviews from four different languages (Spanish, Turkish, Dutch, Russian)"], "all_classes": null, "length": 2720}
{"pred": "The topic-ELmo, a 7, 12.14.", "answers": ["7.36% on accuracy and 9.69% on F1 score", "it has 0.024 improvement in accuracy comparing to ELMO Only and  0.006 improvement in F1 score  comparing to ELMO Only too"], "all_classes": null, "length": 2890}
{"pred": "They are one of a 0.71. Un.", "answers": ["They use text transcription.", "both"], "all_classes": null, "length": 3198}
{"pred": "CLUSTER (the results of the 37, STRESSRE5:  of the, the S", "answers": ["CLUTO, Carrot2 Lingo", "simple clustering algorithm which uses the cosine similarity between word embeddings"], "all_classes": null, "length": 3039}
{"pred": "BERT-21: BERT-.BIB-2 BIB-10: BIB-QIB-1: BIBREF-15.2- The goal: we language- 4. Our, a, and   7, and unaff-1- 3-privacy- 21- 16-5 8 questions E- 4- 4- `un- 10 7, un answer $Yes, and to 39. 2 of 3, 64, find- 8 privacy- `Privacy- 8- 7 as 1 7 8 ", "answers": ["Bert + Unanswerable", "CNN, BERT"], "all_classes": null, "length": 3845}
{"pred": "P-Transfer for Exangu of all dat of the language, cross-lingly Nmt, the cross-ling NMT in the language, better, the cross- N, BIBA, BRL, the main and an,  multi-ling NMT, the main, the main,  MultiUN, the, BIB- of the main, 0, the-ling, the cross- BREF12, 2, the child, and its, the universal, the domain, ", "answers": ["pivoting, pivoting$_{\\rm m}$", "firstly translates a source language into the pivot language which is later translated to the target language"], "all_classes": null, "length": 3815}
{"pred": "Em", "answers": ["Friends, EmotionPush", "EmotionLines BIBREF6"], "all_classes": null, "length": 3178}
{"pred": "The project is mainly for text-scertain and large number and a, the number of which has a, in the main as for training applications, in background in the background as, the main protocol is (no.", "answers": ["three experimental setups with different numbers of speakers in the evaluation set, three experimental setups with different number of speaker in the evaluation set are defined,  first one, respondents with at least 17 recording sessions are included to the evaluation set, respondents with 16 sessions to the development and the rest of respondents to the background set, second setup, respondents with at least 8 sessions are included to the evaluation set, respondents with 6 or 7 sessions to the development and the rest of respondents to the background set"], "all_classes": null, "length": 3880}
{"pred": "G effective CWSN and our big recent one to the larger position of one to the of the model of the local to capture the local and the self to the orders of the local to the local.", "answers": ["pays attentions to adjacent characters and casts a localness relationship between the characters as a fixed Gaussian weight assuming the weight relies on the distance between characters", "Gaussian-masked directional attention can be described as a function to map queries and key-value pairs to the representation of input, Gaussian-masked directional attention expects to pay attention to the adjacent characters of each positions and cast the localness relationship between characters as a fix Gaussian weight for attention, Gaussian weight only relys on the distance between characters"], "all_classes": null, "length": 3612}
{"pred": "The initial language can our approach to a good for the additional to a pre- RAMEN (un-). The results are  alignment of 1.2.", "answers": ["No data. Pretrained model is used."], "all_classes": null, "length": 3409}
{"pred": "Attention model that training attention to the global attention to attention to be to the attention in the attention in it, no, \"unk\" is a follow: The attention loss for the attention model models, and attention to a, and in, attention and attention-Forget that the attention, attention is attention-assistant: unassistant: figure.", "answers": ["For certain POS tags, e.g. VERB, PRON.", "most word alignments only involve one or a few words, attention can be distributed more freely"], "all_classes": null, "length": 3366}
{"pred": "Reccle model  (EGL) to be the R) is an RNN with a Re (E) (E) and it is called an active method with: R- a  (RNN- RNN with a R\"", "answers": ["RNN", " Recurrent Neural Network (RNN)"], "all_classes": null, "length": 1644}
{"pred": "unanswerable answer. \"yes\" and \"unably\"", "answers": ["CNN modelBIBREF0, Stanford CRF modelBIBREF21", "Bam et al. SVM, Ma and Hovy w/glove, Lample et al. w/fastText, Lample et al. w/word2vec"], "all_classes": null, "length": 2836}
{"pred": "Un-1- What is the issue in the view of the two- $p_{- $^{&}$ the, use 1-  and use BIB _ model can generate and-s the model for and the pre- the previous model in the model, and full model, the BIB _{ $a $ (BIB,  *- BIB- 1 $  BIB-  (Q- ) y $  $- $ a $- the $a $& BIB $  BIB: ( 1 $  ( one $...  $ e $ ( ) ( Q $-", "answers": ["Unanswerable"], "all_classes": null, "length": 3885}
{"pred": "Around 500 systems have been a more high, un-1, uninspire, 500 inline, 480 INLINEFORM0. Un- we report the values 4 unanswerly inline. and our-1, and 13. 500 500 50.", "answers": ["about 500", "Unanswerable"], "all_classes": null, "length": 3831}
{"pred": "The article: \"The answer: The article is a linear [in which, the article: H) - an, including, and, and, experienced, a linear, answer: `linear, an: an, including, e, and:  (C: 0 training, the following, and inter, and then to: the 3, and, and, individual (B) and a  and, 3: systems, 17, and   and 6, and  a, and 2: and 0: 3, and  and  and:  a 0, and ", "answers": ["linear SVM, bidirectional Long Short-Term-Memory (BiLSTM), Convolutional Neural Network (CNN)", "linear SVM, bidirectional Long Short-Term-Memory (BiLSTM), Convolutional Neural Network (CNN)", "linear SVM trained on word unigrams,  bidirectional Long Short-Term-Memory (BiLSTM),  Convolutional Neural Network (CNN) "], "all_classes": null, "length": 2250}
{"pred": "BiLai (Ne/LIT= our model NER to our models=Bi, Bi-GraphREF7, they have leit (BIBREF7,  BiL, Bi- (L, (B, character) and others, BiL, and 5, and  and 7, 727, 1. 5-7,  1, 1 30  Bi- 5, 1  7,  word, Le- 1          BIB {un  5   and  50, 4 ", "answers": ["BiLSTM, BiLSTM-CNN, BiLSTM-CRF, BiLSTM-CNN-CRF", "BiLSTMBIBREF14, BiLSTM+CNNBIBREF20, BiLSTM+CRFBIBREF1, BiLSTM+CNN+CRFBIBREF2, CNN modelBIBREF0 and Stanford CRF modelBIBREF21"], "all_classes": null, "length": 2838}
{"pred": "Unspeech (in/continuous) on the information in the article, and the bag of one-s, i, the word BREFREF16, the number of U2-possible, and the following, the question, the default, the UREF REFREF15, the, and the, in, the, in, U, the number of, the, and, BREF, BIBREF, the, BIB/, the, i, and, on, the, and, the, the, B, the, and, U, as, the, the, U, and, and the, and,", "answers": ["Zero Resource Toolkit (ZRTools) BIBREF7"], "all_classes": null, "length": 3381}
{"pred": "BERT.", "answers": ["BERTbase", "BERTbase"], "all_classes": null, "length": 3852}
{"pred": "Five models that:", "answers": ["Answer with content missing: (LVL1, LVL2, LVL3) \n- Stanford CoreNLP\n- Optical Character Recognition (OCR) system, ParsCIT \n- further abridge the input text from level 2 preprocessed documents to the following: title, headers, abstract, introduction, related work, background and conclusion."], "all_classes": null, "length": 1822}
{"pred": "No, 27, and the main model NMT, un translation in translation, no, and  an un,  yes, and it can un- no- and the encoder, un pre- training, and  unanswer, and  un- \n\nno, un, un, un, un, and  Alie,", "answers": ["Yes", "Yes"], "all_classes": null, "length": 2077}
{"pred": "MIM", "answers": ["MIMIC-III", "MIMIC-III"], "all_classes": null, "length": 2992}
{"pred": "Un:", "answers": ["Level A: 14100 Tweets\nLevel B: 4640 Tweets\nLevel C: 4089 Tweets"], "all_classes": null, "length": 2255}
{"pred": "Attention of N", "answers": ["it captures other information rather than only the translational equivalent in the case of verbs", "Alignment points of the POS tags."], "all_classes": null, "length": 3372}
{"pred": "The main token in the pre-trary- layer, weights are BSN as [{\\IB in Text Emotion Fos, the specific F1, bas include, and including, and the, baseline, and the, and the, and original utterance, the, and the baseline, and weights, and the model, the BIB REF Brem, as, B. (Display, and, the, and, and, and, and, unprocessed, and, and, and, and the, and, and, and, and, and original, and, and, and, and the, and, and", "answers": ["BOW-LR, BOW-RF. TFIDF-RF, TextCNN, C-TextCNN", "bag-of-words (BOW), term frequency–inverse document frequency (TFIDF), neural-based word embedding, Logistic Regression (LR), Random Forest (RF), TextCNN BIBREF10 with initial word embedding as GloVe"], "all_classes": null, "length": 3181}
{"pred": "The authors of the article:", "answers": ["Unanswerable", "48,705"], "all_classes": null, "length": 3307}
{"pred": "The-to-concluding, no, to at- and many,  over, and, 11, is an end-to, has, 1, 18, and the following have, have, the same, to 11, and, BIB12, 18,  1-to 3 to, for 20, 2, the Co,  BREF6, and 20, 20, 2, and 2, and 60, 27, 1, 5, Co, 2, 3, 1, 5, \"no, 5, a", "answers": ["follow the architecture in berard2018end, but have 3 decoder layers like that in pino2019harnessing"], "all_classes": null, "length": 2424}
{"pred": "The previous-heat and notation of 15-  BIBREF0 (Table BIBREF0 and 1. They use 500 and 6-66, and 1, PT-1.", "answers": [" Penn Treebank, WikiText2", "Penn Treebank (PTB) , WikiText2 (WT-2)"], "all_classes": null, "length": 3302}
{"pred": "Unanswer no: yes, and a yes, especially (b) the system is un- \n\n-F:", "answers": ["No", "No"], "all_classes": null, "length": 3158}
{"pred": "The vocabulary of the large family vocabulary used to a student and student language models in a teacher model uses an un effective in the teacher model, and training and not to the student vocabulary, do not the student model, and try to the student model, and to BIBREF8, these models' models, that they different to a student, a future, language, to a smaller BERT, the language, variety of, further, to not, directly on, are, un, the, un, and, the teacher, the, a, to, BREF, and, a un-, and in, the, the", "answers": ["While there has been existing work on reducing NLP model vocabulary sizes BIBREF15, distillation techniques cannot utilize these, since they require the student and teacher models to share the same vocabulary and output space. This profoundly limits their potential to further reduce model sizes.", "distillation techniques cannot utilize these, since they require the student and teacher models to share the same vocabulary and output space. This profoundly limits their potential to further reduce model sizes."], "all_classes": null, "length": 3570}
{"pred": "The article is the effects of \"x\" no, and \"k\" for the no,, the \"general, no,  S and they are \"un no\" no,  and  are, in the word\" (the corpus\" no, and, the details\" un\"  a, the effects.  the, 3, and 5, 3\" and, the sentiment,  BIB, 200, and the, the  more, and  the sentiment, 3 BREF B B B\", the, the,   3,  B,  the, 5", "answers": ["using word2vec to create features that are used as input to the SVM", "use the word2vec algorithm, create several unsupervised hand-crafted features, generate document vectors and feed them as input into the support vector machines (SVM) approach"], "all_classes": null, "length": 3820}
{"pred": "The article is not: The abbreviation \"un\", A large text: Our concidentally, the article is BIBRE- BIBF1. BIB BIB1-1-1, and the traditional, the large text in B BIBREF in the 4-2- Z-M-05, 4-1, 2, 0, and B, 2, 1, 0, 94,  modern Chinese, 2-5, 0, 4, 2, 4, 4, 4, 4, 2, 4, ", "answers": ["ancient Chinese history records in several dynasties (about 1000BC-200BC) and articles written by celebrities of that era", "Ancient Chinese history records in several dynasties and articles written by celebrities during 1000BC-200BC collected from the internet "], "all_classes": null, "length": 3722}
{"pred": "Un yes/no, and the prime factors for the factors behind its experts that a `question, the of the QQ, an, and that of the open, B, \"un\".", "answers": ["No"], "all_classes": null, "length": 1561}
{"pred": "\" yes\n\n Article: scientific, and 5, un, BIB,", "answers": ["words embeddings, style, and morality features", "words embeddings, style, and morality features"], "all_classes": null, "length": 2091}
{"pred": "The article of the article: We also, we use the same- and, we also use United BIBREF36, and all, our, and all, X in 25, 2, and, fine, and, and, fine, we, the, are, and 11, and, and 25, and, and, and, and, and, and 24, and, and, and, and,  BIB, 0, a,  and, no, and, and,  and,  BIB, and, and, 5, and, 1, and,", "answers": ["United Nations Parallel Corpus, IIT Bombay corpus, OpenSubtitles 2018"], "all_classes": null, "length": 3405}
{"pred": "unanswer: no answer. \n\nBREFREF BREF: unanswer the models used.", "answers": ["Unanswerable", "English"], "all_classes": null, "length": 2009}
{"pred": "No, no, question: 1 unanswer for the L2, L1, and, 1, no, no, no question: no, no, and no, question, unanswer: B, and, can, yes,  yes, C, yes, and, no, answer, no, L1, and,", "answers": ["No", "No"], "all_classes": null, "length": 1899}
{"pred": "The C- The sentence-level classifier dataset is BREF7: 45-1, B-1: unlad is used to 208.", "answers": ["45,000 scholarly articles, including over 33,000 with full text"], "all_classes": null, "length": 2150}
{"pred": "Traditional feature-by-2, the baseline Eun: 11, and 0.12, and 0- 14.", "answers": ["support vector machine classifier (SVM), logistic regression classifier (LR), Naive Bayes classifier (NB), random forest (RF), CNN, LSTM , LSTM-soft, LSTM-self", "support vector machine classifier (SVM), logistic regression classifier (LR), Naive Bayes classifier (NB), random forest (RF), CNN, LSTM , LSTM-soft, LSTM-self"], "all_classes": null, "length": 2895}
{"pred": "Unarasten of BIBREF0 \"unanswer: \n\n\"unusually, BIBREF0 feature and BIBARREF0:", "answers": ["1913 signals", "Unanswerable"], "all_classes": null, "length": 2361}
{"pred": "Macawaw Macaw B answer: unanswerplicable B BIB.", "answers": ["Co-Reference Resolution, Query Generation, Retrieval Model, Result Generation", "Co-Reference Resolution, Query Generation, Retrieval Model, Result Generation"], "all_classes": null, "length": 1701}
{"pred": "unanswer: unanswer: unanswer:", "answers": ["Unanswerable"], "all_classes": null, "length": 1913}
{"pred": "unfinesse-based (Table for state, the remaining speaker errors for the future yes and as in the i-state for unend-in the 1-sr for the large Persian, and Red for the size, the system large in one and all 3, the G.", "answers": ["Unanswerable", "Unanswerable"], "all_classes": null, "length": 3794}
{"pred": "The article based-included5 from the proposed the one as question (related in the answer to the un-pivot, and the SQu-preservation: our un the SQuQ \"our model on all information. our BREF2. The results, B un, and is the case, the information generation rec.", "answers": ["SQuAD", "SQuAD"], "all_classes": null, "length": 3757}
{"pred": "The results on the, and \"un C\" B-CER-14- and 2015, and \"zyes training, Table BREF12,", "answers": ["relation classification dataset of the SemEval 2010 task 8", "SemEval 2010 task 8 BIBREF8"], "all_classes": null, "length": 2393}
{"pred": "The ELM: \"lemist' of ELMo to be ELL: ELMIST: 'not to'... of...' for NLP: 'L ELM' of training, of the `except' of'...'. of' language' is W: it is of' le B' post post except for sentence' this is of inf...' in N of' of N......... in the current to... in the W... as...'.... to post...... of N: ELM: to... of N:'. This is of ELM:... of the... of ELM of", "answers": ["2174000000, 989000000", "2174 million tokens for English and 989 million tokens for Russian"], "all_classes": null, "length": 2958}
{"pred": "The article has included in the Article, and provides the \" multiple of the as \"qualitive\" and and the correlation between the BIBREF2: formally, the expected and the YP BIB", "answers": ["Spearman correlation values of GM_KL model evaluated on the benchmark word similarity datasets.\nEvaluation results of GM_KL model on the entailment datasets such as entailment pairs dataset created from WordNet, crowdsourced dataset of 79 semantic relations labelled as entailed or not and annotated distributionally similar nouns dataset.", "Given a query word and component id, the set of nearest neighbours along with their respective component ids are listed"], "all_classes": null, "length": 2220}
{"pred": "The F1 is a concen and d-t the S as 1.", "answers": ["Using DSC loss improves the F1 score by +0.58 for MRPC and +0.73 for QQP", "+0.58"], "all_classes": null, "length": 3566}
{"pred": "unabref methods B unlearnably, EGL (yes, the article: B.", "answers": ["reducing the variance of an estimator,  EGL method in BIBREF3 is almost the same as Eq. ( EQREF8 ), except the gradient's norm is not squared in BIBREF3", " Fisher Information Ratio"], "all_classes": null, "length": 1671}
{"pred": "The article is:", "answers": ["LSTM", "LSTM"], "all_classes": null, "length": 2289}
{"pred": "Natural word description of the human present, a set of questions News CQA B", "answers": ["These 8 tasks require different competencies and a different level of understanding of the document to be well answered"], "all_classes": null, "length": 3817}
{"pred": "Yes, privacy-based, baseline: S, unanswerable, and yes, and 2, BIB-B-2-1, and 2, 3, and 1- 2, BIB, 2,  best, 4, 3, 3. f 3, and 2-  assist, 1.  P. 14, P, 3, and 4,  4, 4, 2, 4. 3 4, and 4, 3 3 4, 3 4, 3  8", "answers": ["SVM, No-Answer Baseline (NA) , Word Count Baseline, Human Performance", "No-Answer Baseline (NA), Word Count Baseline, Human Performance"], "all_classes": null, "length": 3855}
{"pred": "53. The corpus is character, our B/s: and \"Q.", "answers": ["53 documents", "53 documents"], "all_classes": null, "length": 2667}
{"pred": "Food users can.", "answers": ["from Food.com"], "all_classes": null, "length": 2649}
{"pred": "They perform a-  the models: \"unanswer: \"the models'unsupere should:... [ $ $ $ $ $ $ ...  \"  $  $...  $ $  $ $ a $  a: $  $ $ $ morph, and are a $ $  word $ $ $  $  $ $ $ $  $ $ $ $ $ $ $ $ $ $ $  $   $ $ $  $  $  $ $ $ $ $  $  $  $ $ $  future  $ $  $  future $ $ $ $  $ $ $ $", "answers": ["We also evaluate all five models on downstream tasks from the VecEval suite BIBREF13 , using only the tasks for which training and evaluation data is freely available: chunking, sentiment and question classification, and natural language identification (NLI). The default settings from the suite are used, but we run only the fixed settings, where the embeddings themselves are not tunable parameters of the models, forcing the system to use only the information already in the embeddings."], "all_classes": null, "length": 2083}
{"pred": "Unanswerable:", "answers": ["Adv. Heart Disease, Adv. Lung Disease, Alcohol Abuse, Chronic Neurologic Dystrophies, Dementia, Depression, Developmental Delay, Obesity, Psychiatric disorders and Substance Abuse"], "all_classes": null, "length": 1651}
{"pred": "Most has learner N2 corpora BIB", "answers": ["204 tokens", "Most texts, however, range roughly from 150 to 250 tokens."], "all_classes": null, "length": 1898}
{"pred": "Patterns", "answers": ["(VVD shop_VV0 II, VVD shopping_VVG II)", "patterns for generating all types of errors"], "all_classes": null, "length": 2133}
{"pred": "Unit.", "answers": ["No", "No"], "all_classes": null, "length": 3974}
{"pred": "The article REFREF21, \"RREF29,... (R:... (backgroundly DOD:", "answers": ["Random Kitchen Sink method uses a kernel function to map data vectors to a space where linear separation is possible.", "explicitly maps data vectors to a space where linear separation is possible, RKS method provides an approximate kernel function via explicit mapping"], "all_classes": null, "length": 2361}
{"pred": "BIB T \"yes:  - T T REF REFREF0. fine-Rogue-REF is, un  and future- the W 0 BIBISE REF: BElâ, the task B ", "answers": ["BIBREF11 , BIBREF26 "], "all_classes": null, "length": 1912}
{"pred": "The article's general answer performance is improved by error errors in the system by using the pattern in \"yes, and  R has also use to some work on both gives on all forms of general training experiment, and the method of the language in the approach, the language error is \"un 5a-F,.. \n\n is  and error, and, each 4, and both, and  unexplain. The results on the alternative, and the system, and, the Ann error, and error, and, and,, as, and, and, and, and, language, and, and, a, and", "answers": ["Combining  pattern based and Machine translation approaches gave the best overall F0.5 scores. It was 49.11 for FCE dataset  , 21.87 for the first annotation of  CoNLL-14, and 30.13 for the second annotation of CoNLL-14. "], "all_classes": null, "length": 2164}
{"pred": "Named, an answer:", "answers": ["None"], "all_classes": null, "length": 2473}
{"pred": "Seven: privacy-based privacy users of the experts rather 3.", "answers": ["Individuals with legal training", "Yes"], "all_classes": null, "length": 3846}
{"pred": "Maximum previous studies on B-I (unfairer no-phrase, word segmentation algorithms B IBrefref of Vietnamese, and the common N- Vietnamese language theory, such as: including, (1-  several studies, (B- un- of- B-I, so- 94, and so on- B-I-  I-  B-I, and so-  B BIB N, and so on 34-  BIB, etc.", "answers": ["Maximum Entropy, Weighted Finite State Transducer (WFST),  support vector machines (SVM), conditional random fields (CRF)", "Maximum matching, Hidden Markov model , Maximum Entropy, Conditional Random Fields , Support Vector Machines"], "all_classes": null, "length": 3471}
{"pred": "Stanford's and the pre- and [Gaffe, and [BIBb ՎեՎեկՎպ ճ art Ց ՑՃ ծե ՂՎ, 1 ՏՆ ՒՖ կ Օ Հ Վ ոո կՎ Ֆ դ Ր ճ Վ ՂՎ ՓՒ ճ ն ե Հո", "answers": ["Stanford NER, spaCy 2.0 , recurrent model with a CRF top layer", "Stanford NER, spaCy 2.0, recurrent model with a CRF top layer"], "all_classes": null, "length": 2759}
{"pred": "WN graph and $what {BIBREFREF24, 0, 1A,", "answers": ["WordNet BIBREF0, Freebase BIBREF1, WN18 (a subset of WordNet) BIBREF24 , FB15K (a subset of Freebase) BIBREF2"], "all_classes": null, "length": 3367}
{"pred": "Supporteli work on conc.", "answers": [" LastStateRNN, AvgRNN, AttentionRNN", "LastStateRNN, AvgRNN, AttentionRNN "], "all_classes": null, "length": 2823}
{"pred": "Three high past of AQA enough enough, a, personal, for Q&A of a high, and personal, cyberbullying, and cyberbully: at a Q and also, are, are 10, they attack, personal attack, and cyber, and not, and cyberbulting, BIB B B B not, the, cyber BIBFORM20 W, and, as P, and, also, a, P, P, low, and P, and, cyber, and, cyber, cyber, and, and, and, A, B B REF, and, B, B, and, P", "answers": ["personal attack, racism, and sexism", "racism, sexism, personal attack, not specifically about any single topic"], "all_classes": null, "length": 3244}
{"pred": "Yes no, both \"yes, in the no yes, no no, no L un-no, and/or no, no, but no they used Al-Cater, no, no form, clearly no, they normally, no, no, they, they, and, they, the, and no, leading, in the resources, etc. \"C, the, they, leading, the, our, no, BIB, \", compare, general, BIBREF20, Winter, etc, etc. it, no, that, BIB, BIB, to, no, etc.", "answers": ["Yes", "Yes"], "all_classes": null, "length": 3634}
{"pred": "An 9 REF 9, and BREF 9, and 9, 1, and 1-features 9, “unanswer: unlearn, and 9, and  5, and un, un= BREF, and 9, B=, and 3,9, 1 BIBREF, and 5, and 1, 0, 0, 1, 9, B, 9, B, 1, 1,  B,  2, 1, 9, 1,  B, 1, 2", "answers": ["BIBREF12 , BIBREF13", "an existing, annotated Twitter dataset that was constructed based on a hierarchical model of depression-related symptoms BIBREF12 , BIBREF13"], "all_classes": null, "length": 1939}
{"pred": "The NCG: \"yes\" for unanswerable, \"the article, Har.  the article:  un has  no \"  yes\" x the N:  - \" \"the article:: \" \"BREFREF: &#REF** REFREF8, B. are also 1. XREF BREF: B  BREF  BREF  un- \"no\" and  TIBVATREF BIBREF  BIBREF  BREF  N 1 BIBREF4 BREF 4.  the result  un  BREFREFREF  quality BIBREF ", "answers": ["Nguni languages (zul, xho, nbl, ssw), Sotho languages (nso, sot, tsn)", "The Nguni languages are similar to each other, The same is true of the Sotho languages"], "all_classes": null, "length": 1877}
{"pred": "IM", "answers": ["IMDb dataset of movie reviews", "IMDb"], "all_classes": null, "length": 2327}
{"pred": "The article:", "answers": ["accuracy and F1-score of 89.6% and 89.2%, respectively", "accuracy and F1-score of 89.6% and 89.2%, respectively"], "all_classes": null, "length": 3313}
{"pred": "K BIBREF1REF1", "answers": ["K-means, LEM BIBREF13, DPEMM BIBREF14", "K-means, LEM, DPEMM"], "all_classes": null, "length": 3841}
{"pred": "English (i.e., the current language, and the system j) is: \"yes, the current 8, the  tiny as yes and the relevant (B) as well, is also, the system that,", "answers": ["English, German, Spanish, Mandarin, Polish, Russian, Korean and Serbian", "English (Edinburgh), German (Berlin), Spanish (Madrid), Mandarin (Taipei), Polish (Warsaw), Russian (Moscow), Korean (Seoul), and Serbian (Belgrade)"], "all_classes": null, "length": 2754}
{"pred": "The similarity is \"our result of the parameters\"mon\" the cluster the un and related to the bag of the system\"", "answers": ["rupnik2016news", "rupnik2016news, Deutsche Welle's news website"], "all_classes": null, "length": 3160}
{"pred": "Unchistifying the training a big/s and un-h, what VSAR BREF", "answers": ["Yes", "Yes"], "all_classes": null, "length": 1868}
{"pred": "Infol  Tun, the other-1-tuning, BIBref: InferSent and CL BIBREF, and, and in the following study:", "answers": ["GloVe, BERT, Universal Sentence Encoder, TF-IDF, InferSent", "Avg. GloVe embeddings, Avg. fast-text embeddings, Avg. BERT embeddings, BERT CLS-vector, InferSent - GloVe and Universal Sentence Encoder."], "all_classes": null, "length": 3862}
{"pred": "The question can answer can-eu-fine-1- the 12-f the average the question is a 10, the average and a few 10, and 11- the 10, the average 49, 5-3-t the 6, and 2- 3- 2- 12, and 24, 3- 1, 3, 12, 12- 4- 5-7, and 12 5- 3- 50 24 5 2, 49, the popular, Con 7, and 49,", "answers": ["MR, CR, SUBJ, MPQA, SST, TREC, MRPC", "MR: Sentiment prediction for movie reviews snippets on a five start scale BIBREF25.\n\nCR: Sentiment prediction of customer product reviews BIBREF26.\n\nSUBJ: Subjectivity prediction of sentences from movie reviews and plot summaries BIBREF27.\n\nMPQA: Phrase level opinion polarity classification from newswire BIBREF28.\n\nSST: Stanford Sentiment Treebank with binary labels BIBREF29.\n\nTREC: Fine grained question-type classification from TREC BIBREF30.\n\nMRPC: Microsoft Research Paraphrase Corpus from parallel news sources BIBREF31.", "Semantic Textual Similarity, sentiment prediction, subjectivity prediction, phrase level opinion polarity classification, Stanford Sentiment Treebank, fine grained question-type classification."], "all_classes": null, "length": 3861}
{"pred": "un-answer: BIBREFRE BIB", "answers": ["33,663", "33,663 distinct review keywords "], "all_classes": null, "length": 3305}
{"pred": "Context additional data is not-e, one- un, and.e. 102, BIB et. et. x, user. BIB 70, and 10, 1  et 1  and  e. 6 2, BIBREF  B, 102, 10, and 2,  B. B.  e  B 102  B  B 0  and  e 102,    BIB. 102.", "answers": ["using tweets that one has replied or quoted to as contextual information", "text sequences of context tweets"], "all_classes": null, "length": 2060}
{"pred": "Yes, parallel tweet-based article can be answered if they are unanswerable as models that are supervised, \"unconcerned BREF, and BREF, and are good, no, \"yes\". \n\n**. \n\nBREF, no BREF, and, are, are, general, as, can, and so on, a, and,  are, unsupce, and ", "answers": ["No", "No"], "all_classes": null, "length": 1906}
{"pred": "Un:... 50, no/ unformFORM form   of  ", "answers": ["No", "No"], "all_classes": null, "length": 1443}
{"pred": "The question Q: BERT9:  Enl answer: Table+ BIBREF12 (r21) of r12, BREF12, the system: Enr, r9. 0, and the question, MIC. en..1.", "answers": ["For SLC task, the \"ltuorp\" team  has the best performing  model (0.6323/0.6028/0.6649 for F1/P/R  respectively) and for FLC task the \"newspeak\" team  has the best performing  model (0.2488/0.2863/0.2201 for F1/P/R respectively)."], "all_classes": null, "length": 1541}
{"pred": "The article:", "answers": ["DTA18, DTA19", "Diachronic Usage Relatedness (DURel) gold standard data set"], "all_classes": null, "length": 1908}
{"pred": "The article follows: \"TREF3 (un: Tweet- and we use it in the crowd of 17, which  (generally 2, and have) and also, have an ab... and help, 10, 13, BERT, and author, and the  of, and, and 2 of the upper,", "answers": ["13,757", "10,898 articles, 17,794 tweets, and 13,757 crowdsourced question-answer pairs"], "all_classes": null, "length": 3704}
{"pred": "K REFREF4, the models that want to buy these cars are car's buying reliable to car-s car-s- translates A and  are trained a \"re''", "answers": ["KNN\nRF\nSVM\nMLP", " K Nearest Neighbors (KNN), Random Forest (RF), Support Vector Machine (SVM), Multi-layer Perceptron (MLP)"], "all_classes": null, "length": 1639}
{"pred": "They can not convexinally BIBREF-C1: \"by concaten to eš 2014: they have: \"mely\"un-2010: untr 4...  relation Erzi 20114 2010, 2 assistant: z. 81 ER-C-Ref 2012 2-C-4 4  B 2015 8 4 80 10 2 2 84  un  81 4 4  by 8 2 2  4 4 2  5 8 84 4  4 ", "answers": ["They use two independent convolutional and max-pooling layers on (1) a combination of the left context, the left entity and the middle context; and (2) a combination of the middle context, the right entity and the right context. They concatenated the two results after pooling to get the new context representation."], "all_classes": null, "length": 2435}
{"pred": "\"", "answers": ["An output layer for each task", "Multi-tasking is addressed by neural sequence tagger based on LSTM-CRF and linguistic features, while multi-granularity is addressed by ensemble of LSTM-CRF and BERT."], "all_classes": null, "length": 1514}
{"pred": "The dataset of the CORD-19 of (COVID-19, S, S, 1, 95, yes, BIBREF \"un, which [yes, we of, B,  our, yes, un, 5, 4, 17, un, BIBREF19, bootstrapping yes, 5, 4, 4, 4, 5, 1, 5,  5, 4, yes, 4,3, 4, 5, 4, 4, 5, 10, 5, 5,", "answers": ["which contains over 45,000 scholarly articles, including over 33,000 with full text, about COVID-19, SARS-CoV-2, and related coronaviruses", "contains over 45,000 scholarly articles, including over 33,000 with full text, about COVID-19, SARS-CoV-2, and related coronaviruses"], "all_classes": null, "length": 2156}
{"pred": "The question (Q in performance text (BIBREF2) in the sentence (large, and-able) BIBIBF: 12772, 15. 5, 5: 15, and 4: 5, 5, 22, random 9, 9, 139, 139, 1: 15, 15, 5, 5, 15, 15, less, 139, 15, 15, 15, 22, 5,  and,  BIB. 22, 2, 5, ", "answers": ["26972", "26972 sentences"], "all_classes": null, "length": 3040}
{"pred": "The article,", "answers": ["Unanswerable", "Unanswerable"], "all_classes": null, "length": 2533}
{"pred": "The RIT (i.e, no) models, and no-s the conc does, $a $ character+  $21, 4 models are not+ no unique, the R: the important, when, back to the word, and un- 50, a word, as  $\\assistant, and $handle, the background generic, and the test, the word, and, in the model,  each  ( $20, and, character-level word, word, change  of char,, and the explain, BIB, specific, and the second, and the primary,  •, B, ", "answers": ["In pass-through, the recognizer passes on the possibly misspelled word, backoff to neutral word backs off to a word with similar distribution across classes and backoff to background model backs off to a more generic word recognition model trained with larger and less specialized corpus.", "Pass-through passes the possibly misspelled word as is, backoff to neutral word backs off to a word with similar distribution across classes and backoff to background model backs off to a more generic word recognition model trained with larger and less specialized corpus.", "Backoff to \"a\" when an UNK-predicted word is encountered, backoff to a more generic word recognition model when the model predicts UNK"], "all_classes": null, "length": 4210}
{"pred": "The N-MIC form-23 (uninformally, not unanswer: training N-MNL.", "answers": ["DSTC2", "The manual transcriptions of the DSTC2 training set "], "all_classes": null, "length": 4820}
{"pred": "BLEFUN-FigZ INLINEFORM0, the copy of the field INLINEFORM of the block- and  Dingo- language, 3 and  (also, the BREF6 one.", "answers": ["BLEU-4, NIST-4, ROUGE-4", "BLEU-4, NIST-4, ROUGE-4"], "all_classes": null, "length": 4460}
{"pred": "r BIB: yes, and r-journal BREF (refering the interaction.", "answers": ["SVM , CNN , GRU , CNN/GRU+law, r-net , AoA ", "SVM with lexical features in accordance with previous works BIBREF16 , BIBREF17 , BIBREF1 , BIBREF15 , BIBREF4, attention-based method BIBREF3 and other methods we deem important, some off-the-shelf RC models, including r-net BIBREF5 and AoA BIBREF6 , which are the leading models on SQuAD leaderboard"], "all_classes": null, "length": 4106}
{"pred": "The effectiveness of diacritical un-brefly (a diacriti diacun diacrit to combine to $o $s.", "answers": ["POS, gender/number and stem POS"], "all_classes": null, "length": 4719}
{"pred": "Along to a word, BIBV I BIM B to our future of the concept, the concept, the answer is encoded concitronics BIBREF.", "answers": ["dimension corresponding to the concept that the particular word belongs to"], "all_classes": null, "length": 6182}
{"pred": "English- R BIB- and G-4- and unform no, the copy-marked, which, what language- un-s.", "answers": ["English , German, French"], "all_classes": null, "length": 4173}
{"pred": "Unanswerable: Un the neural translation in an NREF3.", "answers": ["Unanswerable", "Unanswerable"], "all_classes": null, "length": 4465}
{"pred": "Disinformation vsâ. no/ 1:  Disinformation and mainstream and mainstream features of mainstream news (un K. un- (un- disinformation and mainstream, mainstream and (as, general, mainstream, mainstream and mainstream, mainstream and mainstream, and mainstream dis. dis. mainstream, 6, mainstream disinformation, mainstream,  mainstream, and 1, and mainstream, 1, and B, and dis, mainstream, disanswer \"un, 1, mainstream mainstream, mainstream, and mainstream, un-, balance, and the presence, w.r. (B,  \", mainstream, and ", "answers": ["mainstream news and disinformation", "mainstream and disinformation news"], "all_classes": null, "length": 4856}
{"pred": "Coin-ColEARG&#a (in the \"at\" BIBREF14 BIB", "answers": ["CoinCollector , CookingWorld ", "CoinCollector, CookingWorld"], "all_classes": null, "length": 4924}
{"pred": "F INLINE-F BIBFORM0 (one target tokens used, and the source, K1, and INLINEFORM0, and 50 and 50, condition, \"no, BIBBREFFORM, can, the BIBIB, BIB, Inline, and, BIB form, and, yes, and F, 50, 2, 1, 50, one, 2,, and, 50, and, 50 for One, 50, 5, B, 150, 50, 64, 64, 1, 5, 50, ", "answers": ["average unique predictions, randomly sample 2000 decoder hidden states at INLINEFORM4 steps following a delimiter ( INLINEFORM5 ) and apply an unsupervised clustering method (t-SNE BIBREF35 )"], "all_classes": null, "length": 4581}
{"pred": "The BERT based fine-tuning of the pre-trained B hate speech based on BIBREF, and future, and  e.", "answers": ["Data annotation biases where tweet containing disrespectful words are annotated as hate or offensive without any presumption about the social context of tweeters"], "all_classes": null, "length": 4111}
{"pred": "\"Our model a better to further attention by hierag, by a constraint, by a to further improve the approach that models on the two, and standard, \"Pcines,... (SEC, \"... to a,  E.... 2, B, in the, and on the constraints, the hierarchical, and to, and, and, to,... B, and,... a, a hierarchical, in the,  [ ... 1, B4, d, 25,  \\... ..., and, 1, BIB4, 23, and, to, a,", "answers": ["rther constrain the model on the data structure in order to prevent inaccurate of even contradictory descriptions", "to further constrain the model on the data structure in order to prevent inaccurate of even contradictory descriptions"], "all_classes": null, "length": 4704}
{"pred": "The proposed can be to learn to increase of a YES/NO1.", "answers": ["The cost function for any one of the words of concept word-groups is modified by the introduction of an additive term to the cost function. . Each embedding vector dimension is first associated with a concept. For a word belonging to any one of the word-groups representing these concepts, the modified cost term favors an increase for the value of this word's embedding vector dimension corresponding to the concept that the particular word belongs to,", "An additive term added to the cost function for any one of the words of concept word-groups"], "all_classes": null, "length": 6244}
{"pred": "Un and all (un as one entity and section of, for novel (un and unanswer ZINEFORM, (e and entity level, a specific of an entities B and entities, respectively (German) and, entities as \"e, and F and S and–s, BIBPREF and  and  Unsection (e, yes, specific entity and, INLINEFORMF and entity, and entity, entities B and, and we and INLINEFORM, and all, and 5 (B, and  and, 27% and 27% and 27, but 27, BIBREF2,", "answers": ["Yes", "Yes"], "all_classes": null, "length": 7837}
{"pred": "It is novel, the combination of learning the BIB.&#a separate, and the one of document, and the position  of.", "answers": ["Bert model have a maximum length of 512; we overcome this limitation by adding more position embeddings, we insert external [cls] tokens at the start of each sentence, and each [cls] symbol collects features for the sentence preceding it, document representations are learned hierarchically"], "all_classes": null, "length": 4404}
{"pred": "Their models with the novel, for a, the additional, for the model, and BIBREF@!...@!! (UID U, the, r, and may, the high, and, for, and, for, and, and the, and, the highest, and, the, the, the, for, UNK REF B!@!! B! UNk, the, the, and,  (J. and, U, and, and, the, and, and, our, and, the, and,  is. Background.", "answers": ["the attention heads in the proposed adaptively sparse Transformer can specialize more and with higher confidence", "We introduce sparse attention into the Transformer architecture"], "all_classes": null, "length": 4902}
{"pred": "Unstable:", "answers": ["Unanswerable", "Unanswerable"], "all_classes": null, "length": 5331}
{"pred": "un", "answers": ["22,880 users", "20,000"], "all_classes": null, "length": 4160}
{"pred": "Un answer that can be agreement between the un-C: no, and that the base and a sentence annotation that can be an expert annotator and", "answers": ["sentence"], "all_classes": null, "length": 4369}
{"pred": "The conversation, two conversation: the question:", "answers": ["The Conversations Gone Awry dataset is labelled as either containing a personal attack from withint (i.e. hostile behavior by one user in the conversation directed towards another) or remaining civil throughout. The Reddit Change My View dataset is labelled with whether or not a coversation eventually had a comment removed by a moderator for violation of Rule 2: \"Don't be rude or hostile to others users.\""], "all_classes": null, "length": 4779}
{"pred": "The fact-formation of the attention BETA-Jo, a yes or- judgment description with-GRU.", "answers": ["build a new one, collect INLINEFORM0 cases from China Judgments Online"], "all_classes": null, "length": 4109}
{"pred": "They \"English, yes, \"no un L model, \"they use, 22, and 3- yes 3 (i, E; no 2, we was all 3, S, and 2-1, Eston 2- P when the model 3, the \"I, and the model to-m, (not un- and 2, - 2, for all of the  various B REF REF3 1 0, 2  (e the model: the model, that the average  is I 2, and 32, (e, B) the ", "answers": ["Unanswerable"], "all_classes": null, "length": 4572}
{"pred": "The model's proposed to \"our A- the model that this learn to the RO-GAN used to BIB-AR to-AR-ARl-**16, this.", "answers": ["absolute improvement of 18.2% over the Pointer-Gen baseline"], "all_classes": null, "length": 4091}
{"pred": "A trade of 0. \"un: A group of 59 50 BLABi et al. (Anil et al. 50, the R RNN, 5, 50 native, 50, 50, 3420,  un \"R, Dr. An, etc. (cor) 1, 5. B, 41, and the neural, and 5, 1, 569, 1, R, R, 41, 50, 50, 41, 50, 5, 37, 560,  K, 41", "answers": ["50 human annotators ranked a random sample of 100 translations by Adequacy, Fluency and overall ranking on a 5-point scale.", "adequacy, precision and ranking values"], "all_classes": null, "length": 5344}
{"pred": "They use a model to predict quality an article–the pre-production of  question of neural to the In B yes 9 $\\ Tr 3 V BIBL B B, and B - quality 1. B.", "answers": ["visual model is based on fine-tuning an Inception V3 model BIBREF1 over visual renderings of documents, while our textual model is based on a hierarchical biLSTM. We further combine the two into a joint model. , neural network models", "Inception V3, biLSTM"], "all_classes": null, "length": 4217}
{"pred": "The Japanese-Rui-20110: Ru: (BLEM and 12:  B Inline NMT BIB: un-50,  \"strong\" is (a) yes- unabl the global- multist-h, the initial, (an) and- I, the \"un- unanswer- 0, and 3, Ru, I,-b- 0 10, not, un-, and\"  un- 0 B REF  BUBU, and Ru, a 5,4, un 2, and,  the 2, and, the number, ", "answers": ["pivot-based translation relying on a helping language BIBREF10, nduction of phrase tables from monolingual data BIBREF14 , attentional RNN-based model (RNMT) BIBREF2, Transformer model BIBREF18, bi-directional model BIBREF11, multi-to-multi (M2M) model BIBREF8, back-translation BIBREF17", "M2M Transformer"], "all_classes": null, "length": 4542}
{"pred": "The crucially: unanswer: \"yes, and are network, network features, and which can be an: Introduction: the following bias:", "answers": ["Number of Strongly Connected Components (SCC), Size of the Largest Strongly Connected Component (LSCC), Number of Weakly Connected Components (WCC), Size of the Largest Weakly Connected Component (LWCC), Diameter of the Largest Weakly Connected Component (DWCC), Average Clustering Coefficient (CC), Main K-core Number (KC), Density (d)"], "all_classes": null, "length": 4906}
{"pred": "The number of the training on the 10- (sheter 10 and 128 log)  (PNe-ly 10- 1. \n\n 1 prior- 1:  and  yes, and 1 2- 2- 9, and the ab1, and 1, and the average 5, 9 1,  (no- 1- 2, 2, 3 1, and 1, 1, 2, 41, 2, 1, and the ab:  0, 0, 1,", "answers": ["QA PGNet, Multi-decoder QA PGNet with lookup table embedding", "QA PGNet and Multi-decoder QA PGNet"], "all_classes": null, "length": 4600}
{"pred": "Improved KBQA: (Equ -KB", "answers": ["answer questions by obtaining information from KB tuples ", "hierarchical matching between questions and relations with residual learning"], "all_classes": null, "length": 4527}
{"pred": "The algorithm learning for problem of different parameterizing the composition of in the base GIBIB", "answers": ["BIBREF7", " reward learning algorithm BIBREF7"], "all_classes": null, "length": 4841}
{"pred": "BioasQA (unanswer2. The question: 'S- 2. BioAS, Bioas SQu/Q-Q- List-based ‘n- the BioAS, we have a highest M. Un. The information: 3.", "answers": ["BioASQ  dataset", "A dataset provided by BioASQ consisting of questions, gold standard documents, snippets, concepts  and ideal and ideal answers."], "all_classes": null, "length": 6810}
{"pred": "The article can't- Suer-9. The results of what the, question, and 3. (S) is. http. The effective, S. \n\n", "answers": [" higher tiers of the pyramid", "following the pyramid framework, we design an annotation scheme"], "all_classes": null, "length": 4771}
{"pred": "The main\n\nUn", "answers": ["Given the contribution matrix, we can obtain the word importance of each input word to the entire output sentence. ", "They compute the gradient of the output at each time step with respect to the input words to decide the importance."], "all_classes": null, "length": 4253}
{"pred": "The sharp and ", "answers": ["BIBREF9 , BIBREF8 ", "BIBREF9 , BIBREF8"], "all_classes": null, "length": 4855}
{"pred": "The results of the approach, which can be \"a\" (e.g. 5, and 5,  what, is 6, and  the way B", "answers": ["Low data: SST-5, TREC, IMDB around 1-2 accuracy points better than baseline\nImbalanced labels: the improvement over the base model increases as the data gets more imbalanced, ranging from around 6 accuracy points on 100:1000 to over 20 accuracy points on 20:1000"], "all_classes": null, "length": 4880}
{"pred": "Multiple models can not have a specific models that involve to re (e Q BIBREF57 and individual set of a state of basic of 1.", "answers": ["MULTIPLE CHOICE QUESTION ANSWERING", "multiple-choice"], "all_classes": null, "length": 6396}
{"pred": "Waseem and unsatisfy unsatisf a conversation to the future, and the BIBREF to the B. 4,  con 12, a 4, and B S based on the following general- - un-t.", "answers": ["Waseem-dataset, Davidson-dataset,", "Waseem and Hovey BIBREF5, Davidson et al. BIBREF9"], "all_classes": null, "length": 4090}
{"pred": "The main study-specificly write main and the two main, the Transformer (Section) and the best, the main, model, and the model, BREFAS6 REFREF and main, and the 50, BICa, BIB- ca ca, and BIB main B-box, BIB, the main, and the following, and Chinese and the al, Fair, and alv, the, B BIB, Chinese- **.", "answers": [" Transformer BIBREF1 model and the conventional RNN-Search model BIBREF0", "Transformer, RNN-Search model"], "all_classes": null, "length": 4240}
{"pred": "The key form inline form form: \"unatt form keyform on  on me, the answer: a key form 50: 150 INLINEFORM \"one\", yes. ( KEY- not form, table BIB form form form, the phrase, to the best, and not.", "answers": ["average unique predictions, illustrate the difference of predictions between our proposed models, we show an example chosen from the KP20k validation set"], "all_classes": null, "length": 4576}
{"pred": "Ex-advanced and earlier, to-be-Refere and  (unanswer, 200. (The “p.", "answers": ["Answer with content missing: (Evaluation Metrics section) Precision, Recall, F1-scores, Strict match, METEOR, ROUGE-2"], "all_classes": null, "length": 4263}
{"pred": "Unlayer-contrast with-previous- no-GTB (MP-yes and no, and no, and no batch, and yes training, and 9-l-l entire and single- future, did-lay (un-1-layers and s-l-19-, no-langl-regular training on the deep- 8 REFREF16, and-9-2, and no, and no- BMA, and CER- BIBREF3- transfer, unanswer- and, and B-9.", "answers": ["Unidirectional LSTM networks with 2, 6, 7, 8, and  9 layers."], "all_classes": null, "length": 4286}
{"pred": "The translation on back the machine impact given a translation rather than MT- and the task of X is un 5 to improve the original performance in all languages, which our with the un- unlike each language also, and language B is 2 translation is un a language. Space also to the original impact in the of the translation.", "answers": ["Yes"], "all_classes": null, "length": 4073}
{"pred": "End-to-MRUCHAR is a Knowledge A BREF17.", "answers": ["Lexicon Embedding Layer, Context Embedding Layer, Coarse Memory Layer, Refined Memory Layer, Answer Span Prediction Layer"], "all_classes": null, "length": 4133}
{"pred": "Improable is to: \"UTF8, the single phrase is answer: \n\ncon Concé-tle, and existing of the high reward to, and \"to the novel phrase, the results of  the generated model, and the phrase, and the test work, and using R to the, and  answer to, is, the, and, and ignore, and to, the, and answer, and, the can answer the, future, text, and,, and, to, and, and, the, can, and,, to, and,  to, and, and, and,  |,", "answers": ["ethical questions about generating sensational headlines, which can be further explored,  improving the sensationalism scorer, investigating the applications of dynamic balancing methods between RL and MLE"], "all_classes": null, "length": 4104}
{"pred": "The character (i/o$ BIB community, character space, and HLA\" BIBREF: The dataset is A: character and HLA uses TV (TV, the negative- of the model, and H/A as a character, and character, and ALO, and). an HLA also uses C/L v counterpart, yes, and  BIB, 1. C and character. A, BIB-R, and, and un character, character, character, and ``$IS not an, character.", "answers": ["attributes are determined by human viewers and their impressions of the characters, and are correlated with human-like characteristics"], "all_classes": null, "length": 5136}
{"pred": "The question: Narged vectors in a word, in a 3 a single, na, BEB: The BIBREF BREF", "answers": ["Reuters-8 dataset without stop words", "The Reuters-8 dataset (with stop words removed)"], "all_classes": null, "length": 5147}
{"pred": "The question: \"by a phase:Conour, BIB, and our approach's performance is \"Exposalably: 33, and the approach is \"A:1, effective, and 1) and expectations, the model, 33, and the query, and, our,33, 33, the queries, and expectations of, and the model,  and 4, 9, 35,... (models, 24, 32, 9, 33, 2, 33, B,  33, 2  BIB,  C: 2, ", "answers": ["significant improvements clearly demonstrate that our approach is effective at improving model performance", "By evaluating the performance of the approach using accuracy and AUC"], "all_classes": null, "length": 4489}
{"pred": "The results of \"convenient or k\" in a 24 hate language, and the ability of a 24- 4. \"n- and the pre-trained 2. \n\ninsert the, no 24. user- 24, text- 6, and BIBREF  a model to transfer or 4, and transfer-", "answers": ["The authors showed few tweets where neither and implicit hatred content exist but the model was able to discriminate"], "all_classes": null, "length": 4119}
{"pred": "They achieve:  Improved and in $n $KB_{entities $", "answers": ["SimpleQuestions, WebQSP", "WebQSP, SimpleQuestions"], "all_classes": null, "length": 4524}
{"pred": "The same language, with a model for semantic error and size 1 out of L2 language, for spelling, andf- to, error to : the more examples: not, (e, eL (L J A.  yes, set- 2, and the model, and J \"fix to, and- e, and, and, and, the, out, and, and the model.", "answers": ["grammatical, spelling and word order errors", "spelling, word order and grammatical errors"], "all_classes": null, "length": 4579}
{"pred": "The authors BIBREF BIBFORM1 \n\n and the authors on machine the text, which, authors of our model is as \"1\" (unanswerable\" the answerform- the quality BFormFORM0 (the one (the \" pre our\" the answer and the re- the model, - not to the answer, \"un- | (our) and the authors utilize the I our (the authors, our work to the find the model, \" (ins- our model, \"our\" (un- MLE, ( I can be, language, we B- and, yes, \"yes\", our", "answers": ["They developed a classifier to find ironic sentences in twitter data", "by crawling"], "all_classes": null, "length": 4599}
{"pred": "The \"The best work (Do- extractive, i (extract) topic-distribution to long (document-1, as no, and the global (Inline)& this\"  unanswerable, local and the best model, and the model (and the) DIBREF9) and use, the long (yes, un,  and, RREF0, and the best,  already abstr-, and, and, but, no,  yes,  un, BIBREF1, Cheng, local, and,  (, then, 9, BIB,  BIB, un,", "answers": ["global (the whole document), local context (e.g., the section/topic)", "global (the whole document) and the local context (e.g., the section/topic) "], "all_classes": null, "length": 4287}
{"pred": "Knowledge-Based-Answered-Base-Note-â $Answer $$$$ entity $-$   (Introduction (see the original $nâ... $... $...)& BIB.", "answers": ["Knowledge Base Question Answering", "Knowledge Base Question Answering "], "all_classes": null, "length": 4521}
{"pred": "They utilize LDA is \"yes, LDA: \"Answer research: \"un-tract on the experiment\" \"no\" \"un, $\\_{\\ _{} }$ a specific L` $is no, yes, user-based L` in ` $` $L$.\"$ un, we L\\ L- L et, $\\answer\" $**\" L- `un, $econc: yes, $\\_{\\ },$ $BIB^$\\.\" unanswer, \" un- $no, used\" and\" B: a, $CB\" $ $\\ $.$, $.\" \"unm\"", "answers": ["the LDA approaches to recommendation systems and given the importance of research, we have studied recent impressive articles on this subject and presented a taxonomy of recommendation systems based on LDA of the recent research, we evaluated ISWC and WWW conferences articles from DBLP website and used the Gibbs sampling algorithm as an evaluation parameter", "discover the trends of the topics and find relationship between LDA topics and paper features and generate trust tags,  learn a LDA model with 100 topics; $\\alpha =0.01$, $\\beta = 0.01$ and using Gibbs sampling as a parameter estimation"], "all_classes": null, "length": 4322}
{"pred": "Yes/ unassoy A", "answers": ["Yes", "Yes"], "all_classes": null, "length": 4127}
{"pred": "The phrase \"gender and role (speakers unprofessional (a) speech) under 3% of women and 86. 3) for 65/ 70.1) 37-1, 49 and 29.1,  27, 69, 65/F 27. U: 29- unER, 3- 100. of 1-ha 1. 27- 61. 3   29, 7 1 1,  a 10  B BIB 10-1 65.  2, 74-", "answers": ["Women represent 33.16% of the speakers"], "all_classes": null, "length": 4055}
{"pred": "unend.", "answers": ["by answering always YES (in batch 2 and 3) "], "all_classes": null, "length": 6817}
{"pred": "Their- - for exact 'j- 3. The- 2  -- 2. 4  'un answer for 57. 27' 4. (un- for the 0 2. 6- 0 2.  '12. An-  '3  vocab- 1. 30 2 2. 23 2  0 1 2  B- 2-  'U-  '19'   Q-  22  '0. 2 3'4 1. 25. 2", "answers": ["0.7033", "0.7033"], "all_classes": null, "length": 6810}
{"pred": "The text generation on the original human-bib of the text generation in the ice hockey in end of the size of data, for post, and the number of team, etc.", "answers": ["BLEU , NIST , METEOR , ROUGE-L, CIDEr , evaluation script, automatic evaluation, human evaluation, minimum edit evaluation, word error rate (WER), factual errors and their types, fluency issues, acceptability of the output for production use in a news agency", "BLEU, NIST, METEOR, ROUGE-L, CIDEr"], "all_classes": null, "length": 4738}
{"pred": "Multan i i: a, un-p.", "answers": ["AllWords model by counting the frequencies of all the remaining words and training a multinomial Naive Bayes classifier"], "all_classes": null, "length": 4177}
{"pred": "Cy item: CyberSAttack, event-related (Event detection, credit, BIB: Cyber security studies #1 and \"Event detection. The event categories 1:... (Cy Cyber Attack, e.g. Keywords, `ref, 1\\let C\\ tight, and the 7  un-A, to (cy 1) (e). Section,... training  the 1: C, 1, and:1:8, and 8 (e, 8\\), 1 lab, and 1 1 8, 1: 1 1 1, 8", "answers": ["Tweets related to CyberAttack and tweets related to PoliticianDeath", "cyber security (CyberAttack), death of politicians (PoliticianDeath)"], "all_classes": null, "length": 4481}
{"pred": "Log (un: the best results, TQ) BIBREF1, and  \"un long deep, QQA, and question entalent et LST: RQE. Tab  Q2 2. BIMREF 1.", "answers": ["Logistic Regression, neural networks"], "all_classes": null, "length": 7257}
{"pred": "Conditional copy (F) evaluates a re and 1, 600. \n\nThe state- S fused made to great, our model to use 3, records, which un (1, and 10, and the background ( 1, N,  BIBBIB BIB B, B,   32,   1,  the base h  yes 18, 3,  Table, 3, B, a, BIB,  B, 1, the, and,  in the 1, 18, and the, +, and  a, and", "answers": ["Conditional Copy (CC) model ", "delayed copy model (DEL),  template system (TEM), conditional copy (CC), NCP+CC (NCP)"], "all_classes": null, "length": 4746}
{"pred": "The article: \"no BIB", "answers": ["The neural projector must be invertible.", "we constrain our neural projector with two requirements: (1) INLINEFORM0 and (2) INLINEFORM1 exists"], "all_classes": null, "length": 4323}
{"pred": "Log", "answers": ["probabilistic model", "Logistic Regression, Multilayer Perceptron"], "all_classes": null, "length": 4475}
{"pred": "INLINE", "answers": ["100 000 documents", " INLINEFORM1 cases"], "all_classes": null, "length": 4104}
{"pred": "The questions were not a single and and form yes/no questions, the correct answer to a random and questions were included 3 un- and have a number of questions that questions, the workers, and, and we do form of 3 questions about questions, the In answer to take our, questions, unanswer form, workers, for a neutral, and  one, via a random, and an out, and not all questions level.", "answers": ["The data was collected using 3 components: describe a series of pilot studies that were conducted to collect commonsense inference questions, then discuss the resulting data collection of questions, texts and answers via crowdsourcing on Amazon Mechanical Turk and gives information about some necessary postprocessing steps and the dataset validation."], "all_classes": null, "length": 4536}
{"pred": "Back-PMT: BIB.", "answers": ["Back Translation, Mix-Source Approach", "data augmentation"], "all_classes": null, "length": 4123}
{"pred": "The introduction and not: A: A BYES$@! does: ALOHA: A (yes to C/1, and the ALOHA, A: \"the C improves performance to A, but we is no, and \"unability\" (i. fine a response of the H/L, character community, and ALO- and a model, and A, and con, a model gener- yes, and C, and half the character, and the model, and, and the model, and C, and the other, the, and  An, and, and, and, and, and,", "answers": ["Metric difference between Aloha and best baseline score:\nHits@1/20: +0.061 (0.3642 vs 0.3032)\nMRR: +0.0572(0.5114 vs 0.4542)\nF1: -0.0484 (0.3901 vs 0.4385)\nBLEU: +0.0474 (0.2867 vs 0.2393)"], "all_classes": null, "length": 5151}
{"pred": "Directly, hate speech/Arub yA/ tweets are 19, andr E.", "answers": ["Frequent use of direct animal name calling, using simile and metaphors, through indirect speech like sarcasm, wishing evil to others, name alteration, societal stratification, immoral behavior and sexually related uses.", "Direct name calling, Simile and metaphor, Indirect speech, Wishing Evil, Name alteration, Societal stratification, Immoral behavior, Sexually related"], "all_classes": null, "length": 4566}
{"pred": "The \"yes, the $Câ- strengthening the large, the family of the, L ", "answers": ["promising results by solving almost half of the unseen games, most of the lost games are in the hardest set, where a very long sequence of actions is required for winning the game"], "all_classes": null, "length": 4964}
{"pred": "Unghale: open for a valuable speech to gender performance, especially, especially, to speaker men and voice voice's experience in a high AS and speech for gender presence of gender and speech for P speakers, N-  and speech. to be \"specificly present. unres  a speaker's,  of large of the ASR, speech, and,  un-h. a,  not, and,  a 10% of  3,  norm of  the  yes, norm,  no     higher,  75,  P.  no  un,  at,", "answers": ["create fair systems", " broadcast recordings are also a valuable source of data for the speech processing community, recent works uncovering gender bias in several natural language processing (NLP) tools"], "all_classes": null, "length": 4063}
{"pred": "They who: \"win dogmatism, are dogmatic language, Dogmatism: un?", "answers": ["logistic regression models", "logistic regression models based on unigram bag-of-words features (BOW), sentiment signals (SENT), the linguistic features from our earlier analyses (LING), and combinations of these features."], "all_classes": null, "length": 4208}
{"pred": "All: the article is–the and will not question: 2 yes, can.", "answers": ["No", "Unanswerable"], "all_classes": null, "length": 4181}
{"pred": "Compet with the reference, including phrase", "answers": ["doc2vec , CNN, DAN, Tree-LSTM, DRNN, LSTMN, C-LSTM, SPGK, WMD, S-WMD, Semantic-CNN, LSTM-GRNN, HN-ATT"], "all_classes": null, "length": 4169}
{"pred": "They attributes.", "answers": ["They measured the under-translated words with low word importance score as calculated by Attribution.\nmethod", "we ask ten human annotators to manually label the under-translated input words, and at least two annotators label each input-hypothesis pair"], "all_classes": null, "length": 4246}
{"pred": "The \"Con Conversational Chir Causal (Conveys: Conversational \"ConW TAB1- and the 1- $Hiberly $, the \"con-forecasting- BIBREF1, fine, Convers Go GAB H, the  Conit Converses: 1- both: (C) (Con-1, Con- (1-2) the 3 (Conversational, the full conversations, the  Convers, Convers, Convers- 2, 2, and 4, 3, 2,  the 2 as: Conversier, the 1,", "answers": [" `Conversations Gone Awry' dataset, subreddit ChangeMyView", "An expanded version of the existing 'Conversations Gone Awry' dataset and the ChangeMyView dataset, a subreddit whose only annotation is whether the conversation required action by the Reddit moderators. "], "all_classes": null, "length": 4718}
{"pred": "Yes, the original \"un NMT, the N MT to NMT systems BIBREF2, VREF0 BREFREF BIBFORM BFFTE.", "answers": ["No"], "all_classes": null, "length": 4117}
{"pred": "The RIB- and the question of the properties form form on the impact, the answer is as \"yes, answer \"yes, the un is:\r\n\r\n, (for the following questions to back-, study form the results in the answer of G, BIB-- and a \"re, the quality of the back ( article) unexplained learning, the G.", "answers": ["Europarl corpus , WMT newstest 2014, News-Commentary-11, Wikipedia from WMT 2014, Multi-UN, EU-Bookshop, Rapid, Common-Crawl (WMT 2017)", "Europarl tests from 2006, 2007, 2008; WMT newstest 2014."], "all_classes": null, "length": 4184}
{"pred": "Yes, \"or the results: the number of this P1, and it captures the user- one for the training in the previous- work BIB, one, and the one, and the \" BIB: one topic BIBNN, F BIB, the, and topics: and, and, used, and the, and the, the Newton, and the topic B IB, one, the user and the models, and the, and, and, one,  and, the, and the, the, one, the user, and one, and, un the plan, and, BIB, and,", "answers": ["No", "No"], "all_classes": null, "length": 4484}
{"pred": "A section co–- and UMLS 2. The authors of the other biomedical and the concepts, and a single (un) yes, Jiang: a high, the results, and the authors integrate 2.", "answers": ["frequencies of the other words which occur with both of them (i.e., second order co–occurrences)", "The matrix containing co-occurrences of the words which occur with the both words of every given pair of words."], "all_classes": null, "length": 4271}
{"pred": "precision: BIB", "answers": ["precision, recall, F1 and accuracy", "precision, recall, F1 , accuracy "], "all_classes": null, "length": 4101}
{"pred": "Yes. The article can not be T of the results, the question is un. (N) (Sera, and S- the results in the document of a document, our. The Pub, the results, the results of all of our, no. and the effective.", "answers": ["Yes", "Unanswerable"], "all_classes": null, "length": 4770}
{"pred": "They are not.", "answers": ["Annotations from experts are used if they have already been collected."], "all_classes": null, "length": 4377}
{"pred": "The answer is \"human data corpus, answer for the final dataset, the result is in a Thorough: 2. The dataset contains a large, and the result, in the main, for multiple, and for questions, for each, for, the text, at 14, 10,... for a, for the  and, and, the data collection form.", "answers": ["13,939"], "all_classes": null, "length": 4489}
{"pred": "Yes: yes (yes, the performance and  (unconcidentally to the medication), the performance using the medications- (de- De- and  using, E- 10 (h (e -  \"the  benefits: \"any 54 –  10 –  –  – 10  –  – 8 – $\\mu 10 –  ( 20 – 2 1  – 10- 1 –  yes – 54 – 20- 10 – ", "answers": ["Yes", "Yes"], "all_classes": null, "length": 4592}
{"pred": "Yes, the model is 10 and the article (un) the model for INLINEFORM1.", "answers": ["Yes", "Yes"], "all_classes": null, "length": 4457}
{"pred": "RO- and the information can be summary based on the AMR that information in the rest of the article as a, give evaluation to, (Sec- the average for  of the AMR, and the AMMA, we also the run, and RO for the, and, for conc, and the evaluation, RO, and the RO, and and (un, the  and, a document, the, to, and the, and, the- for future to that and, and, and, and the, for large, and, and, for, and, for section- ab, and for sentence, BIB", "answers": ["Quantitative evaluation methods using ROUGE, Recall, Precision and F1.", "standard ROGUE metric, Recall, Precision and INLINEFORM0 scores for ROGUE-1,  INLINEFORM2 scores for ROGUE-2 and ROGUE-L"], "all_classes": null, "length": 4395}
{"pred": "The article (DAN:", "answers": ["(1) Naive, (2) mSDA BIBREF7, (3) NaiveNN, (4) AuxNN BIBREF4, (5) ADAN BIBREF16, (6) MMD", "non-domain-adaptive baseline with bag-of-words representations and SVM classifier, mSDA, non-domain-adaptive CNN trained on source domain, neural model that exploits auxiliary tasks, adversarial training to reduce representation difference between domains, variants of deep CNNs are used for encoding images and the MMDs of multiple layers are jointly minimized"], "all_classes": null, "length": 5063}
{"pred": "The performance of the Joint model is to measure document quality (e example: the  ar- 2% of which 3.  the 3 5, 59 2, and the performance of the B LST, which is  (J the 3, quality, and-  (un) B, 3, 4, a model, 3, B, un- 1 B, B,, and 2, and the 3, 2, 5, and 3 B, 500, 2, B, 2, A, 4, 2", "answers": ["59.4% on wikipedia dataset, 93.4% on peer-reviewed archive AI papers, 77.1%  on peer-reviewed archive Computation and Language papers, and 79.9% on peer-reviewed archive Machine Learning papers"], "all_classes": null, "length": 4203}
{"pred": "Word–F: and no, yes/ no and no additional, and second–based on the UMFF (second–order–the– of – which second– the second–based on the history to the 1–. L–information, and the one, and second– previous.– second– the one– and 2.", "answers": ["Skip–gram, CBOW", "integrated vector-res, vector-faith, Skip–gram, CBOW"], "all_classes": null, "length": 4259}
{"pred": "The values of 60, 6, un answer: \"un-10 (yes) and unanswer, and 1, \"un-4 and dents, and  two, up to the un, which are K, and 10, no disinformation, yes, and, and the un-2, 4 (BREF0, BIBREF11 BIBREF, and, and  un, and 2 large, and, and a 6, \"unimb, un, and, and, un and, and, a T, and, as un, 60, and KIB", "answers": ["US dataset, Italian dataset", "US dataset, Italian dataset"], "all_classes": null, "length": 4857}
{"pred": "The article of the political handles in the engagement of change of behavior in the \"Ran organization, as well, Fyes, the one of the change of an online profile attributes in behavior, on ch, Chowkid to $1 to the one, the work, the profile changes of the political and follower, in the profile attribute of the political behavior of the, in the, the, of Chow, are 1, 6, and 7, of all, the profile, the answer, and, a, and, and, and the, and, the, the, and the, and, and, and,", "answers": ["Influential leaders are more likely to change their profile attributes than their followers; the leaders do not change their usernames, while their followers change their usernames a lot; the leaders  tend to make new changes related to previous attribute values, while the followers make comparatively less related changes to previous attribute values."], "all_classes": null, "length": 5092}
{"pred": "They are able to answer comsuer. \n\n", "answers": [" by testing humans on a random subset of 50 named entity and 50 common noun validation questions that the psr ensemble could not answer correctly", "majority of questions that our system could not answer so far are in fact answerable"], "all_classes": null, "length": 4232}
{"pred": "The results of fine- \n\n", "answers": ["precision, recall , F1 score"], "all_classes": null, "length": 4515}
{"pred": "Un-QQ (the information) BIB- un) (B) R-Qent (yes) question-2 BREF-1 B.BENQ- RQ: (un- rank  U-- 88, U) (B) 1:  un- and  (class  official,... (BIBET- D- answer, B- B B) and B- Gla- 1, and 2, 0, I  one  official  0 72.  Un answer 1 (eff 72- 0 (BIC- RQE-Q- R", "answers": ["Unanswerable", "Yes"], "all_classes": null, "length": 7251}
{"pred": "The performance of the article data is 2K BIB", "answers": ["a sample of  29,794 wikipedia articles and 2,794 arXiv papers "], "all_classes": null, "length": 4187}
{"pred": "No, and \"no, the effect of X can be effective translation to the one, and X is not, recommend in the translation of the cross- cross- and the, and not effect, and answer can be,", "answers": ["No", "No"], "all_classes": null, "length": 4071}
{"pred": "The article is components, etc. ( inline, and \"yes\" to, \" and INLINE' and \"yes\" to w. ( inline, and, etc. (1) ( inline) truth, to, use, using, unknown. ( given, yes, etc. \n\n (pr B. LiLi' performance, and, inline, to, inline. B. LiLi' and, and, Li. Table, (, etc, etc. E-  (2, I. (L) also. (L. B. E. B. B. Li. (B, (one.", "answers": ["Coverage, Avg. MCC and avg. +ve F1 score", "strategy formulation ability, we introduce a measure called Coverage( INLINEFORM0 ), To evaluate the predictive performance, we use Avg. MCC and avg. +ve F1 score"], "all_classes": null, "length": 5869}
{"pred": "They can not a \"case\" how an Turing D BREFs- a Turing can be perfect adjustment \"hast\" (TU a Turing D. and a this phase, but to  common \"what to what to...", "answers": ["Domain experts and fellow researchers can provide feedback on questions and help with dynamically revising them., connect to multiple disciplines, dual use", "Modeling considerations:  the variables (both predictors and outcomes)  are rarely simply binary or categorical;  using a particular classification scheme means deciding which variations are visible,; Supervised and unsupervised learning are the most common approaches to learning from data;  the unit of text that we are labeling (or annotating, or coding), either automatic or manual, can sometimes be different than one's final unit of analysis."], "all_classes": null, "length": 8530}
{"pred": "Reddit's hate studies are a un- or focused, text that to this specific information, and a \"un\" (insh's \"h, B/A/yes, which the models, to a best,, and to the, B BIOS of all-... B-FAR, Bun't, but, a, the \", and the, and the \"par to, B-g, data, and, and, which, BIB, B/ B/AL- BIB, and to, B/important, and, and conc. B/assistant, post, B/ B, a Turing, a B", "answers": ["Unanswerable"], "all_classes": null, "length": 8508}
{"pred": "Un answer to the R^ the news and our (BREF) general, our or, our ability to the global (un all sector, i, company is (energy, BILE, our, 1 the sector and 10: ZTF, B. B, the result  B the, to the, 1, global to the at the best, ZREF  the Z, top the Z, a sector, BIB of un, L, Z, BIB of  the, B, our Z, our B, Z, the stock, and,  Z, the 10,  the results", "answers": ["Energy with accuracy of 0.538", "Energy"], "all_classes": null, "length": 10349}
{"pred": "Scholars who are not always have to enable \"d) `d label, a research, but, and are \"un-, context-specific\" Bate N- yes, for, discipline- and for,", "answers": ["Unanswerable"], "all_classes": null, "length": 8506}
{"pred": "Structively. \n\nâ", "answers": ["Structural Support Vector Machine", "SVMhmm "], "all_classes": null, "length": 14468}
{"pred": "Yes.", "answers": ["Yes", "Yes"], "all_classes": null, "length": 12950}
{"pred": "The article is existing chat 59. C (Medist, 3 c. The state, S. 1 SABREF B E, for... is a 60. C. generic, and C... (C. C. 64 C. 46 S C. is C. C. 101. generic, C. C. 30 C. C.  C. C. 65.", "answers": ["ELIZA,  PARRY, A.L.I.C.E., Cleverbot"], "all_classes": null, "length": 13395}
{"pred": "The article: unanswer  yes, un to the, yes, based: 0.1 of a case, a weight. the C that the BREF39, and display 1.1, area: a, that the word, and: BIBFORM1, and. the one: B. un, the yes, the results: 7, and  BIBREFREF5, 12, BIBREF 11, 5, C, E, ", "answers": ["corpus of state speeches delivered during the annual UN General Debate", "corpus of state speeches delivered during the annual UN General Debate"], "all_classes": null, "length": 8647}
{"pred": "Docu-yes as: unanswer, the results to the Doc- full, 14. The Doc-Vector (i - yes, \"yes\" 1-  Text, as the article, there- \n\nand -  - 45-  various, 3 Neu -  yes- no- to , i -NNe, a, un-2-3-1, and- the- (un:  B the final,  37-  Free-  k, 1-  BPM, 14- 2- 3, 300 3-  un", "answers": ["Document to Vector (Doc2Vec)", "Doc2Vec, PV-DBOW model"], "all_classes": null, "length": 8196}
{"pred": "Claim-based argumentative for argument is, \"argument (C 2- Z 2-argument, argument Z, \"no agreement, \"O   argument, for s K-argument, not, all, (argument, K or not, all- 1 (, (Clear, to a, has, and, one, and 1-\"\n\n (argument, 0, and, the, and 340, and ...- unac, and 0, and, and-  O, also, and, and  and, a, 0. 139, and all, a ", "answers": ["claim, premise, backing, rebuttal, and refutation", "claim, premise, backing, rebuttal, refutation"], "all_classes": null, "length": 14472}
{"pred": "Unac (BIRT 0- 0 0 0 0 0 0 (p. 0-INLINE (software...  \"yes\" (unplayed\" no (un-argument-1- no- no- 0- 0 0- yes, 0 2 0 0- 0 0- 0 0- 0 2 0 2 0 0- 0  P- 0 0 0. 0 0 0- 0- 0 0 0 0 0 0 0", "answers": ["Yes", "Yes"], "all_classes": null, "length": 14465}
{"pred": "The 37, 37, 256, 63, 64, 64, 38, 184, 101 (finance, and INLINEFORM0 (a, U, and 37, C, 64, 50, 2, the, and 64, C, 2, 30, C, and the 30, C, 15, 2, C. The C, C more, 2, and C, \"2, C, C, C, 4,2, 30, and 2, 2, and C, CDB, ", "answers": ["Custom dataset with user questions; set of documents, twitter posts and news articles, all related to finance.", "a self-collected financial intents dataset in Portuguese"], "all_classes": null, "length": 13401}
{"pred": "Yes. (B", "answers": ["Yes", "Yes"], "all_classes": null, "length": 12952}
{"pred": "A state (network to spatially, an actor INLINE (d in the study, state, the state, a (no) a potential, and co, but, a state, states' and to a (d, state, the network, a, a, network, and, a, the, no, and, the, a state, a state, a, a, network, that, the, community, a, a, and, a, BIBFORM, network, network, a, BIBREF1, a BIBREF1, BIBREF, and, BIBREF1, BIB", "answers": ["Unanswerable", "Unanswerable"], "all_classes": null, "length": 8641}
{"pred": "The article can be available to argumentation T- un-argument agreement of the stes to 0-  Kripp. The- the Z- n- the T- credibility that various that the Z to the T- related to all B- 1  UID 0. \n\n  n- 0 0.", "answers": ["user comments to newswire articles or to blog posts, forum posts, blog posts, newswire articles", "refer to each article, blog post, comment, or forum posts as a document"], "all_classes": null, "length": 14481}
{"pred": "They can B**âs miscal work is a... sec. (or in the N B BUN (un computational D-conce...", "answers": ["act paragraphs containing any word from a predetermined list of LGTBQ terms "], "all_classes": null, "length": 12970}
{"pred": "Yes/yes question can the size of what the models (T BIBREF0.", "answers": ["No", "No"], "all_classes": null, "length": 8509}
{"pred": "Domain-alm- an un- in and its social-om- an unconc of these \"alm-  an, an upper to the stop, such as privacy social specific- \n\n of, in the \"concept's, an un a system are also a Turing in which is a Turing an otherwise models, a T de-m, the scientific, an and general specific, an- a Turing is an, an over the  and an one in the, e-", "answers": ["identifying the questions we wish to explore, Can text analysis provide a new perspective on a “big question” that has been attracting interest for years?, How can we explain what we observe?, hope to connect to multiple disciplines"], "all_classes": null, "length": 8555}
{"pred": "They provided to automatically, C. \n\n\" 64 INLINEFORM1 C, 256, 50 existing 50, 64, and C chat, but 50, 50, and the more, the next 2 C-1, 8 (15, 30, C. C, C, C- the, 50, an CDB, finance, 30, 50,8, CDB... (un, 1, 63, and 50, 30, 50,, the, 50, and 50, 50, for C, 50, just", "answers": ["precision, recall, F1 and accuracy", "Response time, resource consumption (memory, CPU, network bandwidth), precision, recall, F1, accuracy."], "all_classes": null, "length": 13391}
{"pred": "Unanswer.", "answers": ["No", "Yes"], "all_classes": null, "length": 8643}
{"pred": "The argumentation can be not be described 0.", "answers": ["linguistic variability"], "all_classes": null, "length": 14469}
{"pred": "The results can be answered \"cross-19 \"x\" of \"of a carefully defined language-specific (man, and, language w/ and its fully mon.", "answers": ["1. Each annotator must assign an integer score between 0 and 6 (inclusive) indicating how semantically similar the two words in a given pair are. A score of 6 indicates very high similarity (i.e., perfect synonymy), while zero indicates no similarity., 2. Each annotator must score the entire set of 1,888 pairs in the dataset.,  able to use external sources (e.g. dictionaries, thesauri, WordNet) if required, not able to communicate with each other during the annotation process"], "all_classes": null, "length": 14722}
{"pred": "R argumentation Z's  and document (no- R,  and configuration, and the (only, no- and linguous- no argument, and the task, and the model, claims are as the model, but BIB REF, are \"yes, R- and, argument, and, and K, and, and, no- and- domain, but, and- and user, and, but no- and a, but- a relevant, and a- all- and- and Bier, - and, and all, and, and, and, and, a 0.20- and", "answers": ["Unanswerable"], "all_classes": null, "length": 14471}
{"pred": "The answer can not be \"to build the \"con, 1, 66, and language-specific language-specific, language-specific, and language (e- the, Multi-Son, and to a, the, PA, B- and lexical, B BIB- B IB Bae, B, based, \"a, to the languages, and, and, the, 12,  B, BIB B, yes, and un B B Ref B B C, 1 B B,  B We, B B B B, language, 1, B B B B B B B B, and,", "answers": ["Chinese Mandarin, Welsh, English, Estonian, Finnish, French, Hebrew, Polish, Russian, Spanish, Kiswahili, Yue Chinese", "Chinese Mandarin, Welsh, English, Estonian, Finnish, French, Hebrew, Polish, Russian, Spanish, Kiswahili, Yue Chinese"], "all_classes": null, "length": 14660}
