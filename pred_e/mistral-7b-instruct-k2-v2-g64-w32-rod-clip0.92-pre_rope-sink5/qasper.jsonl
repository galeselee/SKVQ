{"pred": "FoxNews, CNN, ESPN, New York Times, Time magazine, Huffington Post Weird News, The Guardian, Cartoon Network, Cooking Network, Home Cooking Adventure, Justin Bieber, Nickelodeon, Spongebob, Disney.", "answers": ["FoxNews, CNN, ESPN, New York Times, Time magazine, Huffington Post Weird News, The Guardian, Cartoon Network, Cooking Light, Home Cooking Adventure, Justin Bieber, Nickelodeon, Spongebob, Disney", "FoxNews, CNN, ESPN, New York Times, Time magazine, Huffington Post Weird News, The Guardian, Cartoon Network, Cooking Light, Home Cooking Adventure, Justin Bieber, Nickelodeon, Spongebob, Disney."], "all_classes": null, "length": 3411}
{"pred": "Latent context is inferred using a sequence of posts.", "answers": ["the series of posts that trigger an intervention"], "all_classes": null, "length": 3732}
{"pred": "\"Kappa difference and odds-ratio\"", "answers": ["F-score, Kappa", "Unanswerable"], "all_classes": null, "length": 3544}
{"pred": "The baselines are plain stacked LSTMs.", "answers": ["(i) models that use plain stacked LSTMs, (ii) models with different INLINEFORM0, (iii) models without INLINEFORM1, (iv) models that integrate lower contexts via peephole connections"], "all_classes": null, "length": 3224}
{"pred": "No.", "answers": ["Yes", "Unanswerable"], "all_classes": null, "length": 2284}
{"pred": "Unanswerable.", "answers": ["No"], "all_classes": null, "length": 3843}
{"pred": "Modest gains in sentiment classification task.", "answers": ["Yes", "No"], "all_classes": null, "length": 2317}
{"pred": "Four datasets were used in evaluation.", "answers": ["SemEval-2016 Challenge Task 5 BIBREF27 , BIBREF28", " English reviews ,  restaurant reviews from four different languages (Spanish, Turkish, Dutch, Russian)"], "all_classes": null, "length": 2720}
{"pred": "Improvements on small-scale unbalanced datasets with topic information are significant.", "answers": ["7.36% on accuracy and 9.69% on F1 score", "it has 0.024 improvement in accuracy comparing to ELMO Only and  0.006 improvement in F1 score  comparing to ELMO Only too"], "all_classes": null, "length": 2890}
{"pred": "They determine text from the audio.", "answers": ["They use text transcription.", "both"], "all_classes": null, "length": 3198}
{"pred": "Clustering algorithms used are simple, Carrot2 Lingo, and CLUTO.", "answers": ["CLUTO, Carrot2 Lingo", "simple clustering algorithm which uses the cosine similarity between word embeddings"], "all_classes": null, "length": 3039}
{"pred": "BERT", "answers": ["Bert + Unanswerable", "CNN, BERT"], "all_classes": null, "length": 3845}
{"pred": "Pivoting and pivot-synthetic", "answers": ["pivoting, pivoting$_{\\rm m}$", "firstly translates a source language into the pivot language which is later translated to the target language"], "all_classes": null, "length": 3815}
{"pred": "EmotionLines dataset was used.", "answers": ["Friends, EmotionPush", "EmotionLines BIBREF6"], "all_classes": null, "length": 3178}
{"pred": "Several evaluation protocols are provided for each part of the DeepMine database.", "answers": ["three experimental setups with different numbers of speakers in the evaluation set, three experimental setups with different number of speaker in the evaluation set are defined,  first one, respondents with at least 17 recording sessions are included to the evaluation set, respondents with 16 sessions to the development and the rest of respondents to the background set, second setup, respondents with at least 8 sessions are included to the evaluation set, respondents with 6 or 7 sessions to the development and the rest of respondents to the background set"], "all_classes": null, "length": 3880}
{"pred": "Gaussian-masked directional multi-head attention calculates the representation of input by using multi-head attention with a variant of self-attention that includes a Gaussian weight matrix and a directional mask.", "answers": ["pays attentions to adjacent characters and casts a localness relationship between the characters as a fixed Gaussian weight assuming the weight relies on the distance between characters", "Gaussian-masked directional attention can be described as a function to map queries and key-value pairs to the representation of input, Gaussian-masked directional attention expects to pay attention to the adjacent characters of each positions and cast the localness relationship between characters as a fix Gaussian weight for attention, Gaussian weight only relys on the distance between characters"], "all_classes": null, "length": 3612}
{"pred": "The system can be trained using only English monolingual data for initializing foreign word-embeddings.", "answers": ["No data. Pretrained model is used."], "all_classes": null, "length": 3409}
{"pred": "Different in cases of verbs.", "answers": ["For certain POS tags, e.g. VERB, PRON.", "most word alignments only involve one or a few words, attention can be distributed more freely"], "all_classes": null, "length": 3366}
{"pred": "Recurrent Neural Network (RNN)", "answers": ["RNN", " Recurrent Neural Network (RNN)"], "all_classes": null, "length": 1644}
{"pred": "The baseline is not mentioned in the article.", "answers": ["CNN modelBIBREF0, Stanford CRF modelBIBREF21", "Bam et al. SVM, Ma and Hovy w/glove, Lample et al. w/fastText, Lample et al. w/word2vec"], "all_classes": null, "length": 2836}
{"pred": "Unanswerable (The article does not provide a publication date)", "answers": ["Unanswerable"], "all_classes": null, "length": 3885}
{"pred": "Around 500 workers were involved in the data collection for the evaluation study.", "answers": ["about 500", "Unanswerable"], "all_classes": null, "length": 3831}
{"pred": "CNN, BiLSTM, and SVM", "answers": ["linear SVM, bidirectional Long Short-Term-Memory (BiLSTM), Convolutional Neural Network (CNN)", "linear SVM, bidirectional Long Short-Term-Memory (BiLSTM), Convolutional Neural Network (CNN)", "linear SVM trained on word unigrams,  bidirectional Long Short-Term-Memory (BiLSTM),  Convolutional Neural Network (CNN) "], "all_classes": null, "length": 2250}
{"pred": "BiLSTM, BiLSTM-CNN, BiLSTM-CRF, BiLSTM-CNN-CRF, Stanford CRF, CNN, and RNN.", "answers": ["BiLSTM, BiLSTM-CNN, BiLSTM-CRF, BiLSTM-CNN-CRF", "BiLSTMBIBREF14, BiLSTM+CNNBIBREF20, BiLSTM+CRFBIBREF1, BiLSTM+CNN+CRFBIBREF2, CNN modelBIBREF0 and Stanford CRF modelBIBREF21"], "all_classes": null, "length": 2838}
{"pred": "Unsupervised term discovery (UTD) or acoustic unit discovery (AUD) is used to automatically discover vocabulary of word-like or phoneme-like units.", "answers": ["Zero Resource Toolkit (ZRTools) BIBREF7"], "all_classes": null, "length": 3381}
{"pred": "BERTBase model", "answers": ["BERTbase", "BERTbase"], "all_classes": null, "length": 3852}
{"pred": "Five keyphrase extraction models were reassessed.", "answers": ["Answer with content missing: (LVL1, LVL2, LVL3) \n- Stanford CoreNLP\n- Optical Character Recognition (OCR) system, ParsCIT \n- further abridge the input text from level 2 preprocessed documents to the following: title, headers, abstract, introduction, related work, background and conclusion."], "all_classes": null, "length": 1822}
{"pred": "Yes", "answers": ["Yes", "Yes"], "all_classes": null, "length": 2077}
{"pred": "MIMIC database and MIMIC-III discharge summaries", "answers": ["MIMIC-III", "MIMIC-III"], "all_classes": null, "length": 2992}
{"pred": "The article does not provide the exact number of instances for each step of the hierarchy.", "answers": ["Level A: 14100 Tweets\nLevel B: 4640 Tweets\nLevel C: 4089 Tweets"], "all_classes": null, "length": 2255}
{"pred": "Attention captures information beyond alignment in the case of verbs.", "answers": ["it captures other information rather than only the translational equivalent in the case of verbs", "Alignment points of the POS tags."], "all_classes": null, "length": 3372}
{"pred": "Bag-of-words, TFIDF, Logistic Regression, Random Forest, TextCNN, and Causal modeling TextCNN.", "answers": ["BOW-LR, BOW-RF. TFIDF-RF, TextCNN, C-TextCNN", "bag-of-words (BOW), term frequencyâ€“inverse document frequency (TFIDF), neural-based word embedding, Logistic Regression (LR), Random Forest (RF), TextCNN BIBREF10 with initial word embedding as GloVe"], "all_classes": null, "length": 3181}
{"pred": "They look at multiple tags.", "answers": ["Unanswerable", "48,705"], "all_classes": null, "length": 3307}
{"pred": "\"Transformer base for MT, and a model architecture similar to that in berard2018end for ASR and ST.\"", "answers": ["follow the architecture in berard2018end, but have 3 decoder layers like that in pino2019harnessing"], "all_classes": null, "length": 2424}
{"pred": "Penn Treebank (PTB) and WikiText2 (WT-2) datasets.", "answers": [" Penn Treebank, WikiText2", "Penn Treebank (PTB) , WikiText2 (WT-2)"], "all_classes": null, "length": 3302}
{"pred": "Unanswerable (Graphical models are not mentioned in the article)", "answers": ["No", "No"], "all_classes": null, "length": 3158}
{"pred": "Prior knowledge distillation techniques are not immediately applicable due to incompatible teacher and student model vocabularies.", "answers": ["While there has been existing work on reducing NLP model vocabulary sizes BIBREF15, distillation techniques cannot utilize these, since they require the student and teacher models to share the same vocabulary and output space. This profoundly limits their potential to further reduce model sizes.", "distillation techniques cannot utilize these, since they require the student and teacher models to share the same vocabulary and output space. This profoundly limits their potential to further reduce model sizes."], "all_classes": null, "length": 3570}
{"pred": "word2vec", "answers": ["using word2vec to create features that are used as input to the SVM", "use the word2vec algorithm, create several unsupervised hand-crafted features, generate document vectors and feed them as input into the support vector machines (SVM) approach"], "all_classes": null, "length": 3820}
{"pred": "From the internet.", "answers": ["ancient Chinese history records in several dynasties (about 1000BC-200BC) and articles written by celebrities of that era", "Ancient Chinese history records in several dynasties and articles written by celebrities during 1000BC-200BC collected from the internet "], "all_classes": null, "length": 3722}
{"pred": "Unanswerable (based on the information provided in the article)", "answers": ["No"], "all_classes": null, "length": 1561}
{"pred": "Words embeddings, style, and morality features.", "answers": ["words embeddings, style, and morality features", "words embeddings, style, and morality features"], "all_classes": null, "length": 2091}
{"pred": "United Nations Parallel Corpus, Universal Dependencies v2.4, XNLI dataset, WikiExtractor.", "answers": ["United Nations Parallel Corpus, IIT Bombay corpus, OpenSubtitles 2018"], "all_classes": null, "length": 3405}
{"pred": "Unspecified in the article.", "answers": ["Unanswerable", "English"], "all_classes": null, "length": 2009}
{"pred": "Unanswerable", "answers": ["No", "No"], "all_classes": null, "length": 1899}
{"pred": "Over 45,000 articles", "answers": ["45,000 scholarly articles, including over 33,000 with full text"], "all_classes": null, "length": 2150}
{"pred": "Compared baseline models", "answers": ["support vector machine classifier (SVM), logistic regression classifier (LR), Naive Bayes classifier (NB), random forest (RF), CNN, LSTM , LSTM-soft, LSTM-self", "support vector machine classifier (SVM), logistic regression classifier (LR), Naive Bayes classifier (NB), random forest (RF), CNN, LSTM , LSTM-soft, LSTM-self"], "all_classes": null, "length": 2895}
{"pred": "Unanswerable (no specific number of electrodes mentioned in the article)", "answers": ["1913 signals", "Unanswerable"], "all_classes": null, "length": 2361}
{"pred": "Conversational search, conversational question answering, conversational recommendation, conversational natural language interface to structured and semi-structured data, clarification and preference elicitation, explanation, and recommendation.", "answers": ["Co-Reference Resolution, Query Generation, Retrieval Model, Result Generation", "Co-Reference Resolution, Query Generation, Retrieval Model, Result Generation"], "all_classes": null, "length": 1701}
{"pred": "Unanswerable (based on the information provided in the article)", "answers": ["Unanswerable"], "all_classes": null, "length": 1913}
{"pred": "Unanswerable (Accents are not explicitly mentioned in the article)", "answers": ["Unanswerable", "Unanswerable"], "all_classes": null, "length": 3794}
{"pred": "SQuAD dataset", "answers": ["SQuAD", "SQuAD"], "all_classes": null, "length": 3757}
{"pred": "SemEval 2010 task 8 dataset", "answers": ["relation classification dataset of the SemEval 2010 task 8", "SemEval 2010 task 8 BIBREF8"], "all_classes": null, "length": 2393}
{"pred": "The English corpus was twice the size of the Russian corpus.", "answers": ["2174000000, 989000000", "2174 million tokens for English and 989 million tokens for Russian"], "all_classes": null, "length": 2958}
{"pred": "Qualitative experiments are performed on the Text8 dataset.", "answers": ["Spearman correlation values of GM_KL model evaluated on the benchmark word similarity datasets.\nEvaluation results of GM_KL model on the entailment datasets such as entailment pairs dataset created from WordNet, crowdsourced dataset of 79 semantic relations labelled as entailed or not and annotated distributionally similar nouns dataset.", "Given a query word and component id, the set of nearest neighbours along with their respective component ids are listed"], "all_classes": null, "length": 2220}
{"pred": "Improves F1 by 0.58 for MRPC and 0.73 for QQP.", "answers": ["Using DSC loss improves the F1 score by +0.58 for MRPC and +0.73 for QQP", "+0.58"], "all_classes": null, "length": 3566}
{"pred": "Asymptotic variance is calculated using Fisher Information Ratio criteria.", "answers": ["reducing the variance of an estimator,  EGL method in BIBREF3 is almost the same as Eq. ( EQREF8 ), except the gradient's norm is not squared in BIBREF3", " Fisher Information Ratio"], "all_classes": null, "length": 1671}
{"pred": "LSTM encoder", "answers": ["LSTM", "LSTM"], "all_classes": null, "length": 2289}
{"pred": "Natural language questions are present in the dataset.", "answers": ["These 8 tasks require different competencies and a different level of understanding of the document to be well answered"], "all_classes": null, "length": 3817}
{"pred": "Yes", "answers": ["SVM, No-Answer Baseline (NA) , Word Count Baseline, Human Performance", "No-Answer Baseline (NA), Word Count Baseline, Human Performance"], "all_classes": null, "length": 3855}
{"pred": "53", "answers": ["53 documents", "53 documents"], "all_classes": null, "length": 2667}
{"pred": "Food.com", "answers": ["from Food.com"], "all_classes": null, "length": 2649}
{"pred": "Intrinsic evaluations (word similarity and word analogy tasks), downstream tasks (chunking, sentiment and question classification, natural language identification), and OOV word representation through nearest-neighbors.", "answers": ["We also evaluate all five models on downstream tasks from the VecEval suite BIBREF13 , using only the tasks for which training and evaluation data is freely available: chunking, sentiment and question classification, and natural language identification (NLI). The default settings from the suite are used, but we run only the fixed settings, where the embeddings themselves are not tunable parameters of the models, forcing the system to use only the information already in the embeddings."], "all_classes": null, "length": 2083}
{"pred": "Unanswerable (The article only mentions 13 annotated phenotypes)", "answers": ["Adv. Heart Disease, Adv. Lung Disease, Alcohol Abuse, Chronic Neurologic Dystrophies, Dementia, Depression, Developmental Delay, Obesity, Psychiatric disorders and Substance Abuse"], "all_classes": null, "length": 1651}
{"pred": "Unanswerable (due to variability in text length)", "answers": ["204 tokens", "Most texts, however, range roughly from 150 to 250 tokens."], "all_classes": null, "length": 1898}
{"pred": "Patterns in the form of (incorrect phrase, correct phrase) are extracted.", "answers": ["(VVD shop_VV0 II, VVD shopping_VVG II)", "patterns for generating all types of errors"], "all_classes": null, "length": 2133}
{"pred": "Unanswerable.", "answers": ["No", "No"], "all_classes": null, "length": 3974}
{"pred": "Random Kitchen Sink approach.", "answers": ["Random Kitchen Sink method uses a kernel function to map data vectors to a space where linear separation is possible.", "explicitly maps data vectors to a space where linear separation is possible, RKS method provides an approximate kernel function via explicit mapping"], "all_classes": null, "length": 2361}
{"pred": "They compare to a Big Transformer model and a variant where they share token embeddings between the encoder and decoder.", "answers": ["BIBREF11 , BIBREF26 "], "all_classes": null, "length": 1912}
{"pred": "Improvements on FCE and CoNLL 2014 Shared Task datasets.", "answers": ["Combining  pattern based and Machine translation approaches gave the best overall F0.5 scores. It was 49.11 for FCE dataset  , 21.87 for the first annotation of  CoNLL-14, and 30.13 for the second annotation of CoNLL-14. "], "all_classes": null, "length": 2164}
{"pred": "Named Entity Recognition, POS tagging, text classification, language modeling.", "answers": ["None"], "all_classes": null, "length": 2473}
{"pred": "Seven experts with legal training", "answers": ["Individuals with legal training", "Yes"], "all_classes": null, "length": 3846}
{"pred": "Machine learning approaches have been applied to solve word segmentation in Vietnamese.", "answers": ["Maximum Entropy, Weighted Finite State Transducer (WFST),  support vector machines (SVM), conditional random fields (CRF)", "Maximum matching, Hidden Markov model , Maximum Entropy, Conditional Random Fields , Support Vector Machines"], "all_classes": null, "length": 3471}
{"pred": "Three named entity recognition models were evaluated: Stanford NER, spaCy 2.0, and a recurrent model with a CRF top layer.", "answers": ["Stanford NER, spaCy 2.0 , recurrent model with a CRF top layer", "Stanford NER, spaCy 2.0, recurrent model with a CRF top layer"], "all_classes": null, "length": 2759}
{"pred": "WN18 and FB15K", "answers": ["WordNet BIBREF0, Freebase BIBREF1, WN18 (a subset of WordNet) BIBREF24 , FB15K (a subset of Freebase) BIBREF2"], "all_classes": null, "length": 3367}
{"pred": "\"LastStateRNN\"", "answers": [" LastStateRNN, AvgRNN, AttentionRNN", "LastStateRNN, AvgRNN, AttentionRNN "], "all_classes": null, "length": 2823}
{"pred": "Personal attack, racism, sexism", "answers": ["personal attack, racism, and sexism", "racism, sexism, personal attack, not specifically about any single topic"], "all_classes": null, "length": 3244}
{"pred": "Yes", "answers": ["Yes", "Yes"], "all_classes": null, "length": 3634}
{"pred": "Annotated Twitter dataset constructed based on a hierarchical model of depression-related symptoms", "answers": ["BIBREF12 , BIBREF13", "an existing, annotated Twitter dataset that was constructed based on a hierarchical model of depression-related symptoms BIBREF12 , BIBREF13"], "all_classes": null, "length": 1939}
{"pred": "The Nguni and Sotho languages are similar to each other.", "answers": ["Nguni languages (zul, xho, nbl, ssw), Sotho languages (nso, sot, tsn)", "The Nguni languages are similar to each other, The same is true of the Sotho languages"], "all_classes": null, "length": 1877}
{"pred": "Imdb dataset", "answers": ["IMDb dataset of movie reviews", "IMDb"], "all_classes": null, "length": 2327}
{"pred": "89.6% and 89.2% (accuracy and F1-score respectively)", "answers": ["accuracy and F1-score of 89.6% and 89.2%, respectively", "accuracy and F1-score of 89.6% and 89.2%, respectively"], "all_classes": null, "length": 3313}
{"pred": "Outperforms K-means, LEM, and DPEMM.", "answers": ["K-means, LEM BIBREF13, DPEMM BIBREF14", "K-means, LEM, DPEMM"], "all_classes": null, "length": 3841}
{"pred": "8 languages (English, German, Spanish, Mandarin, Polish, Russian, Korean, Serbian)", "answers": ["English, German, Spanish, Mandarin, Polish, Russian, Korean and Serbian", "English (Edinburgh), German (Berlin), Spanish (Madrid), Mandarin (Taipei), Polish (Warsaw), Russian (Moscow), Korean (Seoul), and Serbian (Belgrade)"], "all_classes": null, "length": 2754}
{"pred": "The datasets are not specified in the article.", "answers": ["rupnik2016news", "rupnik2016news, Deutsche Welle's news website"], "all_classes": null, "length": 3160}
{"pred": "Unanswerable (from the information provided, it is not clear if the lexicon is the same for all languages)", "answers": ["Yes", "Yes"], "all_classes": null, "length": 1868}
{"pred": "InferSent, Universal Sentence Encoder, and average GloVe embeddings are evaluated.", "answers": ["GloVe, BERT, Universal Sentence Encoder, TF-IDF, InferSent", "Avg. GloVe embeddings, Avg. fast-text embeddings, Avg. BERT embeddings, BERT CLS-vector, InferSent - GloVe and Universal Sentence Encoder."], "all_classes": null, "length": 3862}
{"pred": "SentEval toolkit tasks", "answers": ["MR, CR, SUBJ, MPQA, SST, TREC, MRPC", "MR: Sentiment prediction for movie reviews snippets on a five start scale BIBREF25.\n\nCR: Sentiment prediction of customer product reviews BIBREF26.\n\nSUBJ: Subjectivity prediction of sentences from movie reviews and plot summaries BIBREF27.\n\nMPQA: Phrase level opinion polarity classification from newswire BIBREF28.\n\nSST: Stanford Sentiment Treebank with binary labels BIBREF29.\n\nTREC: Fine grained question-type classification from TREC BIBREF30.\n\nMRPC: Microsoft Research Paraphrase Corpus from parallel news sources BIBREF31.", "Semantic Textual Similarity, sentiment prediction, subjectivity prediction, phrase level opinion polarity classification, Stanford Sentiment Treebank, fine grained question-type classification."], "all_classes": null, "length": 3861}
{"pred": "Unanswerable (vocabulary of who or what is not specified in the article)", "answers": ["33,663", "33,663 distinct review keywords "], "all_classes": null, "length": 3305}
{"pred": "Context tweets are proposed as additional features.", "answers": ["using tweets that one has replied or quoted to as contextual information", "text sequences of context tweets"], "all_classes": null, "length": 2060}
{"pred": "Yes", "answers": ["No", "No"], "all_classes": null, "length": 1906}
{"pred": "No. The article describes the creation of maps based on demographic, linguistic, and psycholinguistic properties of a blog dataset, but does not mention building a model to automatically detect these dimensions.", "answers": ["No", "No"], "all_classes": null, "length": 1443}
{"pred": "Ensemble+ of (r19) in Sentence-Level Propaganda and ensemble+ of (II and IV) from each of folds 1-3 in Fragment-level Propaganda, both have a F1 score of 0.67 and 0.43, respectively.", "answers": ["For SLC task, the \"ltuorp\" team  has the best performing  model (0.6323/0.6028/0.6649 for F1/P/R  respectively) and for FLC task the \"newspeak\" team  has the best performing  model (0.2488/0.2863/0.2201 for F1/P/R respectively)."], "all_classes": null, "length": 1541}
{"pred": "DTA18 and DTA19", "answers": ["DTA18, DTA19", "Diachronic Usage Relatedness (DURel) gold standard data set"], "all_classes": null, "length": 1908}
{"pred": "13,757 question-answer pairs", "answers": ["13,757", "10,898 articles, 17,794 tweets, and 13,757 crowdsourced question-answer pairs"], "all_classes": null, "length": 3704}
{"pred": "KNN, Random Forest, SVM, and MLP", "answers": ["KNN\nRF\nSVM\nMLP", " K Nearest Neighbors (KNN), Random Forest (RF), Support Vector Machine (SVM), Multi-layer Perceptron (MLP)"], "all_classes": null, "length": 1639}
{"pred": "They obtain the new context representation by using two contexts: a combination of the left context, the left entity, and the middle context; and a combination of the middle context, the right entity, and the right context.", "answers": ["They use two independent convolutional and max-pooling layers on (1) a combination of the left context, the left entity and the middle context; and (2) a combination of the middle context, the right entity and the right context. They concatenated the two results after pooling to get the new context representation."], "all_classes": null, "length": 2435}
{"pred": "Multi-granularity and multi-tasking in neural architecture design.", "answers": ["An output layer for each task", "Multi-tasking is addressed by neural sequence tagger based on LSTM-CRF and linguistic features, while multi-granularity is addressed by ensemble of LSTM-CRF and BERT."], "all_classes": null, "length": 1514}
{"pred": "The CORD-19 dataset is a collection of scholarly articles, including over 33,000 with full text, about COVID-19, SARS-CoV-2, and related coronaviruses.", "answers": ["which contains over 45,000 scholarly articles, including over 33,000 with full text, about COVID-19, SARS-CoV-2, and related coronaviruses", "contains over 45,000 scholarly articles, including over 33,000 with full text, about COVID-19, SARS-CoV-2, and related coronaviruses"], "all_classes": null, "length": 2156}
{"pred": "4528 employees", "answers": ["26972", "26972 sentences"], "all_classes": null, "length": 3040}
{"pred": "Performs favorably against recent neural network-based approaches to grammar induction.", "answers": ["Unanswerable", "Unanswerable"], "all_classes": null, "length": 2533}
{"pred": "Backoff strategies back off to a neutral word, a background model, or a more generic word recognizer when the foreground model predicts UNK.", "answers": ["In pass-through, the recognizer passes on the possibly misspelled word, backoff to neutral word backs off to a word with similar distribution across classes and backoff to background model backs off to a more generic word recognition model trained with larger and less specialized corpus.", "Pass-through passes the possibly misspelled word as is, backoff to neutral word backs off to a word with similar distribution across classes and backoff to background model backs off to a more generic word recognition model trained with larger and less specialized corpus.", "Backoff to \"a\" when an UNK-predicted word is encountered, backoff to a more generic word recognition model when the model predicts UNK"], "all_classes": null, "length": 4210}
{"pred": "The Neural User Simulator (NUS) is trained on a corpus of recorded dialogues.", "answers": ["DSTC2", "The manual transcriptions of the DSTC2 training set "], "all_classes": null, "length": 4820}
{"pred": "BLEU-4, NIST-4, and ROUGE-4", "answers": ["BLEU-4, NIST-4, ROUGE-4", "BLEU-4, NIST-4, ROUGE-4"], "all_classes": null, "length": 4460}
{"pred": "r-net and AoA", "answers": ["SVM , CNN , GRU , CNN/GRU+law, r-net , AoA ", "SVM with lexical features in accordance with previous works BIBREF16 , BIBREF17 , BIBREF1 , BIBREF15 , BIBREF4, attention-based method BIBREF3 and other methods we deem important, some off-the-shelf RC models, including r-net BIBREF5 and AoA BIBREF6 , which are the leading models on SQuAD leaderboard"], "all_classes": null, "length": 4106}
{"pred": "Surface, morphological, and syntactic features are used.", "answers": ["POS, gender/number and stem POS"], "all_classes": null, "length": 4719}
{"pred": "Larger values along the dimension corresponding to the imparted concept.", "answers": ["dimension corresponding to the concept that the particular word belongs to"], "all_classes": null, "length": 6182}
{"pred": "The article does not specify the language of the data.", "answers": ["English , German, French"], "all_classes": null, "length": 4173}
{"pred": "Unanswerable", "answers": ["Unanswerable", "Unanswerable"], "all_classes": null, "length": 4465}
{"pred": "Disinformation and mainstream news", "answers": ["mainstream news and disinformation", "mainstream and disinformation news"], "all_classes": null, "length": 4856}
{"pred": "CookingWorld and CoinCollector", "answers": ["CoinCollector , CookingWorld ", "CoinCollector, CookingWorld"], "all_classes": null, "length": 4924}
{"pred": "F @ INLINEFORM0 and F @ INLINEFORM1", "answers": ["average unique predictions, randomly sample 2000 decoder hidden states at INLINEFORM4 steps following a delimiter ( INLINEFORM5 ) and apply an unsupervised clustering method (t-SNE BIBREF35 )"], "all_classes": null, "length": 4581}
{"pred": "Their model captures biases in the process of collecting or annotating datasets.", "answers": ["Data annotation biases where tweet containing disrespectful words are annotated as hate or offensive without any presumption about the social context of tweeters"], "all_classes": null, "length": 4111}
{"pred": "\"Comparison with Puduppully-updt, automatic inference and enrichment, and operation-guided networks, and constraining the model on the data structure to prevent inaccurate descriptions.\"", "answers": ["rther constrain the model on the data structure in order to prevent inaccurate of even contradictory descriptions", "to further constrain the model on the data structure in order to prevent inaccurate of even contradictory descriptions"], "all_classes": null, "length": 4704}
{"pred": "Additive modification to the objective function is rCl j(wi,l) + l(Fl g(wi,l)).", "answers": ["The cost function for any one of the words of concept word-groups is modified by the introduction of an additive term to the cost function. . Each embedding vector dimension is first associated with a concept. For a word belonging to any one of the word-groups representing these concepts, the modified cost term favors an increase for the value of this word's embedding vector dimension corresponding to the concept that the particular word belongs to,", "An additive term added to the cost function for any one of the words of concept word-groups"], "all_classes": null, "length": 6244}
{"pred": "Yes", "answers": ["Yes", "Yes"], "all_classes": null, "length": 7837}
{"pred": "It is built on top of pretrained Bert and uses external [cls] tokens at the start of each sentence.", "answers": ["Bert model have a maximum length of 512; we overcome this limitation by adding more position embeddings, we insert external [cls] tokens at the start of each sentence, and each [cls] symbol collects features for the sentence preceding it, document representations are learned hierarchically"], "all_classes": null, "length": 4404}
{"pred": "Improves interpretability by learning sparse attention patterns.", "answers": ["the attention heads in the proposed adaptively sparse Transformer can specialize more and with higher confidence", "We introduce sparse attention into the Transformer architecture"], "all_classes": null, "length": 4902}
{"pred": "The article does not provide a specific percentage of improvement for the attention mechanism.", "answers": ["Unanswerable", "Unanswerable"], "all_classes": null, "length": 5331}
{"pred": "22,880 users", "answers": ["22,880 users", "20,000"], "all_classes": null, "length": 4160}
{"pred": "Instance is a sentence.", "answers": ["sentence"], "all_classes": null, "length": 4369}
{"pred": "Harassment, personal attacks, general toxicity, and derailment of conversations.", "answers": ["The Conversations Gone Awry dataset is labelled as either containing a personal attack from withint (i.e. hostile behavior by one user in the conversation directed towards another) or remaining civil throughout. The Reddit Change My View dataset is labelled with whether or not a coversation eventually had a comment removed by a moderator for violation of Rule 2: \"Don't be rude or hostile to others users.\""], "all_classes": null, "length": 4779}
{"pred": "Datasets constructed from China Judgments Online are used in the experiment.", "answers": ["build a new one, collect INLINEFORM0 cases from China Judgments Online"], "all_classes": null, "length": 4109}
{"pred": "They measure style transfer success using human evaluation.", "answers": ["Unanswerable"], "all_classes": null, "length": 4572}
{"pred": "Unanswerable (without additional context or specific comparison metric)", "answers": ["absolute improvement of 18.2% over the Pointer-Gen baseline"], "all_classes": null, "length": 4091}
{"pred": "Using a group of 50 native speakers.", "answers": ["50 human annotators ranked a random sample of 100 translations by Adequacy, Fluency and overall ranking on a 5-point scale.", "adequacy, precision and ranking values"], "all_classes": null, "length": 5344}
{"pred": "They use a joint model that combines visual and textual features.", "answers": ["visual model is based on fine-tuning an Inception V3 model BIBREF1 over visual renderings of documents, while our textual model is based on a hierarchical biLSTM. We further combine the two into a joint model. , neural network models", "Inception V3, biLSTM"], "all_classes": null, "length": 4217}
{"pred": "The baseline is the M2M Transformer model (b3).", "answers": ["pivot-based translation relying on a helping language BIBREF10, nduction of phrase tables from monolingual data BIBREF14 , attentional RNN-based model (RNMT) BIBREF2, Transformer model BIBREF18, bi-directional model BIBREF11, multi-to-multi (M2M) model BIBREF8, back-translation BIBREF17", "M2M Transformer"], "all_classes": null, "length": 4542}
{"pred": "Number of Strongly Connected Components, Size of the Largest Strongly Connected Component, Number of Weakly Connected Components, Size of the Largest Weakly Connected Component, Diameter of the Largest Weakly Connected Component, Average Clustering Coefficient, Main K-core Number, Density, Structural Virality of the Largest Weakly Connected Component.", "answers": ["Number of Strongly Connected Components (SCC), Size of the Largest Strongly Connected Component (LSCC), Number of Weakly Connected Components (WCC), Size of the Largest Weakly Connected Component (LWCC), Diameter of the Largest Weakly Connected Component (DWCC), Average Clustering Coefficient (CC), Main K-core Number (KC), Density (d)"], "all_classes": null, "length": 4906}
{"pred": "Lookup table embedding with no pretraining.", "answers": ["QA PGNet, Multi-decoder QA PGNet with lookup table embedding", "QA PGNet and Multi-decoder QA PGNet"], "all_classes": null, "length": 4600}
{"pred": "Relation detection", "answers": ["answer questions by obtaining information from KB tuples ", "hierarchical matching between questions and relations with residual learning"], "all_classes": null, "length": 4527}
{"pred": "Gradient-based reward learning algorithm (BIBREF7)", "answers": ["BIBREF7", " reward learning algorithm BIBREF7"], "all_classes": null, "length": 4841}
{"pred": "They used BioASQ data.", "answers": ["BioASQ  dataset", "A dataset provided by BioASQ consisting of questions, gold standard documents, snippets, concepts  and ideal and ideal answers."], "all_classes": null, "length": 6810}
{"pred": "Semi-manual Pyramid scores", "answers": [" higher tiers of the pyramid", "following the pyramid framework, we design an annotation scheme"], "all_classes": null, "length": 4771}
{"pred": "The models attribute output word importance based on integrated gradients.", "answers": ["Given the contribution matrix, we can obtain the word importance of each input word to the entire output sentence. ", "They compute the gradient of the output at each time step with respect to the input words to decide the importance."], "all_classes": null, "length": 4253}
{"pred": "The state of the art models include those by BIBREF9 and BIBREF8.", "answers": ["BIBREF9 , BIBREF8 ", "BIBREF9 , BIBREF8"], "all_classes": null, "length": 4855}
{"pred": "Improved in both low data regime and class-imbalance problems.", "answers": ["Low data: SST-5, TREC, IMDB around 1-2 accuracy points better than baseline\nImbalanced labels: the improvement over the base model increases as the data gets more imbalanced, ranging from around 6 accuracy points on 100:1000 to over 20 accuracy points on 20:1000"], "all_classes": null, "length": 4880}
{"pred": "Multiple choice question answering", "answers": ["MULTIPLE CHOICE QUESTION ANSWERING", "multiple-choice"], "all_classes": null, "length": 6396}
{"pred": "Waseem and Hovy, Davidson et al.", "answers": ["Waseem-dataset, Davidson-dataset,", "Waseem and Hovey BIBREF5, Davidson et al. BIBREF9"], "all_classes": null, "length": 4090}
{"pred": "Transformer and RNN-Search", "answers": [" Transformer BIBREF1 model and the conventional RNN-Search model BIBREF0", "Transformer, RNN-Search model"], "all_classes": null, "length": 4240}
{"pred": "\"By calculating the average unique predictions produced by the model and using an unsupervised clustering method.\"", "answers": ["average unique predictions, illustrate the difference of predictions between our proposed models, we show an example chosen from the KP20k validation set"], "all_classes": null, "length": 4576}
{"pred": "Evaluation with a pilot study and comparison to ROUGE-2 and Pyramid scores.", "answers": ["Answer with content missing: (Evaluation Metrics section) Precision, Recall, F1-scores, Strict match, METEOR, ROUGE-2"], "all_classes": null, "length": 4263}
{"pred": "They compared 6-layers and 9-layers LSTM models.", "answers": ["Unidirectional LSTM networks with 2, 6, 7, 8, and  9 layers."], "all_classes": null, "length": 4286}
{"pred": "Both professional and machine translation introduce artifacts.", "answers": ["Yes"], "all_classes": null, "length": 4073}
{"pred": "Knowledge Aided Reader (KAR)", "answers": ["Lexicon Embedding Layer, Context Embedding Layer, Coarse Memory Layer, Refined Memory Layer, Answer Span Prediction Layer"], "all_classes": null, "length": 4133}
{"pred": "Improving the sensationalism scorer and investigating applications of dynamic balancing methods between RL and MLE in textGAN.", "answers": ["ethical questions about generating sensational headlines, which can be further explored,  improving the sensationalism scorer, investigating the applications of dynamic balancing methods between RL and MLE"], "all_classes": null, "length": 4104}
{"pred": "The dataset models character's profiles based on Human Level Attributes (HLAs) collected from TV Tropes.", "answers": ["attributes are determined by human viewers and their impressions of the characters, and are correlated with human-like characteristics"], "all_classes": null, "length": 5136}
{"pred": "Reuters database", "answers": ["Reuters-8 dataset without stop words", "The Reuters-8 dataset (with stop words removed)"], "all_classes": null, "length": 5147}
{"pred": "Accuracy is demonstrated through empirical evaluation.", "answers": ["significant improvements clearly demonstrate that our approach is effective at improving model performance", "By evaluating the performance of the approach using accuracy and AUC"], "all_classes": null, "length": 4489}
{"pred": "The authors present evidence of the model detecting biases in data annotation and collection by examining misclassified samples and observing that many errors are due to biases in the data collection and annotation rules.", "answers": ["The authors showed few tweets where neither and implicit hatred content exist but the model was able to discriminate"], "all_classes": null, "length": 4119}
{"pred": "SimpleQuestions and WebQSP", "answers": ["SimpleQuestions, WebQSP", "WebQSP, SimpleQuestions"], "all_classes": null, "length": 4524}
{"pred": "Grammatical, spelling, and word order errors", "answers": ["grammatical, spelling and word order errors", "spelling, word order and grammatical errors"], "all_classes": null, "length": 4579}
{"pred": "Crawled over 2M tweets from Twitter.", "answers": ["They developed a classifier to find ironic sentences in twitter data", "by crawling"], "all_classes": null, "length": 4599}
{"pred": "Global context refers to the representation of the whole document, while local context refers to the representation of the topic segment of each sentence.", "answers": ["global (the whole document), local context (e.g., the section/topic)", "global (the whole document) and the local context (e.g., the section/topic) "], "all_classes": null, "length": 4287}
{"pred": "Knowledge Base Question Answering (KBQA)", "answers": ["Knowledge Base Question Answering", "Knowledge Base Question Answering "], "all_classes": null, "length": 4521}
{"pred": "They used Gibbs sampling to implement the inference and obtain the topic models for ISWC and WWW publications.", "answers": ["the LDA approaches to recommendation systems and given the importance of research, we have studied recent impressive articles on this subject and presented a taxonomy of recommendation systems based on LDA of the recent research, we evaluated ISWC and WWW conferences articles from DBLP website and used the Gibbs sampling algorithm as an evaluation parameter", "discover the trends of the topics and find relationship between LDA topics and paper features and generate trust tags,  learn a LDA model with 100 topics; $\\alpha =0.01$, $\\beta = 0.01$ and using Gibbs sampling as a parameter estimation"], "all_classes": null, "length": 4322}
{"pred": "Yes.", "answers": ["Yes", "Yes"], "all_classes": null, "length": 4127}
{"pred": "Imbalanced (33.16% women, 66.84% men)", "answers": ["Women represent 33.16% of the speakers"], "all_classes": null, "length": 4055}
{"pred": "Baseline model was always 'Yes'.", "answers": ["by answering always YES (in batch 2 and 3) "], "all_classes": null, "length": 6817}
{"pred": "0.7033 (for List-type question answering task in the fourth test batch set)", "answers": ["0.7033", "0.7033"], "all_classes": null, "length": 6810}
{"pred": "BLEU, NIST, METEOR, ROUGE-L, CIDEr, and WER (Word Error Rate)", "answers": ["BLEU , NIST , METEOR , ROUGE-L, CIDEr , evaluation script, automatic evaluation, human evaluation, minimum edit evaluation, word error rate (WER), factual errors and their types, fluency issues, acceptability of the output for production use in a news agency", "BLEU, NIST, METEOR, ROUGE-L, CIDEr"], "all_classes": null, "length": 4738}
{"pred": "Multinomial Naive Bayes algorithm", "answers": ["AllWords model by counting the frequencies of all the remaining words and training a multinomial Naive Bayes classifier"], "all_classes": null, "length": 4177}
{"pred": "Two predetermined event categories: cyber security (CyberAttack) and death of politicians (PoliticianDeath).", "answers": ["Tweets related to CyberAttack and tweets related to PoliticianDeath", "cyber security (CyberAttack), death of politicians (PoliticianDeath)"], "all_classes": null, "length": 4481}
{"pred": "Logistic Regression and Deep Learning Model", "answers": ["Logistic Regression, neural networks"], "all_classes": null, "length": 7257}
{"pred": "Conditional Copy (CC)", "answers": ["Conditional Copy (CC) model ", "delayed copy model (DEL),  template system (TEM), conditional copy (CC), NCP+CC (NCP)"], "all_classes": null, "length": 4746}
